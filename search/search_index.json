{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PyCap PyCap is an interface to the REDCap Application Programming Interface (API). PyCap is designed to be a minimal interface exposing all required and optional API parameters. Our hope is that it makes simple things easy & hard things possible. Installation Install the latest version with pip $ pip install PyCap If you want to load REDCap data into pandas dataframes, this will make sure you have pandas installed $ pip install PyCap [ all ] To install the bleeding edge version from the github repo, use the following $ pip install -e git+https://github.com/redcap-tools/PyCap.git#egg = PyCap Philosophy The REDCap API is pretty simple. There is no built-in search or pagination, for example. However, it does expose all the functionality required to build advanced data management services on top of the API. In the same way, PyCap is minimal by design. It doesn't do anything fancy behind the scenes and will not prevent you from shooting yourself in the foot. However, it should be very easy to understand and mentally-map PyCap functionality to the REDCap API. License PyCap is licensed under the MIT license . Citing If you use PyCap in your research, please consider citing the software: Burns, S. S., Browne, A., Davis, G. N., Rimrodt, S. L., & Cutting, L. E. PyCap (Version 1.0) [Computer Software]. Nashville, TN: Vanderbilt University and Philadelphia, PA: Childrens Hospital of Philadelphia. Available from https://github.com/redcap-tools/PyCap. doi:10.5281/zenodo.9917","title":"Home"},{"location":"#pycap","text":"PyCap is an interface to the REDCap Application Programming Interface (API). PyCap is designed to be a minimal interface exposing all required and optional API parameters. Our hope is that it makes simple things easy & hard things possible.","title":"PyCap"},{"location":"#installation","text":"Install the latest version with pip $ pip install PyCap If you want to load REDCap data into pandas dataframes, this will make sure you have pandas installed $ pip install PyCap [ all ] To install the bleeding edge version from the github repo, use the following $ pip install -e git+https://github.com/redcap-tools/PyCap.git#egg = PyCap","title":"Installation"},{"location":"#philosophy","text":"The REDCap API is pretty simple. There is no built-in search or pagination, for example. However, it does expose all the functionality required to build advanced data management services on top of the API. In the same way, PyCap is minimal by design. It doesn't do anything fancy behind the scenes and will not prevent you from shooting yourself in the foot. However, it should be very easy to understand and mentally-map PyCap functionality to the REDCap API.","title":"Philosophy"},{"location":"#license","text":"PyCap is licensed under the MIT license .","title":"License"},{"location":"#citing","text":"If you use PyCap in your research, please consider citing the software: Burns, S. S., Browne, A., Davis, G. N., Rimrodt, S. L., & Cutting, L. E. PyCap (Version 1.0) [Computer Software]. Nashville, TN: Vanderbilt University and Philadelphia, PA: Childrens Hospital of Philadelphia. Available from https://github.com/redcap-tools/PyCap. doi:10.5281/zenodo.9917","title":"Citing"},{"location":"quickstart/","text":"Quickstart PyCap makes it very simple to interact with the data stored in your REDCap projects from redcap import Project api_url = 'https://redcap.example.edu/api/' api_key = 'SomeSuperSecretAPIKeyThatNobodyElseShouldHave' project = Project ( api_url , api_key ) Export all the data data = project . export_records () Import all the data to_import = [{ 'record' : 'foo' , 'test_score' : 'bar' }] response = project . import_records ( to_import ) Import a file fname = 'something_to_upload.txt' with open ( fname , 'r' ) as fobj : project . import_file ( '1' , 'file' , fname , fobj ) Export a file content , headers = project . export_file ( '1' , 'file' ) with open ( headers [ 'name' ], 'wb' ) as fobj : fobj . write ( content ) Delete a file try : project . delete_file ( '1' , 'file' ) except redcap . RedcapError : # Throws this if file wasn't successfully deleted pass except ValueError : # You screwed up and gave it a bad field name, etc pass Export a PDF file of all instruments (blank) content , _headers = project . export_pdf () with open ( 'all_instruments_blank.pdf' , 'wb' ) as fobj : fobj . write ( content )","title":"Quick Start"},{"location":"quickstart/#quickstart","text":"PyCap makes it very simple to interact with the data stored in your REDCap projects from redcap import Project api_url = 'https://redcap.example.edu/api/' api_key = 'SomeSuperSecretAPIKeyThatNobodyElseShouldHave' project = Project ( api_url , api_key ) Export all the data data = project . export_records () Import all the data to_import = [{ 'record' : 'foo' , 'test_score' : 'bar' }] response = project . import_records ( to_import ) Import a file fname = 'something_to_upload.txt' with open ( fname , 'r' ) as fobj : project . import_file ( '1' , 'file' , fname , fobj ) Export a file content , headers = project . export_file ( '1' , 'file' ) with open ( headers [ 'name' ], 'wb' ) as fobj : fobj . write ( content ) Delete a file try : project . delete_file ( '1' , 'file' ) except redcap . RedcapError : # Throws this if file wasn't successfully deleted pass except ValueError : # You screwed up and gave it a bad field name, etc pass Export a PDF file of all instruments (blank) content , _headers = project . export_pdf () with open ( 'all_instruments_blank.pdf' , 'wb' ) as fobj : fobj . write ( content )","title":"Quickstart"},{"location":"using-in-app-or-package/","text":"Using PyCap in an app/package If you're using PyCap for a small script/ad-hoc data pull, then the Project class has the all the necessary functionality. Similarly, the Project class is a good choice if you need access to a wide array of functionality (export records, surveys, user, etc.). However, if you only are using one piece of the REDCap API, then you might want to consider using one of the more focused and simpler classes. For example, if all you want to do is export/import records from your project, then Records class can meet all of your needs, with it's Records.export_records and Records.import_records methods. In fact, these methods are exactly the same as the Project.export_records and Project.import_records methods. The Project class directly inherits them from the Records class. The benefit of using the Records class over the Project class in this case for your application or package is getting to use a simpler class (easy for the developer) and only having to depend on a simpler class (better for the app). For a full list of all Project subclasses, see the API Reference .","title":"Using PyCap in an app/package"},{"location":"using-in-app-or-package/#using-pycap-in-an-apppackage","text":"If you're using PyCap for a small script/ad-hoc data pull, then the Project class has the all the necessary functionality. Similarly, the Project class is a good choice if you need access to a wide array of functionality (export records, surveys, user, etc.). However, if you only are using one piece of the REDCap API, then you might want to consider using one of the more focused and simpler classes. For example, if all you want to do is export/import records from your project, then Records class can meet all of your needs, with it's Records.export_records and Records.import_records methods. In fact, these methods are exactly the same as the Project.export_records and Project.import_records methods. The Project class directly inherits them from the Records class. The benefit of using the Records class over the Project class in this case for your application or package is getting to use a simpler class (easy for the developer) and only having to depend on a simpler class (better for the app). For a full list of all Project subclasses, see the API Reference .","title":"Using PyCap in an app/package"},{"location":"api_reference/arms/","text":"Arms REDCap API methods for Project arms Arms ( Base ) Responsible for all API methods under 'Arms' in the API Playground Source code in redcap/methods/arms.py class Arms ( Base ): \"\"\"Responsible for all API methods under 'Arms' in the API Playground\"\"\" def export_arms ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , ): \"\"\" Export the Arms of the Project Note: This only works for longitudinal projects. Args: format_type: Response return format arms: An array of arm numbers that you wish to pull arms for (by default, all arms are pulled) Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Arms Examples: >>> proj.export_arms() [{'arm_num': 1, 'name': 'Arm 1'}] \"\"\" payload = self . _initialize_payload ( content = \"arm\" , format_type = format_type ) if arms : # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"arm\" , format_type = format_type , ) def import_arms ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , override : Optional [ int ] = 0 , ): \"\"\" Import Arms into the REDCap Project Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded override: 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Arms in the project while importing new Arms. If override=0, then you can only add new Arms or rename existing ones. Returns: Union[int, str]: Number of Arms added or updated Examples: Create a new arm >>> new_arm = [{\"arm_num\": 2, \"name\": \"Arm 2\"}] >>> proj.import_arms(new_arm) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"arm\" , ) payload [ \"action\" ] = \"import\" payload [ \"override\" ] = override return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def delete_arms ( self , arms : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete Arms from the Project Note: Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an arm also automatically deletes all events that belong to that arm, and will also automatically delete any records/data that have been collected under that arm (this is non-reversible data loss). This only works for longitudinal projects. Args: arms: List of arm numbers to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of arms deleted Examples: Create a new arm >>> new_arm = [{\"arm_num\": 2, \"name\": \"Arm 2\"}] >>> proj.import_arms(new_arm) 1 Delete the new arm >>> proj.delete_arms([2]) 1 \"\"\" payload = self . _initialize_payload ( content = \"arm\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server delete_arms ( self , arms , return_format_type = 'json' ) Delete Arms from the Project !!! note Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an arm also automatically deletes all events that belong to that arm, and will also automatically delete any records/data that have been collected under that arm (this is non-reversible data loss). This only works for longitudinal projects. Parameters: Name Type Description Default arms List[str] List of arm numbers to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of arms deleted Examples: Create a new arm >>> new_arm = [{ \"arm_num\" : 2 , \"name\" : \"Arm 2\" }] >>> proj . import_arms ( new_arm ) 1 Delete the new arm >>> proj . delete_arms ([ 2 ]) 1 Source code in redcap/methods/arms.py def delete_arms ( self , arms : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete Arms from the Project Note: Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an arm also automatically deletes all events that belong to that arm, and will also automatically delete any records/data that have been collected under that arm (this is non-reversible data loss). This only works for longitudinal projects. Args: arms: List of arm numbers to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of arms deleted Examples: Create a new arm >>> new_arm = [{\"arm_num\": 2, \"name\": \"Arm 2\"}] >>> proj.import_arms(new_arm) 1 Delete the new arm >>> proj.delete_arms([2]) 1 \"\"\" payload = self . _initialize_payload ( content = \"arm\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response export_arms ( self , format_type = 'json' , arms = None ) Export the Arms of the Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' arms Optional[List[str]] An array of arm numbers that you wish to pull arms for (by default, all arms are pulled) None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of Arms Examples: >>> proj . export_arms () [{ 'arm_num' : 1 , 'name' : 'Arm 1' }] Source code in redcap/methods/arms.py def export_arms ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , ): \"\"\" Export the Arms of the Project Note: This only works for longitudinal projects. Args: format_type: Response return format arms: An array of arm numbers that you wish to pull arms for (by default, all arms are pulled) Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Arms Examples: >>> proj.export_arms() [{'arm_num': 1, 'name': 'Arm 1'}] \"\"\" payload = self . _initialize_payload ( content = \"arm\" , format_type = format_type ) if arms : # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"arm\" , format_type = format_type , ) import_arms ( self , to_import , return_format_type = 'json' , import_format = 'json' , override = 0 ) Import Arms into the REDCap Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' override Optional[int] 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Arms in the project while importing new Arms. If override=0, then you can only add new Arms or rename existing ones. 0 Returns: Type Description Union[int, str] Number of Arms added or updated Examples: Create a new arm >>> new_arm = [{ \"arm_num\" : 2 , \"name\" : \"Arm 2\" }] >>> proj . import_arms ( new_arm ) 1 Source code in redcap/methods/arms.py def import_arms ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , override : Optional [ int ] = 0 , ): \"\"\" Import Arms into the REDCap Project Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded override: 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Arms in the project while importing new Arms. If override=0, then you can only add new Arms or rename existing ones. Returns: Union[int, str]: Number of Arms added or updated Examples: Create a new arm >>> new_arm = [{\"arm_num\": 2, \"name\": \"Arm 2\"}] >>> proj.import_arms(new_arm) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"arm\" , ) payload [ \"action\" ] = \"import\" payload [ \"override\" ] = override return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"Arms"},{"location":"api_reference/arms/#arms","text":"REDCap API methods for Project arms","title":"Arms"},{"location":"api_reference/arms/#redcap.methods.arms.Arms","text":"Responsible for all API methods under 'Arms' in the API Playground Source code in redcap/methods/arms.py class Arms ( Base ): \"\"\"Responsible for all API methods under 'Arms' in the API Playground\"\"\" def export_arms ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , ): \"\"\" Export the Arms of the Project Note: This only works for longitudinal projects. Args: format_type: Response return format arms: An array of arm numbers that you wish to pull arms for (by default, all arms are pulled) Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Arms Examples: >>> proj.export_arms() [{'arm_num': 1, 'name': 'Arm 1'}] \"\"\" payload = self . _initialize_payload ( content = \"arm\" , format_type = format_type ) if arms : # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"arm\" , format_type = format_type , ) def import_arms ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , override : Optional [ int ] = 0 , ): \"\"\" Import Arms into the REDCap Project Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded override: 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Arms in the project while importing new Arms. If override=0, then you can only add new Arms or rename existing ones. Returns: Union[int, str]: Number of Arms added or updated Examples: Create a new arm >>> new_arm = [{\"arm_num\": 2, \"name\": \"Arm 2\"}] >>> proj.import_arms(new_arm) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"arm\" , ) payload [ \"action\" ] = \"import\" payload [ \"override\" ] = override return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def delete_arms ( self , arms : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete Arms from the Project Note: Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an arm also automatically deletes all events that belong to that arm, and will also automatically delete any records/data that have been collected under that arm (this is non-reversible data loss). This only works for longitudinal projects. Args: arms: List of arm numbers to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of arms deleted Examples: Create a new arm >>> new_arm = [{\"arm_num\": 2, \"name\": \"Arm 2\"}] >>> proj.import_arms(new_arm) 1 Delete the new arm >>> proj.delete_arms([2]) 1 \"\"\" payload = self . _initialize_payload ( content = \"arm\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"Arms"},{"location":"api_reference/arms/#redcap.methods.arms.Arms.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/arms/#redcap.methods.arms.Arms.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/arms/#redcap.methods.arms.Arms.forms","text":"Project form names","title":"forms"},{"location":"api_reference/arms/#redcap.methods.arms.Arms.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/arms/#redcap.methods.arms.Arms.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/arms/#redcap.methods.arms.Arms.token","text":"API token to a project","title":"token"},{"location":"api_reference/arms/#redcap.methods.arms.Arms.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/arms/#redcap.methods.arms.Arms.delete_arms","text":"Delete Arms from the Project !!! note Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an arm also automatically deletes all events that belong to that arm, and will also automatically delete any records/data that have been collected under that arm (this is non-reversible data loss). This only works for longitudinal projects. Parameters: Name Type Description Default arms List[str] List of arm numbers to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of arms deleted Examples: Create a new arm >>> new_arm = [{ \"arm_num\" : 2 , \"name\" : \"Arm 2\" }] >>> proj . import_arms ( new_arm ) 1 Delete the new arm >>> proj . delete_arms ([ 2 ]) 1 Source code in redcap/methods/arms.py def delete_arms ( self , arms : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete Arms from the Project Note: Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an arm also automatically deletes all events that belong to that arm, and will also automatically delete any records/data that have been collected under that arm (this is non-reversible data loss). This only works for longitudinal projects. Args: arms: List of arm numbers to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of arms deleted Examples: Create a new arm >>> new_arm = [{\"arm_num\": 2, \"name\": \"Arm 2\"}] >>> proj.import_arms(new_arm) 1 Delete the new arm >>> proj.delete_arms([2]) 1 \"\"\" payload = self . _initialize_payload ( content = \"arm\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"delete_arms()"},{"location":"api_reference/arms/#redcap.methods.arms.Arms.export_arms","text":"Export the Arms of the Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' arms Optional[List[str]] An array of arm numbers that you wish to pull arms for (by default, all arms are pulled) None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of Arms Examples: >>> proj . export_arms () [{ 'arm_num' : 1 , 'name' : 'Arm 1' }] Source code in redcap/methods/arms.py def export_arms ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , ): \"\"\" Export the Arms of the Project Note: This only works for longitudinal projects. Args: format_type: Response return format arms: An array of arm numbers that you wish to pull arms for (by default, all arms are pulled) Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Arms Examples: >>> proj.export_arms() [{'arm_num': 1, 'name': 'Arm 1'}] \"\"\" payload = self . _initialize_payload ( content = \"arm\" , format_type = format_type ) if arms : # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"arm\" , format_type = format_type , )","title":"export_arms()"},{"location":"api_reference/arms/#redcap.methods.arms.Arms.import_arms","text":"Import Arms into the REDCap Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' override Optional[int] 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Arms in the project while importing new Arms. If override=0, then you can only add new Arms or rename existing ones. 0 Returns: Type Description Union[int, str] Number of Arms added or updated Examples: Create a new arm >>> new_arm = [{ \"arm_num\" : 2 , \"name\" : \"Arm 2\" }] >>> proj . import_arms ( new_arm ) 1 Source code in redcap/methods/arms.py def import_arms ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , override : Optional [ int ] = 0 , ): \"\"\" Import Arms into the REDCap Project Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded override: 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Arms in the project while importing new Arms. If override=0, then you can only add new Arms or rename existing ones. Returns: Union[int, str]: Number of Arms added or updated Examples: Create a new arm >>> new_arm = [{\"arm_num\": 2, \"name\": \"Arm 2\"}] >>> proj.import_arms(new_arm) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"arm\" , ) payload [ \"action\" ] = \"import\" payload [ \"override\" ] = override return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_arms()"},{"location":"api_reference/data_access_groups/","text":"Data Access Groups REDCap API methods for Project data access groups DataAccessGroups ( Base ) Responsible for all API methods under 'Data Access Groups' in the API Playground Source code in redcap/methods/data_access_groups.py class DataAccessGroups ( Base ): \"\"\"Responsible for all API methods under 'Data Access Groups' in the API Playground\"\"\" def export_dags ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long \"\"\" Export the DAGs of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of DAGs Examples: >>> proj.export_dags() [{'data_access_group_name': 'Test DAG', 'unique_group_name': 'test_dag', 'data_access_group_id': ...}] \"\"\" # pylint:enable=line-too-long payload = self . _initialize_payload ( content = \"dag\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"dag\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_dags ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import DAGs into the REDCap Project Note: DAGs can be renamed by simply changing the group name (data_access_group_name). DAGs can be created by providing group name value while unique group name should be set to blank. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of DAGs added or updated Examples: Create a new data access group >>> new_dag = [{\"data_access_group_name\": \"New DAG\", \"unique_group_name\": \"\"}] >>> proj.import_dags(new_dag) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"dag\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def delete_dags ( self , dags : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete dags from the project. Args: dags: List of dags to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of dags deleted Examples: Create a new data access group >>> new_dag = [{\"data_access_group_name\": \"New DAG\", \"unique_group_name\": \"\"}] >>> proj.import_dags(new_dag) 1 We know that 'New DAG' will automatically be assigned 'new_dag' as it's unique group name >>> proj.delete_dags([\"new_dag\"]) 1 \"\"\" payload = self . _initialize_payload ( content = \"dag\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of dags into dict, and append to payload dags_dict = { f \"dags[ { idx } ]\" : dag for idx , dag in enumerate ( dags )} payload . update ( dags_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def switch_dag ( self , dag : str , ) -> Literal [ \"1\" ]: \"\"\" Allows the current API user to switch (assign/reassign/unassign) their current Data Access Group assignment. The current user must have been assigned to multiple DAGs via the DAG Switcher page in the project Args: dag: The unique group name of the Data Access Group to which you wish to switch Returns: \"1\" if the user successfully switched DAGs Examples: >>> proj.switch_dag(\"test_dag\") # doctest: +SKIP '1' \"\"\" # API docs say that \"1\" is the only valid value payload = self . _initialize_payload ( content = \"dag\" , return_format_type = \"csv\" ) payload [ \"action\" ] = \"switch\" payload [ \"dag\" ] = dag response = cast ( Literal [ \"1\" ], self . _call_api ( payload , return_type = \"str\" )) return response def export_user_dag_assignment ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the User-DAG assignment of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of User-DAGs assignments Examples: >>> proj.export_user_dag_assignment() [{'username': ..., 'redcap_data_access_group': ''}] \"\"\" payload = self . _initialize_payload ( content = \"userDagMapping\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userDagMapping\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_user_dag_assignment ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import User-DAG assignments into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of User-DAGs assignments added or updated Examples: Create a new user >>> new_user = \"pandeharris@gmail.com\" >>> proj.import_users([{\"username\": new_user}]) 1 Add that user to a DAG >>> dag_mapping = [ ... {\"username\": new_user, \"redcap_data_access_group\": \"test_dag\"} ... ] >>> proj.import_user_dag_assignment(dag_mapping) 1 New user-DAG mapping >>> proj.export_user_dag_assignment() [{'username': 'pandeharris@gmail.com', 'redcap_data_access_group': 'test_dag'}, {'username': ..., 'redcap_data_access_group': ''}] Remove the user >>> proj.delete_users([new_user]) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userDagMapping\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server delete_dags ( self , dags , return_format_type = 'json' ) Delete dags from the project. Parameters: Name Type Description Default dags List[str] List of dags to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of dags deleted Examples: Create a new data access group >>> new_dag = [{ \"data_access_group_name\" : \"New DAG\" , \"unique_group_name\" : \"\" }] >>> proj . import_dags ( new_dag ) 1 We know that 'New DAG' will automatically be assigned 'new_dag' as it's unique group name >>> proj . delete_dags ([ \"new_dag\" ]) 1 Source code in redcap/methods/data_access_groups.py def delete_dags ( self , dags : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete dags from the project. Args: dags: List of dags to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of dags deleted Examples: Create a new data access group >>> new_dag = [{\"data_access_group_name\": \"New DAG\", \"unique_group_name\": \"\"}] >>> proj.import_dags(new_dag) 1 We know that 'New DAG' will automatically be assigned 'new_dag' as it's unique group name >>> proj.delete_dags([\"new_dag\"]) 1 \"\"\" payload = self . _initialize_payload ( content = \"dag\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of dags into dict, and append to payload dags_dict = { f \"dags[ { idx } ]\" : dag for idx , dag in enumerate ( dags )} payload . update ( dags_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response export_dags ( self , format_type = 'json' , df_kwargs = None ) Export the DAGs of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of DAGs Examples: >>> proj . export_dags () [{ 'data_access_group_name' : 'Test DAG' , 'unique_group_name' : 'test_dag' , 'data_access_group_id' : ... }] Source code in redcap/methods/data_access_groups.py def export_dags ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long \"\"\" Export the DAGs of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of DAGs Examples: >>> proj.export_dags() [{'data_access_group_name': 'Test DAG', 'unique_group_name': 'test_dag', 'data_access_group_id': ...}] \"\"\" # pylint:enable=line-too-long payload = self . _initialize_payload ( content = \"dag\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"dag\" , format_type = format_type , df_kwargs = df_kwargs , ) export_user_dag_assignment ( self , format_type = 'json' , df_kwargs = None ) Export the User-DAG assignment of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of User-DAGs assignments Examples: >>> proj . export_user_dag_assignment () [{ 'username' : ... , 'redcap_data_access_group' : '' }] Source code in redcap/methods/data_access_groups.py def export_user_dag_assignment ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the User-DAG assignment of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of User-DAGs assignments Examples: >>> proj.export_user_dag_assignment() [{'username': ..., 'redcap_data_access_group': ''}] \"\"\" payload = self . _initialize_payload ( content = \"userDagMapping\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userDagMapping\" , format_type = format_type , df_kwargs = df_kwargs , ) import_dags ( self , to_import , return_format_type = 'json' , import_format = 'json' ) Import DAGs into the REDCap Project !!! note DAGs can be renamed by simply changing the group name (data_access_group_name). DAGs can be created by providing group name value while unique group name should be set to blank. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of DAGs added or updated Examples: Create a new data access group >>> new_dag = [{ \"data_access_group_name\" : \"New DAG\" , \"unique_group_name\" : \"\" }] >>> proj . import_dags ( new_dag ) 1 Source code in redcap/methods/data_access_groups.py def import_dags ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import DAGs into the REDCap Project Note: DAGs can be renamed by simply changing the group name (data_access_group_name). DAGs can be created by providing group name value while unique group name should be set to blank. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of DAGs added or updated Examples: Create a new data access group >>> new_dag = [{\"data_access_group_name\": \"New DAG\", \"unique_group_name\": \"\"}] >>> proj.import_dags(new_dag) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"dag\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response import_user_dag_assignment ( self , to_import , return_format_type = 'json' , import_format = 'json' ) Import User-DAG assignments into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of User-DAGs assignments added or updated Examples: Create a new user >>> new_user = \"pandeharris@gmail.com\" >>> proj . import_users ([{ \"username\" : new_user }]) 1 Add that user to a DAG >>> dag_mapping = [ ... { \"username\" : new_user , \"redcap_data_access_group\" : \"test_dag\" } ... ] >>> proj . import_user_dag_assignment ( dag_mapping ) 1 New user-DAG mapping >>> proj . export_user_dag_assignment () [{ 'username' : 'pandeharris@gmail.com' , 'redcap_data_access_group' : 'test_dag' }, { 'username' : ... , 'redcap_data_access_group' : '' }] Remove the user >>> proj . delete_users ([ new_user ]) 1 Source code in redcap/methods/data_access_groups.py def import_user_dag_assignment ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import User-DAG assignments into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of User-DAGs assignments added or updated Examples: Create a new user >>> new_user = \"pandeharris@gmail.com\" >>> proj.import_users([{\"username\": new_user}]) 1 Add that user to a DAG >>> dag_mapping = [ ... {\"username\": new_user, \"redcap_data_access_group\": \"test_dag\"} ... ] >>> proj.import_user_dag_assignment(dag_mapping) 1 New user-DAG mapping >>> proj.export_user_dag_assignment() [{'username': 'pandeharris@gmail.com', 'redcap_data_access_group': 'test_dag'}, {'username': ..., 'redcap_data_access_group': ''}] Remove the user >>> proj.delete_users([new_user]) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userDagMapping\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response switch_dag ( self , dag ) Allows the current API user to switch (assign/reassign/unassign) their current Data Access Group assignment. The current user must have been assigned to multiple DAGs via the DAG Switcher page in the project Parameters: Name Type Description Default dag str The unique group name of the Data Access Group to which you wish to switch required Returns: Type Description Literal['1'] \"1\" if the user successfully switched DAGs Examples: >>> proj . switch_dag ( \"test_dag\" ) '1' Source code in redcap/methods/data_access_groups.py def switch_dag ( self , dag : str , ) -> Literal [ \"1\" ]: \"\"\" Allows the current API user to switch (assign/reassign/unassign) their current Data Access Group assignment. The current user must have been assigned to multiple DAGs via the DAG Switcher page in the project Args: dag: The unique group name of the Data Access Group to which you wish to switch Returns: \"1\" if the user successfully switched DAGs Examples: >>> proj.switch_dag(\"test_dag\") # doctest: +SKIP '1' \"\"\" # API docs say that \"1\" is the only valid value payload = self . _initialize_payload ( content = \"dag\" , return_format_type = \"csv\" ) payload [ \"action\" ] = \"switch\" payload [ \"dag\" ] = dag response = cast ( Literal [ \"1\" ], self . _call_api ( payload , return_type = \"str\" )) return response","title":"Data Access Groups"},{"location":"api_reference/data_access_groups/#data-access-groups","text":"REDCap API methods for Project data access groups","title":"Data Access Groups"},{"location":"api_reference/data_access_groups/#redcap.methods.data_access_groups.DataAccessGroups","text":"Responsible for all API methods under 'Data Access Groups' in the API Playground Source code in redcap/methods/data_access_groups.py class DataAccessGroups ( Base ): \"\"\"Responsible for all API methods under 'Data Access Groups' in the API Playground\"\"\" def export_dags ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long \"\"\" Export the DAGs of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of DAGs Examples: >>> proj.export_dags() [{'data_access_group_name': 'Test DAG', 'unique_group_name': 'test_dag', 'data_access_group_id': ...}] \"\"\" # pylint:enable=line-too-long payload = self . _initialize_payload ( content = \"dag\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"dag\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_dags ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import DAGs into the REDCap Project Note: DAGs can be renamed by simply changing the group name (data_access_group_name). DAGs can be created by providing group name value while unique group name should be set to blank. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of DAGs added or updated Examples: Create a new data access group >>> new_dag = [{\"data_access_group_name\": \"New DAG\", \"unique_group_name\": \"\"}] >>> proj.import_dags(new_dag) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"dag\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def delete_dags ( self , dags : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete dags from the project. Args: dags: List of dags to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of dags deleted Examples: Create a new data access group >>> new_dag = [{\"data_access_group_name\": \"New DAG\", \"unique_group_name\": \"\"}] >>> proj.import_dags(new_dag) 1 We know that 'New DAG' will automatically be assigned 'new_dag' as it's unique group name >>> proj.delete_dags([\"new_dag\"]) 1 \"\"\" payload = self . _initialize_payload ( content = \"dag\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of dags into dict, and append to payload dags_dict = { f \"dags[ { idx } ]\" : dag for idx , dag in enumerate ( dags )} payload . update ( dags_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def switch_dag ( self , dag : str , ) -> Literal [ \"1\" ]: \"\"\" Allows the current API user to switch (assign/reassign/unassign) their current Data Access Group assignment. The current user must have been assigned to multiple DAGs via the DAG Switcher page in the project Args: dag: The unique group name of the Data Access Group to which you wish to switch Returns: \"1\" if the user successfully switched DAGs Examples: >>> proj.switch_dag(\"test_dag\") # doctest: +SKIP '1' \"\"\" # API docs say that \"1\" is the only valid value payload = self . _initialize_payload ( content = \"dag\" , return_format_type = \"csv\" ) payload [ \"action\" ] = \"switch\" payload [ \"dag\" ] = dag response = cast ( Literal [ \"1\" ], self . _call_api ( payload , return_type = \"str\" )) return response def export_user_dag_assignment ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the User-DAG assignment of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of User-DAGs assignments Examples: >>> proj.export_user_dag_assignment() [{'username': ..., 'redcap_data_access_group': ''}] \"\"\" payload = self . _initialize_payload ( content = \"userDagMapping\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userDagMapping\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_user_dag_assignment ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import User-DAG assignments into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of User-DAGs assignments added or updated Examples: Create a new user >>> new_user = \"pandeharris@gmail.com\" >>> proj.import_users([{\"username\": new_user}]) 1 Add that user to a DAG >>> dag_mapping = [ ... {\"username\": new_user, \"redcap_data_access_group\": \"test_dag\"} ... ] >>> proj.import_user_dag_assignment(dag_mapping) 1 New user-DAG mapping >>> proj.export_user_dag_assignment() [{'username': 'pandeharris@gmail.com', 'redcap_data_access_group': 'test_dag'}, {'username': ..., 'redcap_data_access_group': ''}] Remove the user >>> proj.delete_users([new_user]) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userDagMapping\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"DataAccessGroups"},{"location":"api_reference/data_access_groups/#redcap.methods.data_access_groups.DataAccessGroups.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/data_access_groups/#redcap.methods.data_access_groups.DataAccessGroups.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/data_access_groups/#redcap.methods.data_access_groups.DataAccessGroups.forms","text":"Project form names","title":"forms"},{"location":"api_reference/data_access_groups/#redcap.methods.data_access_groups.DataAccessGroups.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/data_access_groups/#redcap.methods.data_access_groups.DataAccessGroups.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/data_access_groups/#redcap.methods.data_access_groups.DataAccessGroups.token","text":"API token to a project","title":"token"},{"location":"api_reference/data_access_groups/#redcap.methods.data_access_groups.DataAccessGroups.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/data_access_groups/#redcap.methods.data_access_groups.DataAccessGroups.delete_dags","text":"Delete dags from the project. Parameters: Name Type Description Default dags List[str] List of dags to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of dags deleted Examples: Create a new data access group >>> new_dag = [{ \"data_access_group_name\" : \"New DAG\" , \"unique_group_name\" : \"\" }] >>> proj . import_dags ( new_dag ) 1 We know that 'New DAG' will automatically be assigned 'new_dag' as it's unique group name >>> proj . delete_dags ([ \"new_dag\" ]) 1 Source code in redcap/methods/data_access_groups.py def delete_dags ( self , dags : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete dags from the project. Args: dags: List of dags to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of dags deleted Examples: Create a new data access group >>> new_dag = [{\"data_access_group_name\": \"New DAG\", \"unique_group_name\": \"\"}] >>> proj.import_dags(new_dag) 1 We know that 'New DAG' will automatically be assigned 'new_dag' as it's unique group name >>> proj.delete_dags([\"new_dag\"]) 1 \"\"\" payload = self . _initialize_payload ( content = \"dag\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of dags into dict, and append to payload dags_dict = { f \"dags[ { idx } ]\" : dag for idx , dag in enumerate ( dags )} payload . update ( dags_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"delete_dags()"},{"location":"api_reference/data_access_groups/#redcap.methods.data_access_groups.DataAccessGroups.export_dags","text":"Export the DAGs of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of DAGs Examples: >>> proj . export_dags () [{ 'data_access_group_name' : 'Test DAG' , 'unique_group_name' : 'test_dag' , 'data_access_group_id' : ... }] Source code in redcap/methods/data_access_groups.py def export_dags ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long \"\"\" Export the DAGs of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of DAGs Examples: >>> proj.export_dags() [{'data_access_group_name': 'Test DAG', 'unique_group_name': 'test_dag', 'data_access_group_id': ...}] \"\"\" # pylint:enable=line-too-long payload = self . _initialize_payload ( content = \"dag\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"dag\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_dags()"},{"location":"api_reference/data_access_groups/#redcap.methods.data_access_groups.DataAccessGroups.export_user_dag_assignment","text":"Export the User-DAG assignment of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of User-DAGs assignments Examples: >>> proj . export_user_dag_assignment () [{ 'username' : ... , 'redcap_data_access_group' : '' }] Source code in redcap/methods/data_access_groups.py def export_user_dag_assignment ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the User-DAG assignment of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of User-DAGs assignments Examples: >>> proj.export_user_dag_assignment() [{'username': ..., 'redcap_data_access_group': ''}] \"\"\" payload = self . _initialize_payload ( content = \"userDagMapping\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userDagMapping\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_user_dag_assignment()"},{"location":"api_reference/data_access_groups/#redcap.methods.data_access_groups.DataAccessGroups.import_dags","text":"Import DAGs into the REDCap Project !!! note DAGs can be renamed by simply changing the group name (data_access_group_name). DAGs can be created by providing group name value while unique group name should be set to blank. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of DAGs added or updated Examples: Create a new data access group >>> new_dag = [{ \"data_access_group_name\" : \"New DAG\" , \"unique_group_name\" : \"\" }] >>> proj . import_dags ( new_dag ) 1 Source code in redcap/methods/data_access_groups.py def import_dags ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import DAGs into the REDCap Project Note: DAGs can be renamed by simply changing the group name (data_access_group_name). DAGs can be created by providing group name value while unique group name should be set to blank. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of DAGs added or updated Examples: Create a new data access group >>> new_dag = [{\"data_access_group_name\": \"New DAG\", \"unique_group_name\": \"\"}] >>> proj.import_dags(new_dag) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"dag\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_dags()"},{"location":"api_reference/data_access_groups/#redcap.methods.data_access_groups.DataAccessGroups.import_user_dag_assignment","text":"Import User-DAG assignments into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of User-DAGs assignments added or updated Examples: Create a new user >>> new_user = \"pandeharris@gmail.com\" >>> proj . import_users ([{ \"username\" : new_user }]) 1 Add that user to a DAG >>> dag_mapping = [ ... { \"username\" : new_user , \"redcap_data_access_group\" : \"test_dag\" } ... ] >>> proj . import_user_dag_assignment ( dag_mapping ) 1 New user-DAG mapping >>> proj . export_user_dag_assignment () [{ 'username' : 'pandeharris@gmail.com' , 'redcap_data_access_group' : 'test_dag' }, { 'username' : ... , 'redcap_data_access_group' : '' }] Remove the user >>> proj . delete_users ([ new_user ]) 1 Source code in redcap/methods/data_access_groups.py def import_user_dag_assignment ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import User-DAG assignments into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of User-DAGs assignments added or updated Examples: Create a new user >>> new_user = \"pandeharris@gmail.com\" >>> proj.import_users([{\"username\": new_user}]) 1 Add that user to a DAG >>> dag_mapping = [ ... {\"username\": new_user, \"redcap_data_access_group\": \"test_dag\"} ... ] >>> proj.import_user_dag_assignment(dag_mapping) 1 New user-DAG mapping >>> proj.export_user_dag_assignment() [{'username': 'pandeharris@gmail.com', 'redcap_data_access_group': 'test_dag'}, {'username': ..., 'redcap_data_access_group': ''}] Remove the user >>> proj.delete_users([new_user]) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userDagMapping\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_user_dag_assignment()"},{"location":"api_reference/data_access_groups/#redcap.methods.data_access_groups.DataAccessGroups.switch_dag","text":"Allows the current API user to switch (assign/reassign/unassign) their current Data Access Group assignment. The current user must have been assigned to multiple DAGs via the DAG Switcher page in the project Parameters: Name Type Description Default dag str The unique group name of the Data Access Group to which you wish to switch required Returns: Type Description Literal['1'] \"1\" if the user successfully switched DAGs Examples: >>> proj . switch_dag ( \"test_dag\" ) '1' Source code in redcap/methods/data_access_groups.py def switch_dag ( self , dag : str , ) -> Literal [ \"1\" ]: \"\"\" Allows the current API user to switch (assign/reassign/unassign) their current Data Access Group assignment. The current user must have been assigned to multiple DAGs via the DAG Switcher page in the project Args: dag: The unique group name of the Data Access Group to which you wish to switch Returns: \"1\" if the user successfully switched DAGs Examples: >>> proj.switch_dag(\"test_dag\") # doctest: +SKIP '1' \"\"\" # API docs say that \"1\" is the only valid value payload = self . _initialize_payload ( content = \"dag\" , return_format_type = \"csv\" ) payload [ \"action\" ] = \"switch\" payload [ \"dag\" ] = dag response = cast ( Literal [ \"1\" ], self . _call_api ( payload , return_type = \"str\" )) return response","title":"switch_dag()"},{"location":"api_reference/events/","text":"Events REDCap API methods for Project events Events ( Base ) Responsible for all API methods under 'Events' in the API Playground Source code in redcap/methods/events.py class Events ( Base ): \"\"\"Responsible for all API methods under 'Events' in the API Playground\"\"\" def export_events ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , ): \"\"\" Export the Events of the Project Note: This only works for longitudinal projects. Args: format_type: Response return format arms: An array of arm numbers that you wish to pull events for (by default, all events are pulled) Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Events Examples: >>> proj.export_events() [{'event_name': 'Event 1', 'arm_num': 1, 'unique_event_name': 'event_1_arm_1', 'custom_event_label': '', 'event_id': ...}, {'event_name': 'Event 2', ...}] \"\"\" payload = self . _initialize_payload ( content = \"event\" , format_type = format_type ) if arms : # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"event\" , format_type = format_type , ) def import_events ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , override : Optional [ int ] = 0 , ): \"\"\" Import Events into the REDCap Project Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded override: 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Events in the project while importing new Events. If override=0, then you can only add new Events or rename existing ones. Returns: Union[int, str]: Number of Events added or updated Examples: Create a new event >>> new_event = [{\"event_name\": \"Event 2\", \"arm_num\": \"1\"}] >>> proj.import_events(new_event) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"event\" , ) payload [ \"action\" ] = \"import\" payload [ \"override\" ] = override return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def delete_events ( self , events : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete Events from the Project Note: Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an event will automatically delete any records/data that have been collected under that event (this is non-reversible data loss). This only works for longitudinal projects. Args: events: List of unique event names to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of events deleted Examples: Create a new event >>> new_event = [{\"event_name\": \"Event 2\", \"arm_num\": \"1\"}] >>> proj.import_events(new_event) 1 Delete the new event >>> proj.delete_events([\"event_2_arm_1\"]) 1 \"\"\" payload = self . _initialize_payload ( content = \"event\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of events into dict, and append to payload events_dict = { f \"events[ { idx } ]\" : event for idx , event in enumerate ( events )} payload . update ( events_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server delete_events ( self , events , return_format_type = 'json' ) Delete Events from the Project !!! note Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an event will automatically delete any records/data that have been collected under that event (this is non-reversible data loss). This only works for longitudinal projects. Parameters: Name Type Description Default events List[str] List of unique event names to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of events deleted Examples: Create a new event >>> new_event = [{ \"event_name\" : \"Event 2\" , \"arm_num\" : \"1\" }] >>> proj . import_events ( new_event ) 1 Delete the new event >>> proj . delete_events ([ \"event_2_arm_1\" ]) 1 Source code in redcap/methods/events.py def delete_events ( self , events : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete Events from the Project Note: Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an event will automatically delete any records/data that have been collected under that event (this is non-reversible data loss). This only works for longitudinal projects. Args: events: List of unique event names to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of events deleted Examples: Create a new event >>> new_event = [{\"event_name\": \"Event 2\", \"arm_num\": \"1\"}] >>> proj.import_events(new_event) 1 Delete the new event >>> proj.delete_events([\"event_2_arm_1\"]) 1 \"\"\" payload = self . _initialize_payload ( content = \"event\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of events into dict, and append to payload events_dict = { f \"events[ { idx } ]\" : event for idx , event in enumerate ( events )} payload . update ( events_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response export_events ( self , format_type = 'json' , arms = None ) Export the Events of the Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' arms Optional[List[str]] An array of arm numbers that you wish to pull events for (by default, all events are pulled) None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of Events Examples: >>> proj . export_events () [{ 'event_name' : 'Event 1' , 'arm_num' : 1 , 'unique_event_name' : 'event_1_arm_1' , 'custom_event_label' : '' , 'event_id' : ... }, { 'event_name' : 'Event 2' , ... }] Source code in redcap/methods/events.py def export_events ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , ): \"\"\" Export the Events of the Project Note: This only works for longitudinal projects. Args: format_type: Response return format arms: An array of arm numbers that you wish to pull events for (by default, all events are pulled) Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Events Examples: >>> proj.export_events() [{'event_name': 'Event 1', 'arm_num': 1, 'unique_event_name': 'event_1_arm_1', 'custom_event_label': '', 'event_id': ...}, {'event_name': 'Event 2', ...}] \"\"\" payload = self . _initialize_payload ( content = \"event\" , format_type = format_type ) if arms : # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"event\" , format_type = format_type , ) import_events ( self , to_import , return_format_type = 'json' , import_format = 'json' , override = 0 ) Import Events into the REDCap Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' override Optional[int] 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Events in the project while importing new Events. If override=0, then you can only add new Events or rename existing ones. 0 Returns: Type Description Union[int, str] Number of Events added or updated Examples: Create a new event >>> new_event = [{ \"event_name\" : \"Event 2\" , \"arm_num\" : \"1\" }] >>> proj . import_events ( new_event ) 1 Source code in redcap/methods/events.py def import_events ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , override : Optional [ int ] = 0 , ): \"\"\" Import Events into the REDCap Project Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded override: 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Events in the project while importing new Events. If override=0, then you can only add new Events or rename existing ones. Returns: Union[int, str]: Number of Events added or updated Examples: Create a new event >>> new_event = [{\"event_name\": \"Event 2\", \"arm_num\": \"1\"}] >>> proj.import_events(new_event) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"event\" , ) payload [ \"action\" ] = \"import\" payload [ \"override\" ] = override return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"Events"},{"location":"api_reference/events/#events","text":"REDCap API methods for Project events","title":"Events"},{"location":"api_reference/events/#redcap.methods.events.Events","text":"Responsible for all API methods under 'Events' in the API Playground Source code in redcap/methods/events.py class Events ( Base ): \"\"\"Responsible for all API methods under 'Events' in the API Playground\"\"\" def export_events ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , ): \"\"\" Export the Events of the Project Note: This only works for longitudinal projects. Args: format_type: Response return format arms: An array of arm numbers that you wish to pull events for (by default, all events are pulled) Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Events Examples: >>> proj.export_events() [{'event_name': 'Event 1', 'arm_num': 1, 'unique_event_name': 'event_1_arm_1', 'custom_event_label': '', 'event_id': ...}, {'event_name': 'Event 2', ...}] \"\"\" payload = self . _initialize_payload ( content = \"event\" , format_type = format_type ) if arms : # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"event\" , format_type = format_type , ) def import_events ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , override : Optional [ int ] = 0 , ): \"\"\" Import Events into the REDCap Project Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded override: 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Events in the project while importing new Events. If override=0, then you can only add new Events or rename existing ones. Returns: Union[int, str]: Number of Events added or updated Examples: Create a new event >>> new_event = [{\"event_name\": \"Event 2\", \"arm_num\": \"1\"}] >>> proj.import_events(new_event) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"event\" , ) payload [ \"action\" ] = \"import\" payload [ \"override\" ] = override return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def delete_events ( self , events : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete Events from the Project Note: Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an event will automatically delete any records/data that have been collected under that event (this is non-reversible data loss). This only works for longitudinal projects. Args: events: List of unique event names to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of events deleted Examples: Create a new event >>> new_event = [{\"event_name\": \"Event 2\", \"arm_num\": \"1\"}] >>> proj.import_events(new_event) 1 Delete the new event >>> proj.delete_events([\"event_2_arm_1\"]) 1 \"\"\" payload = self . _initialize_payload ( content = \"event\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of events into dict, and append to payload events_dict = { f \"events[ { idx } ]\" : event for idx , event in enumerate ( events )} payload . update ( events_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"Events"},{"location":"api_reference/events/#redcap.methods.events.Events.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/events/#redcap.methods.events.Events.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/events/#redcap.methods.events.Events.forms","text":"Project form names","title":"forms"},{"location":"api_reference/events/#redcap.methods.events.Events.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/events/#redcap.methods.events.Events.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/events/#redcap.methods.events.Events.token","text":"API token to a project","title":"token"},{"location":"api_reference/events/#redcap.methods.events.Events.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/events/#redcap.methods.events.Events.delete_events","text":"Delete Events from the Project !!! note Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an event will automatically delete any records/data that have been collected under that event (this is non-reversible data loss). This only works for longitudinal projects. Parameters: Name Type Description Default events List[str] List of unique event names to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of events deleted Examples: Create a new event >>> new_event = [{ \"event_name\" : \"Event 2\" , \"arm_num\" : \"1\" }] >>> proj . import_events ( new_event ) 1 Delete the new event >>> proj . delete_events ([ \"event_2_arm_1\" ]) 1 Source code in redcap/methods/events.py def delete_events ( self , events : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete Events from the Project Note: Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an event will automatically delete any records/data that have been collected under that event (this is non-reversible data loss). This only works for longitudinal projects. Args: events: List of unique event names to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of events deleted Examples: Create a new event >>> new_event = [{\"event_name\": \"Event 2\", \"arm_num\": \"1\"}] >>> proj.import_events(new_event) 1 Delete the new event >>> proj.delete_events([\"event_2_arm_1\"]) 1 \"\"\" payload = self . _initialize_payload ( content = \"event\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of events into dict, and append to payload events_dict = { f \"events[ { idx } ]\" : event for idx , event in enumerate ( events )} payload . update ( events_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"delete_events()"},{"location":"api_reference/events/#redcap.methods.events.Events.export_events","text":"Export the Events of the Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' arms Optional[List[str]] An array of arm numbers that you wish to pull events for (by default, all events are pulled) None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of Events Examples: >>> proj . export_events () [{ 'event_name' : 'Event 1' , 'arm_num' : 1 , 'unique_event_name' : 'event_1_arm_1' , 'custom_event_label' : '' , 'event_id' : ... }, { 'event_name' : 'Event 2' , ... }] Source code in redcap/methods/events.py def export_events ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , ): \"\"\" Export the Events of the Project Note: This only works for longitudinal projects. Args: format_type: Response return format arms: An array of arm numbers that you wish to pull events for (by default, all events are pulled) Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Events Examples: >>> proj.export_events() [{'event_name': 'Event 1', 'arm_num': 1, 'unique_event_name': 'event_1_arm_1', 'custom_event_label': '', 'event_id': ...}, {'event_name': 'Event 2', ...}] \"\"\" payload = self . _initialize_payload ( content = \"event\" , format_type = format_type ) if arms : # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"event\" , format_type = format_type , )","title":"export_events()"},{"location":"api_reference/events/#redcap.methods.events.Events.import_events","text":"Import Events into the REDCap Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' override Optional[int] 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Events in the project while importing new Events. If override=0, then you can only add new Events or rename existing ones. 0 Returns: Type Description Union[int, str] Number of Events added or updated Examples: Create a new event >>> new_event = [{ \"event_name\" : \"Event 2\" , \"arm_num\" : \"1\" }] >>> proj . import_events ( new_event ) 1 Source code in redcap/methods/events.py def import_events ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , override : Optional [ int ] = 0 , ): \"\"\" Import Events into the REDCap Project Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded override: 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Events in the project while importing new Events. If override=0, then you can only add new Events or rename existing ones. Returns: Union[int, str]: Number of Events added or updated Examples: Create a new event >>> new_event = [{\"event_name\": \"Event 2\", \"arm_num\": \"1\"}] >>> proj.import_events(new_event) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"event\" , ) payload [ \"action\" ] = \"import\" payload [ \"override\" ] = override return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_events()"},{"location":"api_reference/field_names/","text":"Field Names REDCap API methods for Project field names FieldNames ( Base ) Responsible for all API methods under 'Field Names' in the API Playground Source code in redcap/methods/field_names.py class FieldNames ( Base ): \"\"\"Responsible for all API methods under 'Field Names' in the API Playground\"\"\" def export_field_names ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , field : Optional [ str ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long \"\"\" Export the project's export field names Args: format_type: Return the metadata in native objects, csv or xml. `'df'` will return a `pandas.DataFrame` field: Limit exported field name to this field (only single field supported). When not provided, all fields returned df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. by default `{'index_col': 'original_field_name'}` Returns: Union[str, List[Dict[str, Any]], \"pd.DataFrame\"]: Metadata structure for the project. Examples: >>> proj.export_field_names() [{'original_field_name': 'record_id', 'choice_value': '', 'export_field_name': 'record_id'}, {'original_field_name': 'field_1', 'choice_value': '', 'export_field_name': 'field_1'}, {'original_field_name': 'checkbox_field', 'choice_value': '1', 'export_field_name': 'checkbox_field___1'}, {'original_field_name': 'checkbox_field', 'choice_value': '2', 'export_field_name': 'checkbox_field___2'}, {'original_field_name': 'form_1_complete', 'choice_value': '', 'export_field_name': 'form_1_complete'}] \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"exportFieldNames\" , format_type = format_type ) if field : payload [ \"field\" ] = field return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"exportFieldNames\" , format_type = format_type , df_kwargs = df_kwargs , ) def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server export_field_names ( self , format_type = 'json' , field = None , df_kwargs = None ) Export the project's export field names Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the metadata in native objects, csv or xml. 'df' will return a pandas.DataFrame 'json' field Optional[str] Limit exported field name to this field (only single field supported). When not provided, all fields returned None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. by default {'index_col': 'original_field_name'} None Returns: Type Description Union[str, List[Dict[str, Any]], \"pd.DataFrame\"] Metadata structure for the project. Examples: >>> proj . export_field_names () [{ 'original_field_name' : 'record_id' , 'choice_value' : '' , 'export_field_name' : 'record_id' }, { 'original_field_name' : 'field_1' , 'choice_value' : '' , 'export_field_name' : 'field_1' }, { 'original_field_name' : 'checkbox_field' , 'choice_value' : '1' , 'export_field_name' : 'checkbox_field___1' }, { 'original_field_name' : 'checkbox_field' , 'choice_value' : '2' , 'export_field_name' : 'checkbox_field___2' }, { 'original_field_name' : 'form_1_complete' , 'choice_value' : '' , 'export_field_name' : 'form_1_complete' }] Source code in redcap/methods/field_names.py def export_field_names ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , field : Optional [ str ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long \"\"\" Export the project's export field names Args: format_type: Return the metadata in native objects, csv or xml. `'df'` will return a `pandas.DataFrame` field: Limit exported field name to this field (only single field supported). When not provided, all fields returned df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. by default `{'index_col': 'original_field_name'}` Returns: Union[str, List[Dict[str, Any]], \"pd.DataFrame\"]: Metadata structure for the project. Examples: >>> proj.export_field_names() [{'original_field_name': 'record_id', 'choice_value': '', 'export_field_name': 'record_id'}, {'original_field_name': 'field_1', 'choice_value': '', 'export_field_name': 'field_1'}, {'original_field_name': 'checkbox_field', 'choice_value': '1', 'export_field_name': 'checkbox_field___1'}, {'original_field_name': 'checkbox_field', 'choice_value': '2', 'export_field_name': 'checkbox_field___2'}, {'original_field_name': 'form_1_complete', 'choice_value': '', 'export_field_name': 'form_1_complete'}] \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"exportFieldNames\" , format_type = format_type ) if field : payload [ \"field\" ] = field return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"exportFieldNames\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"Field Names"},{"location":"api_reference/field_names/#field-names","text":"REDCap API methods for Project field names","title":"Field Names"},{"location":"api_reference/field_names/#redcap.methods.field_names.FieldNames","text":"Responsible for all API methods under 'Field Names' in the API Playground Source code in redcap/methods/field_names.py class FieldNames ( Base ): \"\"\"Responsible for all API methods under 'Field Names' in the API Playground\"\"\" def export_field_names ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , field : Optional [ str ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long \"\"\" Export the project's export field names Args: format_type: Return the metadata in native objects, csv or xml. `'df'` will return a `pandas.DataFrame` field: Limit exported field name to this field (only single field supported). When not provided, all fields returned df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. by default `{'index_col': 'original_field_name'}` Returns: Union[str, List[Dict[str, Any]], \"pd.DataFrame\"]: Metadata structure for the project. Examples: >>> proj.export_field_names() [{'original_field_name': 'record_id', 'choice_value': '', 'export_field_name': 'record_id'}, {'original_field_name': 'field_1', 'choice_value': '', 'export_field_name': 'field_1'}, {'original_field_name': 'checkbox_field', 'choice_value': '1', 'export_field_name': 'checkbox_field___1'}, {'original_field_name': 'checkbox_field', 'choice_value': '2', 'export_field_name': 'checkbox_field___2'}, {'original_field_name': 'form_1_complete', 'choice_value': '', 'export_field_name': 'form_1_complete'}] \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"exportFieldNames\" , format_type = format_type ) if field : payload [ \"field\" ] = field return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"exportFieldNames\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"FieldNames"},{"location":"api_reference/field_names/#redcap.methods.field_names.FieldNames.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/field_names/#redcap.methods.field_names.FieldNames.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/field_names/#redcap.methods.field_names.FieldNames.forms","text":"Project form names","title":"forms"},{"location":"api_reference/field_names/#redcap.methods.field_names.FieldNames.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/field_names/#redcap.methods.field_names.FieldNames.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/field_names/#redcap.methods.field_names.FieldNames.token","text":"API token to a project","title":"token"},{"location":"api_reference/field_names/#redcap.methods.field_names.FieldNames.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/field_names/#redcap.methods.field_names.FieldNames.export_field_names","text":"Export the project's export field names Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the metadata in native objects, csv or xml. 'df' will return a pandas.DataFrame 'json' field Optional[str] Limit exported field name to this field (only single field supported). When not provided, all fields returned None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. by default {'index_col': 'original_field_name'} None Returns: Type Description Union[str, List[Dict[str, Any]], \"pd.DataFrame\"] Metadata structure for the project. Examples: >>> proj . export_field_names () [{ 'original_field_name' : 'record_id' , 'choice_value' : '' , 'export_field_name' : 'record_id' }, { 'original_field_name' : 'field_1' , 'choice_value' : '' , 'export_field_name' : 'field_1' }, { 'original_field_name' : 'checkbox_field' , 'choice_value' : '1' , 'export_field_name' : 'checkbox_field___1' }, { 'original_field_name' : 'checkbox_field' , 'choice_value' : '2' , 'export_field_name' : 'checkbox_field___2' }, { 'original_field_name' : 'form_1_complete' , 'choice_value' : '' , 'export_field_name' : 'form_1_complete' }] Source code in redcap/methods/field_names.py def export_field_names ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , field : Optional [ str ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long \"\"\" Export the project's export field names Args: format_type: Return the metadata in native objects, csv or xml. `'df'` will return a `pandas.DataFrame` field: Limit exported field name to this field (only single field supported). When not provided, all fields returned df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. by default `{'index_col': 'original_field_name'}` Returns: Union[str, List[Dict[str, Any]], \"pd.DataFrame\"]: Metadata structure for the project. Examples: >>> proj.export_field_names() [{'original_field_name': 'record_id', 'choice_value': '', 'export_field_name': 'record_id'}, {'original_field_name': 'field_1', 'choice_value': '', 'export_field_name': 'field_1'}, {'original_field_name': 'checkbox_field', 'choice_value': '1', 'export_field_name': 'checkbox_field___1'}, {'original_field_name': 'checkbox_field', 'choice_value': '2', 'export_field_name': 'checkbox_field___2'}, {'original_field_name': 'form_1_complete', 'choice_value': '', 'export_field_name': 'form_1_complete'}] \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"exportFieldNames\" , format_type = format_type ) if field : payload [ \"field\" ] = field return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"exportFieldNames\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_field_names()"},{"location":"api_reference/file_repository/","text":"File Repository REDCap API methods for Project file repository FileRepository ( Base ) Responsible for all API methods under 'File Repository' in the API Playground Source code in redcap/methods/file_repository.py class FileRepository ( Base ): \"\"\"Responsible for all API methods under 'File Repository' in the API Playground\"\"\" def create_folder_in_repository ( self , name : str , folder_id : Optional [ int ] = None , dag_id : Optional [ int ] = None , role_id : Optional [ int ] = None , format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Create a New Folder in the File Repository Args: name: The desired name of the folder to be created (max length = 150 characters) folder_id: The folder_id of a specific folder in the File Repository for which you wish to create this sub-folder. If none is provided, the folder will be created in the top-level directory of the File Repository. dag_id: The dag_id of the DAG (Data Access Group) to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all DAGs and users in no DAGs. role_id: The role_id of the User Role to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all User Roles and users in no User Roles. format_type: Return the metadata in native objects, csv or xml. return_format_type: Response format. By default, response will be json-decoded. Returns: Union[str, List[Dict[str, Any]]]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.create_folder_in_repository(name=\"New Folder\") [{'folder_id': ...}] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" , format_type = format_type , return_format_type = return_format_type , ) payload [ \"action\" ] = \"createFolder\" payload [ \"name\" ] = name if folder_id : payload [ \"folder_id\" ] = folder_id if dag_id : payload [ \"dag_id\" ] = dag_id if role_id : payload [ \"role_id\" ] = role_id return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) return cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) def export_file_repository ( self , folder_id : Optional [ int ] = None , format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Export of list of files/folders in the File Repository Only exports the top-level of files/folders. To see which files are contained within a folder, use the `folder_id` parameter Args: folder_id: The folder_id of a specific folder in the File Repository for which you wish to search for files/folders. If none is provided, the search will be conducted in the top-level directory of the File Repository. format_type: Return the metadata in native objects, csv or xml. return_format_type: Response format. By default, response will be json-decoded. Returns: Union[str, List[Dict[str, Any]]]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.export_file_repository() [{'folder_id': ..., 'name': 'New Folder'}, ...] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" , format_type = format_type , return_format_type = return_format_type , ) payload [ \"action\" ] = \"list\" if folder_id : payload [ \"folder_id\" ] = folder_id return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) return cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) def export_file_from_repository ( self , doc_id : int , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ) -> FileMap : \"\"\" Export the contents of a file stored in the File Repository Args: doc_id: The doc_id of the file in the File Repository return_format_type: Response format. By default, response will be json-decoded. Returns: Content of the file and content-type dictionary Examples: >>> file_dir = proj.export_file_repository() >>> text_file = [file for file in file_dir if file[\"name\"] == \"test.txt\"].pop() >>> proj.export_file_from_repository(doc_id=text_file[\"doc_id\"]) (b'hello', {'name': 'test.txt', 'charset': 'UTF-8'}) \"\"\" payload = self . _initialize_payload ( content = \"fileRepository\" , return_format_type = return_format_type ) # there's no format field in this call payload [ \"action\" ] = \"export\" payload [ \"doc_id\" ] = doc_id content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map def import_file_into_repository ( self , file_name : str , file_object : IO , folder_id : Optional [ int ] = None , ) -> EmptyJson : \"\"\" Import the contents of a file represented by file_object into the file repository Args: file_name: File name visible in REDCap UI file_object: File object as returned by `open` folder_id: The folder_id of a specific folder in the File Repository where you wish to store the file. If none is provided, the file will be stored in the top-level directory of the File Repository. Returns: Empty JSON object Examples: >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file_into_repository( ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... ) [{}] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" ) payload [ \"action\" ] = \"import\" if folder_id : payload [ \"folder_id\" ] = folder_id file_upload_dict : FileUpload = { \"file\" : ( file_name , file_object )} return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" , file = file_upload_dict ), ) def delete_file_from_repository ( self , doc_id : int , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ) -> EmptyJson : # pylint: disable=line-too-long \"\"\" Delete a File from the File Repository Once deleted, the file will remain in the Recycle Bin folder for up to 30 days. Args: doc_id: The doc_id of the file in the File Repository return_format_type: Response format. By default, response will be json-decoded. Returns: Empty JSON object Examples: >>> file_dir = proj.export_file_repository() >>> test_folder = [folder for folder in file_dir if folder[\"name\"] == \"test\"].pop() >>> test_dir = proj.export_file_repository(folder_id=test_folder[\"folder_id\"]) >>> test_file = [file for file in test_dir if file[\"name\"] == \"test_in_folder.txt\"].pop() >>> proj.delete_file_from_repository(doc_id=test_file[\"doc_id\"]) [{}] \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"fileRepository\" , return_format_type = return_format_type ) # there's no format field in this call payload [ \"action\" ] = \"delete\" payload [ \"doc_id\" ] = doc_id return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" ) ) def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server create_folder_in_repository ( self , name , folder_id = None , dag_id = None , role_id = None , format_type = 'json' , return_format_type = 'json' ) Create a New Folder in the File Repository Parameters: Name Type Description Default name str The desired name of the folder to be created (max length = 150 characters) required folder_id Optional[int] The folder_id of a specific folder in the File Repository for which you wish to create this sub-folder. If none is provided, the folder will be created in the top-level directory of the File Repository. None dag_id Optional[int] The dag_id of the DAG (Data Access Group) to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all DAGs and users in no DAGs. None role_id Optional[int] The role_id of the User Role to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all User Roles and users in no User Roles. None format_type Literal['json', 'csv', 'xml'] Return the metadata in native objects, csv or xml. 'json' return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[str, List[Dict[str, Any]]] List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj . create_folder_in_repository ( name = \"New Folder\" ) [{ 'folder_id' : ... }] Source code in redcap/methods/file_repository.py def create_folder_in_repository ( self , name : str , folder_id : Optional [ int ] = None , dag_id : Optional [ int ] = None , role_id : Optional [ int ] = None , format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Create a New Folder in the File Repository Args: name: The desired name of the folder to be created (max length = 150 characters) folder_id: The folder_id of a specific folder in the File Repository for which you wish to create this sub-folder. If none is provided, the folder will be created in the top-level directory of the File Repository. dag_id: The dag_id of the DAG (Data Access Group) to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all DAGs and users in no DAGs. role_id: The role_id of the User Role to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all User Roles and users in no User Roles. format_type: Return the metadata in native objects, csv or xml. return_format_type: Response format. By default, response will be json-decoded. Returns: Union[str, List[Dict[str, Any]]]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.create_folder_in_repository(name=\"New Folder\") [{'folder_id': ...}] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" , format_type = format_type , return_format_type = return_format_type , ) payload [ \"action\" ] = \"createFolder\" payload [ \"name\" ] = name if folder_id : payload [ \"folder_id\" ] = folder_id if dag_id : payload [ \"dag_id\" ] = dag_id if role_id : payload [ \"role_id\" ] = role_id return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) return cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) delete_file_from_repository ( self , doc_id , return_format_type = 'json' ) Delete a File from the File Repository Once deleted, the file will remain in the Recycle Bin folder for up to 30 days. Parameters: Name Type Description Default doc_id int The doc_id of the file in the File Repository required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description List[dict] Empty JSON object Examples: >>> file_dir = proj . export_file_repository () >>> test_folder = [ folder for folder in file_dir if folder [ \"name\" ] == \"test\" ] . pop () >>> test_dir = proj . export_file_repository ( folder_id = test_folder [ \"folder_id\" ]) >>> test_file = [ file for file in test_dir if file [ \"name\" ] == \"test_in_folder.txt\" ] . pop () >>> proj . delete_file_from_repository ( doc_id = test_file [ \"doc_id\" ]) [{}] Source code in redcap/methods/file_repository.py def delete_file_from_repository ( self , doc_id : int , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ) -> EmptyJson : # pylint: disable=line-too-long \"\"\" Delete a File from the File Repository Once deleted, the file will remain in the Recycle Bin folder for up to 30 days. Args: doc_id: The doc_id of the file in the File Repository return_format_type: Response format. By default, response will be json-decoded. Returns: Empty JSON object Examples: >>> file_dir = proj.export_file_repository() >>> test_folder = [folder for folder in file_dir if folder[\"name\"] == \"test\"].pop() >>> test_dir = proj.export_file_repository(folder_id=test_folder[\"folder_id\"]) >>> test_file = [file for file in test_dir if file[\"name\"] == \"test_in_folder.txt\"].pop() >>> proj.delete_file_from_repository(doc_id=test_file[\"doc_id\"]) [{}] \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"fileRepository\" , return_format_type = return_format_type ) # there's no format field in this call payload [ \"action\" ] = \"delete\" payload [ \"doc_id\" ] = doc_id return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" ) ) export_file_from_repository ( self , doc_id , return_format_type = 'json' ) Export the contents of a file stored in the File Repository Parameters: Name Type Description Default doc_id int The doc_id of the file in the File Repository required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Tuple[bytes, dict] Content of the file and content-type dictionary Examples: >>> file_dir = proj . export_file_repository () >>> text_file = [ file for file in file_dir if file [ \"name\" ] == \"test.txt\" ] . pop () >>> proj . export_file_from_repository ( doc_id = text_file [ \"doc_id\" ]) ( b 'hello' , { 'name' : 'test.txt' , 'charset' : 'UTF-8' }) Source code in redcap/methods/file_repository.py def export_file_from_repository ( self , doc_id : int , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ) -> FileMap : \"\"\" Export the contents of a file stored in the File Repository Args: doc_id: The doc_id of the file in the File Repository return_format_type: Response format. By default, response will be json-decoded. Returns: Content of the file and content-type dictionary Examples: >>> file_dir = proj.export_file_repository() >>> text_file = [file for file in file_dir if file[\"name\"] == \"test.txt\"].pop() >>> proj.export_file_from_repository(doc_id=text_file[\"doc_id\"]) (b'hello', {'name': 'test.txt', 'charset': 'UTF-8'}) \"\"\" payload = self . _initialize_payload ( content = \"fileRepository\" , return_format_type = return_format_type ) # there's no format field in this call payload [ \"action\" ] = \"export\" payload [ \"doc_id\" ] = doc_id content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map export_file_repository ( self , folder_id = None , format_type = 'json' , return_format_type = 'json' ) Export of list of files/folders in the File Repository Only exports the top-level of files/folders. To see which files are contained within a folder, use the folder_id parameter Parameters: Name Type Description Default folder_id Optional[int] The folder_id of a specific folder in the File Repository for which you wish to search for files/folders. If none is provided, the search will be conducted in the top-level directory of the File Repository. None format_type Literal['json', 'csv', 'xml'] Return the metadata in native objects, csv or xml. 'json' return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[str, List[Dict[str, Any]]] List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj . export_file_repository () [{ 'folder_id' : ... , 'name' : 'New Folder' }, ... ] Source code in redcap/methods/file_repository.py def export_file_repository ( self , folder_id : Optional [ int ] = None , format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Export of list of files/folders in the File Repository Only exports the top-level of files/folders. To see which files are contained within a folder, use the `folder_id` parameter Args: folder_id: The folder_id of a specific folder in the File Repository for which you wish to search for files/folders. If none is provided, the search will be conducted in the top-level directory of the File Repository. format_type: Return the metadata in native objects, csv or xml. return_format_type: Response format. By default, response will be json-decoded. Returns: Union[str, List[Dict[str, Any]]]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.export_file_repository() [{'folder_id': ..., 'name': 'New Folder'}, ...] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" , format_type = format_type , return_format_type = return_format_type , ) payload [ \"action\" ] = \"list\" if folder_id : payload [ \"folder_id\" ] = folder_id return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) return cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) import_file_into_repository ( self , file_name , file_object , folder_id = None ) Import the contents of a file represented by file_object into the file repository Parameters: Name Type Description Default file_name str File name visible in REDCap UI required file_object IO File object as returned by open required folder_id Optional[int] The folder_id of a specific folder in the File Repository where you wish to store the file. If none is provided, the file will be stored in the top-level directory of the File Repository. None Returns: Type Description List[dict] Empty JSON object Examples: >>> import tempfile >>> tmp_file = tempfile . TemporaryFile () >>> proj . import_file_into_repository ( ... file_name = \"myupload.txt\" , ... file_object = tmp_file , ... ) [{}] Source code in redcap/methods/file_repository.py def import_file_into_repository ( self , file_name : str , file_object : IO , folder_id : Optional [ int ] = None , ) -> EmptyJson : \"\"\" Import the contents of a file represented by file_object into the file repository Args: file_name: File name visible in REDCap UI file_object: File object as returned by `open` folder_id: The folder_id of a specific folder in the File Repository where you wish to store the file. If none is provided, the file will be stored in the top-level directory of the File Repository. Returns: Empty JSON object Examples: >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file_into_repository( ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... ) [{}] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" ) payload [ \"action\" ] = \"import\" if folder_id : payload [ \"folder_id\" ] = folder_id file_upload_dict : FileUpload = { \"file\" : ( file_name , file_object )} return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" , file = file_upload_dict ), )","title":"File Repository"},{"location":"api_reference/file_repository/#file-repository","text":"REDCap API methods for Project file repository","title":"File Repository"},{"location":"api_reference/file_repository/#redcap.methods.file_repository.FileRepository","text":"Responsible for all API methods under 'File Repository' in the API Playground Source code in redcap/methods/file_repository.py class FileRepository ( Base ): \"\"\"Responsible for all API methods under 'File Repository' in the API Playground\"\"\" def create_folder_in_repository ( self , name : str , folder_id : Optional [ int ] = None , dag_id : Optional [ int ] = None , role_id : Optional [ int ] = None , format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Create a New Folder in the File Repository Args: name: The desired name of the folder to be created (max length = 150 characters) folder_id: The folder_id of a specific folder in the File Repository for which you wish to create this sub-folder. If none is provided, the folder will be created in the top-level directory of the File Repository. dag_id: The dag_id of the DAG (Data Access Group) to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all DAGs and users in no DAGs. role_id: The role_id of the User Role to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all User Roles and users in no User Roles. format_type: Return the metadata in native objects, csv or xml. return_format_type: Response format. By default, response will be json-decoded. Returns: Union[str, List[Dict[str, Any]]]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.create_folder_in_repository(name=\"New Folder\") [{'folder_id': ...}] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" , format_type = format_type , return_format_type = return_format_type , ) payload [ \"action\" ] = \"createFolder\" payload [ \"name\" ] = name if folder_id : payload [ \"folder_id\" ] = folder_id if dag_id : payload [ \"dag_id\" ] = dag_id if role_id : payload [ \"role_id\" ] = role_id return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) return cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) def export_file_repository ( self , folder_id : Optional [ int ] = None , format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Export of list of files/folders in the File Repository Only exports the top-level of files/folders. To see which files are contained within a folder, use the `folder_id` parameter Args: folder_id: The folder_id of a specific folder in the File Repository for which you wish to search for files/folders. If none is provided, the search will be conducted in the top-level directory of the File Repository. format_type: Return the metadata in native objects, csv or xml. return_format_type: Response format. By default, response will be json-decoded. Returns: Union[str, List[Dict[str, Any]]]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.export_file_repository() [{'folder_id': ..., 'name': 'New Folder'}, ...] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" , format_type = format_type , return_format_type = return_format_type , ) payload [ \"action\" ] = \"list\" if folder_id : payload [ \"folder_id\" ] = folder_id return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) return cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) def export_file_from_repository ( self , doc_id : int , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ) -> FileMap : \"\"\" Export the contents of a file stored in the File Repository Args: doc_id: The doc_id of the file in the File Repository return_format_type: Response format. By default, response will be json-decoded. Returns: Content of the file and content-type dictionary Examples: >>> file_dir = proj.export_file_repository() >>> text_file = [file for file in file_dir if file[\"name\"] == \"test.txt\"].pop() >>> proj.export_file_from_repository(doc_id=text_file[\"doc_id\"]) (b'hello', {'name': 'test.txt', 'charset': 'UTF-8'}) \"\"\" payload = self . _initialize_payload ( content = \"fileRepository\" , return_format_type = return_format_type ) # there's no format field in this call payload [ \"action\" ] = \"export\" payload [ \"doc_id\" ] = doc_id content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map def import_file_into_repository ( self , file_name : str , file_object : IO , folder_id : Optional [ int ] = None , ) -> EmptyJson : \"\"\" Import the contents of a file represented by file_object into the file repository Args: file_name: File name visible in REDCap UI file_object: File object as returned by `open` folder_id: The folder_id of a specific folder in the File Repository where you wish to store the file. If none is provided, the file will be stored in the top-level directory of the File Repository. Returns: Empty JSON object Examples: >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file_into_repository( ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... ) [{}] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" ) payload [ \"action\" ] = \"import\" if folder_id : payload [ \"folder_id\" ] = folder_id file_upload_dict : FileUpload = { \"file\" : ( file_name , file_object )} return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" , file = file_upload_dict ), ) def delete_file_from_repository ( self , doc_id : int , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ) -> EmptyJson : # pylint: disable=line-too-long \"\"\" Delete a File from the File Repository Once deleted, the file will remain in the Recycle Bin folder for up to 30 days. Args: doc_id: The doc_id of the file in the File Repository return_format_type: Response format. By default, response will be json-decoded. Returns: Empty JSON object Examples: >>> file_dir = proj.export_file_repository() >>> test_folder = [folder for folder in file_dir if folder[\"name\"] == \"test\"].pop() >>> test_dir = proj.export_file_repository(folder_id=test_folder[\"folder_id\"]) >>> test_file = [file for file in test_dir if file[\"name\"] == \"test_in_folder.txt\"].pop() >>> proj.delete_file_from_repository(doc_id=test_file[\"doc_id\"]) [{}] \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"fileRepository\" , return_format_type = return_format_type ) # there's no format field in this call payload [ \"action\" ] = \"delete\" payload [ \"doc_id\" ] = doc_id return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" ) )","title":"FileRepository"},{"location":"api_reference/file_repository/#redcap.methods.file_repository.FileRepository.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/file_repository/#redcap.methods.file_repository.FileRepository.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/file_repository/#redcap.methods.file_repository.FileRepository.forms","text":"Project form names","title":"forms"},{"location":"api_reference/file_repository/#redcap.methods.file_repository.FileRepository.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/file_repository/#redcap.methods.file_repository.FileRepository.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/file_repository/#redcap.methods.file_repository.FileRepository.token","text":"API token to a project","title":"token"},{"location":"api_reference/file_repository/#redcap.methods.file_repository.FileRepository.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/file_repository/#redcap.methods.file_repository.FileRepository.create_folder_in_repository","text":"Create a New Folder in the File Repository Parameters: Name Type Description Default name str The desired name of the folder to be created (max length = 150 characters) required folder_id Optional[int] The folder_id of a specific folder in the File Repository for which you wish to create this sub-folder. If none is provided, the folder will be created in the top-level directory of the File Repository. None dag_id Optional[int] The dag_id of the DAG (Data Access Group) to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all DAGs and users in no DAGs. None role_id Optional[int] The role_id of the User Role to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all User Roles and users in no User Roles. None format_type Literal['json', 'csv', 'xml'] Return the metadata in native objects, csv or xml. 'json' return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[str, List[Dict[str, Any]]] List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj . create_folder_in_repository ( name = \"New Folder\" ) [{ 'folder_id' : ... }] Source code in redcap/methods/file_repository.py def create_folder_in_repository ( self , name : str , folder_id : Optional [ int ] = None , dag_id : Optional [ int ] = None , role_id : Optional [ int ] = None , format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Create a New Folder in the File Repository Args: name: The desired name of the folder to be created (max length = 150 characters) folder_id: The folder_id of a specific folder in the File Repository for which you wish to create this sub-folder. If none is provided, the folder will be created in the top-level directory of the File Repository. dag_id: The dag_id of the DAG (Data Access Group) to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all DAGs and users in no DAGs. role_id: The role_id of the User Role to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all User Roles and users in no User Roles. format_type: Return the metadata in native objects, csv or xml. return_format_type: Response format. By default, response will be json-decoded. Returns: Union[str, List[Dict[str, Any]]]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.create_folder_in_repository(name=\"New Folder\") [{'folder_id': ...}] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" , format_type = format_type , return_format_type = return_format_type , ) payload [ \"action\" ] = \"createFolder\" payload [ \"name\" ] = name if folder_id : payload [ \"folder_id\" ] = folder_id if dag_id : payload [ \"dag_id\" ] = dag_id if role_id : payload [ \"role_id\" ] = role_id return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) return cast ( Union [ Json , str ], self . _call_api ( payload , return_type ))","title":"create_folder_in_repository()"},{"location":"api_reference/file_repository/#redcap.methods.file_repository.FileRepository.delete_file_from_repository","text":"Delete a File from the File Repository Once deleted, the file will remain in the Recycle Bin folder for up to 30 days. Parameters: Name Type Description Default doc_id int The doc_id of the file in the File Repository required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description List[dict] Empty JSON object Examples: >>> file_dir = proj . export_file_repository () >>> test_folder = [ folder for folder in file_dir if folder [ \"name\" ] == \"test\" ] . pop () >>> test_dir = proj . export_file_repository ( folder_id = test_folder [ \"folder_id\" ]) >>> test_file = [ file for file in test_dir if file [ \"name\" ] == \"test_in_folder.txt\" ] . pop () >>> proj . delete_file_from_repository ( doc_id = test_file [ \"doc_id\" ]) [{}] Source code in redcap/methods/file_repository.py def delete_file_from_repository ( self , doc_id : int , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ) -> EmptyJson : # pylint: disable=line-too-long \"\"\" Delete a File from the File Repository Once deleted, the file will remain in the Recycle Bin folder for up to 30 days. Args: doc_id: The doc_id of the file in the File Repository return_format_type: Response format. By default, response will be json-decoded. Returns: Empty JSON object Examples: >>> file_dir = proj.export_file_repository() >>> test_folder = [folder for folder in file_dir if folder[\"name\"] == \"test\"].pop() >>> test_dir = proj.export_file_repository(folder_id=test_folder[\"folder_id\"]) >>> test_file = [file for file in test_dir if file[\"name\"] == \"test_in_folder.txt\"].pop() >>> proj.delete_file_from_repository(doc_id=test_file[\"doc_id\"]) [{}] \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"fileRepository\" , return_format_type = return_format_type ) # there's no format field in this call payload [ \"action\" ] = \"delete\" payload [ \"doc_id\" ] = doc_id return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" ) )","title":"delete_file_from_repository()"},{"location":"api_reference/file_repository/#redcap.methods.file_repository.FileRepository.export_file_from_repository","text":"Export the contents of a file stored in the File Repository Parameters: Name Type Description Default doc_id int The doc_id of the file in the File Repository required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Tuple[bytes, dict] Content of the file and content-type dictionary Examples: >>> file_dir = proj . export_file_repository () >>> text_file = [ file for file in file_dir if file [ \"name\" ] == \"test.txt\" ] . pop () >>> proj . export_file_from_repository ( doc_id = text_file [ \"doc_id\" ]) ( b 'hello' , { 'name' : 'test.txt' , 'charset' : 'UTF-8' }) Source code in redcap/methods/file_repository.py def export_file_from_repository ( self , doc_id : int , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ) -> FileMap : \"\"\" Export the contents of a file stored in the File Repository Args: doc_id: The doc_id of the file in the File Repository return_format_type: Response format. By default, response will be json-decoded. Returns: Content of the file and content-type dictionary Examples: >>> file_dir = proj.export_file_repository() >>> text_file = [file for file in file_dir if file[\"name\"] == \"test.txt\"].pop() >>> proj.export_file_from_repository(doc_id=text_file[\"doc_id\"]) (b'hello', {'name': 'test.txt', 'charset': 'UTF-8'}) \"\"\" payload = self . _initialize_payload ( content = \"fileRepository\" , return_format_type = return_format_type ) # there's no format field in this call payload [ \"action\" ] = \"export\" payload [ \"doc_id\" ] = doc_id content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map","title":"export_file_from_repository()"},{"location":"api_reference/file_repository/#redcap.methods.file_repository.FileRepository.export_file_repository","text":"Export of list of files/folders in the File Repository Only exports the top-level of files/folders. To see which files are contained within a folder, use the folder_id parameter Parameters: Name Type Description Default folder_id Optional[int] The folder_id of a specific folder in the File Repository for which you wish to search for files/folders. If none is provided, the search will be conducted in the top-level directory of the File Repository. None format_type Literal['json', 'csv', 'xml'] Return the metadata in native objects, csv or xml. 'json' return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[str, List[Dict[str, Any]]] List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj . export_file_repository () [{ 'folder_id' : ... , 'name' : 'New Folder' }, ... ] Source code in redcap/methods/file_repository.py def export_file_repository ( self , folder_id : Optional [ int ] = None , format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Export of list of files/folders in the File Repository Only exports the top-level of files/folders. To see which files are contained within a folder, use the `folder_id` parameter Args: folder_id: The folder_id of a specific folder in the File Repository for which you wish to search for files/folders. If none is provided, the search will be conducted in the top-level directory of the File Repository. format_type: Return the metadata in native objects, csv or xml. return_format_type: Response format. By default, response will be json-decoded. Returns: Union[str, List[Dict[str, Any]]]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.export_file_repository() [{'folder_id': ..., 'name': 'New Folder'}, ...] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" , format_type = format_type , return_format_type = return_format_type , ) payload [ \"action\" ] = \"list\" if folder_id : payload [ \"folder_id\" ] = folder_id return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) return cast ( Union [ Json , str ], self . _call_api ( payload , return_type ))","title":"export_file_repository()"},{"location":"api_reference/file_repository/#redcap.methods.file_repository.FileRepository.import_file_into_repository","text":"Import the contents of a file represented by file_object into the file repository Parameters: Name Type Description Default file_name str File name visible in REDCap UI required file_object IO File object as returned by open required folder_id Optional[int] The folder_id of a specific folder in the File Repository where you wish to store the file. If none is provided, the file will be stored in the top-level directory of the File Repository. None Returns: Type Description List[dict] Empty JSON object Examples: >>> import tempfile >>> tmp_file = tempfile . TemporaryFile () >>> proj . import_file_into_repository ( ... file_name = \"myupload.txt\" , ... file_object = tmp_file , ... ) [{}] Source code in redcap/methods/file_repository.py def import_file_into_repository ( self , file_name : str , file_object : IO , folder_id : Optional [ int ] = None , ) -> EmptyJson : \"\"\" Import the contents of a file represented by file_object into the file repository Args: file_name: File name visible in REDCap UI file_object: File object as returned by `open` folder_id: The folder_id of a specific folder in the File Repository where you wish to store the file. If none is provided, the file will be stored in the top-level directory of the File Repository. Returns: Empty JSON object Examples: >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file_into_repository( ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... ) [{}] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" ) payload [ \"action\" ] = \"import\" if folder_id : payload [ \"folder_id\" ] = folder_id file_upload_dict : FileUpload = { \"file\" : ( file_name , file_object )} return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" , file = file_upload_dict ), )","title":"import_file_into_repository()"},{"location":"api_reference/files/","text":"Files REDCap API methods for Project files Files ( Base ) Responsible for all API methods under 'Files' in the API Playground Source code in redcap/methods/files.py class Files ( Base ): \"\"\"Responsible for all API methods under 'Files' in the API Playground\"\"\" def _check_file_field ( self , field : str ) -> None : \"\"\"Check that field exists and is a file field\"\"\" is_field = field in self . field_names is_file = self . _filter_metadata ( key = \"field_type\" , field_name = field ) == \"file\" if not ( is_field and is_file ): msg = f \"' { field } ' is not a field or not a 'file' field\" raise ValueError ( msg ) def export_file ( self , record : str , field : str , event : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , ) -> FileMap : \"\"\" Export the contents of a file stored for a particular record Note: Unlike other export methods, this only works on a single record. Args: record: Record ID field: Field name containing the file to be exported. event: For longitudinal projects, the unique event name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Returns: Content of the file and content-type dictionary Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> proj.export_file(record=\"1\", field=\"upload_field\", event=\"event_1_arm_1\") (b'test upload\\\\n', {'name': 'test_upload.txt', 'charset': 'UTF-8'}) \"\"\" self . _check_file_field ( field ) # load up payload payload = self . _initialize_payload ( content = \"file\" ) # there's no format field in this call payload [ \"action\" ] = \"export\" payload [ \"field\" ] = field payload [ \"record\" ] = record if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = str ( repeat_instance ) content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map def import_file ( self , record : str , field : str , file_name : str , file_object : IO , event : Optional [ str ] = None , repeat_instance : Optional [ Union [ int , str ]] = None , ) -> EmptyJson : \"\"\" Import the contents of a file represented by file_object to a particular records field Args: record: Record ID field: Field name where the file will go file_name: File name visible in REDCap UI file_object: File object as returned by `open` event: For longitudinal projects, the unique event name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Returns: Empty JSON object Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file( ... record=\"2\", ... field=\"upload_field\", ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... event=\"event_1_arm_1\", ... ) [{}] \"\"\" self . _check_file_field ( field ) # load up payload payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"file\" ) payload [ \"action\" ] = \"import\" payload [ \"field\" ] = field payload [ \"record\" ] = record if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = repeat_instance file_upload_dict : FileUpload = { \"file\" : ( file_name , file_object )} return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" , file = file_upload_dict ), ) def delete_file ( self , record : str , field : str , event : Optional [ str ] = None , ) -> EmptyJson : \"\"\" Delete a file from REDCap Note: There is no undo button to this. Args: record: Record ID field: Field name event: For longitudinal projects, the unique event name Returns: Empty JSON object Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: Import a tempfile and then delete it >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file( ... record=\"2\", ... field=\"upload_field\", ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... event=\"event_1_arm_1\", ... ) [{}] >>> proj.delete_file(record=\"2\", field=\"upload_field\", event=\"event_1_arm_1\") [{}] \"\"\" self . _check_file_field ( field ) # Load up payload payload = self . _initialize_payload ( content = \"file\" ) payload [ \"action\" ] = \"delete\" payload [ \"record\" ] = record payload [ \"field\" ] = field if event : payload [ \"event\" ] = event return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" ) ) def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server delete_file ( self , record , field , event = None ) Delete a file from REDCap !!! note There is no undo button to this. Parameters: Name Type Description Default record str Record ID required field str Field name required event Optional[str] For longitudinal projects, the unique event name None Returns: Type Description List[dict] Empty JSON object Exceptions: Type Description ValueError Incorrect file field RedcapError Bad Request e.g. invalid record_id Examples: Import a tempfile and then delete it >>> import tempfile >>> tmp_file = tempfile . TemporaryFile () >>> proj . import_file ( ... record = \"2\" , ... field = \"upload_field\" , ... file_name = \"myupload.txt\" , ... file_object = tmp_file , ... event = \"event_1_arm_1\" , ... ) [{}] >>> proj . delete_file ( record = \"2\" , field = \"upload_field\" , event = \"event_1_arm_1\" ) [{}] Source code in redcap/methods/files.py def delete_file ( self , record : str , field : str , event : Optional [ str ] = None , ) -> EmptyJson : \"\"\" Delete a file from REDCap Note: There is no undo button to this. Args: record: Record ID field: Field name event: For longitudinal projects, the unique event name Returns: Empty JSON object Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: Import a tempfile and then delete it >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file( ... record=\"2\", ... field=\"upload_field\", ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... event=\"event_1_arm_1\", ... ) [{}] >>> proj.delete_file(record=\"2\", field=\"upload_field\", event=\"event_1_arm_1\") [{}] \"\"\" self . _check_file_field ( field ) # Load up payload payload = self . _initialize_payload ( content = \"file\" ) payload [ \"action\" ] = \"delete\" payload [ \"record\" ] = record payload [ \"field\" ] = field if event : payload [ \"event\" ] = event return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" ) ) export_file ( self , record , field , event = None , repeat_instance = None ) Export the contents of a file stored for a particular record !!! note Unlike other export methods, this only works on a single record. Parameters: Name Type Description Default record str Record ID required field str Field name containing the file to be exported. required event Optional[str] For longitudinal projects, the unique event name None repeat_instance Optional[int] (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). None Returns: Type Description Tuple[bytes, dict] Content of the file and content-type dictionary Exceptions: Type Description ValueError Incorrect file field RedcapError Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> proj . export_file ( record = \"1\" , field = \"upload_field\" , event = \"event_1_arm_1\" ) ( b 'test upload \\n ' , { 'name' : 'test_upload.txt' , 'charset' : 'UTF-8' }) Source code in redcap/methods/files.py def export_file ( self , record : str , field : str , event : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , ) -> FileMap : \"\"\" Export the contents of a file stored for a particular record Note: Unlike other export methods, this only works on a single record. Args: record: Record ID field: Field name containing the file to be exported. event: For longitudinal projects, the unique event name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Returns: Content of the file and content-type dictionary Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> proj.export_file(record=\"1\", field=\"upload_field\", event=\"event_1_arm_1\") (b'test upload\\\\n', {'name': 'test_upload.txt', 'charset': 'UTF-8'}) \"\"\" self . _check_file_field ( field ) # load up payload payload = self . _initialize_payload ( content = \"file\" ) # there's no format field in this call payload [ \"action\" ] = \"export\" payload [ \"field\" ] = field payload [ \"record\" ] = record if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = str ( repeat_instance ) content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map import_file ( self , record , field , file_name , file_object , event = None , repeat_instance = None ) Import the contents of a file represented by file_object to a particular records field Parameters: Name Type Description Default record str Record ID required field str Field name where the file will go required file_name str File name visible in REDCap UI required file_object IO File object as returned by open required event Optional[str] For longitudinal projects, the unique event name None repeat_instance Union[int, str] (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). None Returns: Type Description List[dict] Empty JSON object Exceptions: Type Description ValueError Incorrect file field RedcapError Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> import tempfile >>> tmp_file = tempfile . TemporaryFile () >>> proj . import_file ( ... record = \"2\" , ... field = \"upload_field\" , ... file_name = \"myupload.txt\" , ... file_object = tmp_file , ... event = \"event_1_arm_1\" , ... ) [{}] Source code in redcap/methods/files.py def import_file ( self , record : str , field : str , file_name : str , file_object : IO , event : Optional [ str ] = None , repeat_instance : Optional [ Union [ int , str ]] = None , ) -> EmptyJson : \"\"\" Import the contents of a file represented by file_object to a particular records field Args: record: Record ID field: Field name where the file will go file_name: File name visible in REDCap UI file_object: File object as returned by `open` event: For longitudinal projects, the unique event name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Returns: Empty JSON object Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file( ... record=\"2\", ... field=\"upload_field\", ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... event=\"event_1_arm_1\", ... ) [{}] \"\"\" self . _check_file_field ( field ) # load up payload payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"file\" ) payload [ \"action\" ] = \"import\" payload [ \"field\" ] = field payload [ \"record\" ] = record if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = repeat_instance file_upload_dict : FileUpload = { \"file\" : ( file_name , file_object )} return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" , file = file_upload_dict ), )","title":"Files"},{"location":"api_reference/files/#files","text":"REDCap API methods for Project files","title":"Files"},{"location":"api_reference/files/#redcap.methods.files.Files","text":"Responsible for all API methods under 'Files' in the API Playground Source code in redcap/methods/files.py class Files ( Base ): \"\"\"Responsible for all API methods under 'Files' in the API Playground\"\"\" def _check_file_field ( self , field : str ) -> None : \"\"\"Check that field exists and is a file field\"\"\" is_field = field in self . field_names is_file = self . _filter_metadata ( key = \"field_type\" , field_name = field ) == \"file\" if not ( is_field and is_file ): msg = f \"' { field } ' is not a field or not a 'file' field\" raise ValueError ( msg ) def export_file ( self , record : str , field : str , event : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , ) -> FileMap : \"\"\" Export the contents of a file stored for a particular record Note: Unlike other export methods, this only works on a single record. Args: record: Record ID field: Field name containing the file to be exported. event: For longitudinal projects, the unique event name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Returns: Content of the file and content-type dictionary Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> proj.export_file(record=\"1\", field=\"upload_field\", event=\"event_1_arm_1\") (b'test upload\\\\n', {'name': 'test_upload.txt', 'charset': 'UTF-8'}) \"\"\" self . _check_file_field ( field ) # load up payload payload = self . _initialize_payload ( content = \"file\" ) # there's no format field in this call payload [ \"action\" ] = \"export\" payload [ \"field\" ] = field payload [ \"record\" ] = record if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = str ( repeat_instance ) content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map def import_file ( self , record : str , field : str , file_name : str , file_object : IO , event : Optional [ str ] = None , repeat_instance : Optional [ Union [ int , str ]] = None , ) -> EmptyJson : \"\"\" Import the contents of a file represented by file_object to a particular records field Args: record: Record ID field: Field name where the file will go file_name: File name visible in REDCap UI file_object: File object as returned by `open` event: For longitudinal projects, the unique event name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Returns: Empty JSON object Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file( ... record=\"2\", ... field=\"upload_field\", ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... event=\"event_1_arm_1\", ... ) [{}] \"\"\" self . _check_file_field ( field ) # load up payload payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"file\" ) payload [ \"action\" ] = \"import\" payload [ \"field\" ] = field payload [ \"record\" ] = record if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = repeat_instance file_upload_dict : FileUpload = { \"file\" : ( file_name , file_object )} return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" , file = file_upload_dict ), ) def delete_file ( self , record : str , field : str , event : Optional [ str ] = None , ) -> EmptyJson : \"\"\" Delete a file from REDCap Note: There is no undo button to this. Args: record: Record ID field: Field name event: For longitudinal projects, the unique event name Returns: Empty JSON object Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: Import a tempfile and then delete it >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file( ... record=\"2\", ... field=\"upload_field\", ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... event=\"event_1_arm_1\", ... ) [{}] >>> proj.delete_file(record=\"2\", field=\"upload_field\", event=\"event_1_arm_1\") [{}] \"\"\" self . _check_file_field ( field ) # Load up payload payload = self . _initialize_payload ( content = \"file\" ) payload [ \"action\" ] = \"delete\" payload [ \"record\" ] = record payload [ \"field\" ] = field if event : payload [ \"event\" ] = event return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" ) )","title":"Files"},{"location":"api_reference/files/#redcap.methods.files.Files.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/files/#redcap.methods.files.Files.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/files/#redcap.methods.files.Files.forms","text":"Project form names","title":"forms"},{"location":"api_reference/files/#redcap.methods.files.Files.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/files/#redcap.methods.files.Files.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/files/#redcap.methods.files.Files.token","text":"API token to a project","title":"token"},{"location":"api_reference/files/#redcap.methods.files.Files.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/files/#redcap.methods.files.Files.delete_file","text":"Delete a file from REDCap !!! note There is no undo button to this. Parameters: Name Type Description Default record str Record ID required field str Field name required event Optional[str] For longitudinal projects, the unique event name None Returns: Type Description List[dict] Empty JSON object Exceptions: Type Description ValueError Incorrect file field RedcapError Bad Request e.g. invalid record_id Examples: Import a tempfile and then delete it >>> import tempfile >>> tmp_file = tempfile . TemporaryFile () >>> proj . import_file ( ... record = \"2\" , ... field = \"upload_field\" , ... file_name = \"myupload.txt\" , ... file_object = tmp_file , ... event = \"event_1_arm_1\" , ... ) [{}] >>> proj . delete_file ( record = \"2\" , field = \"upload_field\" , event = \"event_1_arm_1\" ) [{}] Source code in redcap/methods/files.py def delete_file ( self , record : str , field : str , event : Optional [ str ] = None , ) -> EmptyJson : \"\"\" Delete a file from REDCap Note: There is no undo button to this. Args: record: Record ID field: Field name event: For longitudinal projects, the unique event name Returns: Empty JSON object Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: Import a tempfile and then delete it >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file( ... record=\"2\", ... field=\"upload_field\", ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... event=\"event_1_arm_1\", ... ) [{}] >>> proj.delete_file(record=\"2\", field=\"upload_field\", event=\"event_1_arm_1\") [{}] \"\"\" self . _check_file_field ( field ) # Load up payload payload = self . _initialize_payload ( content = \"file\" ) payload [ \"action\" ] = \"delete\" payload [ \"record\" ] = record payload [ \"field\" ] = field if event : payload [ \"event\" ] = event return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" ) )","title":"delete_file()"},{"location":"api_reference/files/#redcap.methods.files.Files.export_file","text":"Export the contents of a file stored for a particular record !!! note Unlike other export methods, this only works on a single record. Parameters: Name Type Description Default record str Record ID required field str Field name containing the file to be exported. required event Optional[str] For longitudinal projects, the unique event name None repeat_instance Optional[int] (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). None Returns: Type Description Tuple[bytes, dict] Content of the file and content-type dictionary Exceptions: Type Description ValueError Incorrect file field RedcapError Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> proj . export_file ( record = \"1\" , field = \"upload_field\" , event = \"event_1_arm_1\" ) ( b 'test upload \\n ' , { 'name' : 'test_upload.txt' , 'charset' : 'UTF-8' }) Source code in redcap/methods/files.py def export_file ( self , record : str , field : str , event : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , ) -> FileMap : \"\"\" Export the contents of a file stored for a particular record Note: Unlike other export methods, this only works on a single record. Args: record: Record ID field: Field name containing the file to be exported. event: For longitudinal projects, the unique event name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Returns: Content of the file and content-type dictionary Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> proj.export_file(record=\"1\", field=\"upload_field\", event=\"event_1_arm_1\") (b'test upload\\\\n', {'name': 'test_upload.txt', 'charset': 'UTF-8'}) \"\"\" self . _check_file_field ( field ) # load up payload payload = self . _initialize_payload ( content = \"file\" ) # there's no format field in this call payload [ \"action\" ] = \"export\" payload [ \"field\" ] = field payload [ \"record\" ] = record if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = str ( repeat_instance ) content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map","title":"export_file()"},{"location":"api_reference/files/#redcap.methods.files.Files.import_file","text":"Import the contents of a file represented by file_object to a particular records field Parameters: Name Type Description Default record str Record ID required field str Field name where the file will go required file_name str File name visible in REDCap UI required file_object IO File object as returned by open required event Optional[str] For longitudinal projects, the unique event name None repeat_instance Union[int, str] (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). None Returns: Type Description List[dict] Empty JSON object Exceptions: Type Description ValueError Incorrect file field RedcapError Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> import tempfile >>> tmp_file = tempfile . TemporaryFile () >>> proj . import_file ( ... record = \"2\" , ... field = \"upload_field\" , ... file_name = \"myupload.txt\" , ... file_object = tmp_file , ... event = \"event_1_arm_1\" , ... ) [{}] Source code in redcap/methods/files.py def import_file ( self , record : str , field : str , file_name : str , file_object : IO , event : Optional [ str ] = None , repeat_instance : Optional [ Union [ int , str ]] = None , ) -> EmptyJson : \"\"\" Import the contents of a file represented by file_object to a particular records field Args: record: Record ID field: Field name where the file will go file_name: File name visible in REDCap UI file_object: File object as returned by `open` event: For longitudinal projects, the unique event name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Returns: Empty JSON object Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file( ... record=\"2\", ... field=\"upload_field\", ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... event=\"event_1_arm_1\", ... ) [{}] \"\"\" self . _check_file_field ( field ) # load up payload payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"file\" ) payload [ \"action\" ] = \"import\" payload [ \"field\" ] = field payload [ \"record\" ] = record if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = repeat_instance file_upload_dict : FileUpload = { \"file\" : ( file_name , file_object )} return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" , file = file_upload_dict ), )","title":"import_file()"},{"location":"api_reference/instruments/","text":"Instruments REDCap API methods for Project instruments Instruments ( Base ) Responsible for all API methods under 'Instruments' in the API Playground Source code in redcap/methods/instruments.py class Instruments ( Base ): \"\"\"Responsible for all API methods under 'Instruments' in the API Playground\"\"\" def export_instruments ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Export the Instruments of the Project Args: format_type: Response return format Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Instruments Examples: >>> proj.export_instruments() [{'instrument_name': 'form_1', 'instrument_label': 'Form 1'}] \"\"\" payload = self . _initialize_payload ( content = \"instrument\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"instrument\" , format_type = format_type , ) #### pylint: disable=too-many-locals def export_pdf ( self , record : Optional [ str ] = None , event : Optional [ str ] = None , instrument : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , all_records : Optional [ bool ] = None , compact_display : Optional [ bool ] = None , ) -> FileMap : \"\"\" Export PDF file of instruments, either as blank or with data Args: record: Record ID event: For longitudinal projects, the unique event name instrument: Unique instrument name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). all_records: If True, then all records will be exported as a single PDF file. Note: If this is True, then record, event, and instrument parameters are all ignored. compact_display: If True, then the PDF will be exported in compact display mode. Returns: Content of the file and dictionary of useful metadata Examples: >>> proj.export_pdf() (b'%PDF-1.3\\\\n3 0 obj\\\\n..., {...}) \"\"\" # load up payload payload = self . _initialize_payload ( content = \"pdf\" , return_format_type = \"json\" ) keys_to_add = ( record , event , instrument , repeat_instance , all_records , compact_display , ) str_keys = ( \"record\" , \"event\" , \"instrument\" , \"repeat_instance\" , \"allRecords\" , \"compactDisplay\" , ) for key , data in zip ( str_keys , keys_to_add ): data = cast ( str , data ) if data : payload [ key ] = data payload [ \"action\" ] = \"export\" content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map #### pylint: enable=too-many-locals def export_instrument_event_mappings ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's instrument to event mapping Args: format_type: Return the form event mappings in native objects, csv or xml, `'df''` will return a `pandas.DataFrame` arms: Limit exported form event mappings to these arms df_kwargs: Passed to pandas.read_csv to control construction of returned DataFrame Returns: Union[str, List[Dict[str, Any]], pd.DataFrame]: Instrument-event mapping for the project Examples: >>> proj.export_instrument_event_mappings() [{'arm_num': 1, 'unique_event_name': 'event_1_arm_1', 'form': 'form_1'}] \"\"\" payload = self . _initialize_payload ( content = \"formEventMapping\" , format_type = format_type ) if arms : for i , value in enumerate ( arms ): payload [ f \"arms[ { i } ]\" ] = value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"formEventMapping\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_instrument_event_mappings ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): # pylint: disable=line-too-long \"\"\" Import the project's instrument to event mapping Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, import_format will be json-encoded Returns: Union[int, str]: Number of instrument-event mappings imported Examples: Import instrument-event mappings >>> instrument_event_mappings = [{\"arm_num\": \"1\", \"unique_event_name\": \"event_1_arm_1\", \"form\": \"form_1\"}] >>> proj.import_instrument_event_mappings(instrument_event_mappings) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"formEventMapping\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server export_instrument_event_mappings ( self , format_type = 'json' , arms = None , df_kwargs = None ) Export the project's instrument to event mapping Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the form event mappings in native objects, csv or xml, 'df'' will return a pandas.DataFrame 'json' arms Optional[List[str]] Limit exported form event mappings to these arms None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame None Returns: Type Description Union[str, List[Dict[str, Any]], pd.DataFrame] Instrument-event mapping for the project Examples: >>> proj . export_instrument_event_mappings () [{ 'arm_num' : 1 , 'unique_event_name' : 'event_1_arm_1' , 'form' : 'form_1' }] Source code in redcap/methods/instruments.py def export_instrument_event_mappings ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's instrument to event mapping Args: format_type: Return the form event mappings in native objects, csv or xml, `'df''` will return a `pandas.DataFrame` arms: Limit exported form event mappings to these arms df_kwargs: Passed to pandas.read_csv to control construction of returned DataFrame Returns: Union[str, List[Dict[str, Any]], pd.DataFrame]: Instrument-event mapping for the project Examples: >>> proj.export_instrument_event_mappings() [{'arm_num': 1, 'unique_event_name': 'event_1_arm_1', 'form': 'form_1'}] \"\"\" payload = self . _initialize_payload ( content = \"formEventMapping\" , format_type = format_type ) if arms : for i , value in enumerate ( arms ): payload [ f \"arms[ { i } ]\" ] = value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"formEventMapping\" , format_type = format_type , df_kwargs = df_kwargs , ) export_instruments ( self , format_type = 'json' ) Export the Instruments of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of Instruments Examples: >>> proj . export_instruments () [{ 'instrument_name' : 'form_1' , 'instrument_label' : 'Form 1' }] Source code in redcap/methods/instruments.py def export_instruments ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Export the Instruments of the Project Args: format_type: Response return format Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Instruments Examples: >>> proj.export_instruments() [{'instrument_name': 'form_1', 'instrument_label': 'Form 1'}] \"\"\" payload = self . _initialize_payload ( content = \"instrument\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"instrument\" , format_type = format_type , ) export_pdf ( self , record = None , event = None , instrument = None , repeat_instance = None , all_records = None , compact_display = None ) Export PDF file of instruments, either as blank or with data Parameters: Name Type Description Default record Optional[str] Record ID None event Optional[str] For longitudinal projects, the unique event name None instrument Optional[str] Unique instrument name None repeat_instance Optional[int] (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). None all_records Optional[bool] If True, then all records will be exported as a single PDF file. Note: If this is True, then record, event, and instrument parameters are all ignored. None compact_display Optional[bool] If True, then the PDF will be exported in compact display mode. None Returns: Type Description Tuple[bytes, dict] Content of the file and dictionary of useful metadata Examples: >>> proj . export_pdf () ( b '%PDF-1.3 \\n 3 0 obj \\n ..., {...}) Source code in redcap/methods/instruments.py def export_pdf ( self , record : Optional [ str ] = None , event : Optional [ str ] = None , instrument : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , all_records : Optional [ bool ] = None , compact_display : Optional [ bool ] = None , ) -> FileMap : \"\"\" Export PDF file of instruments, either as blank or with data Args: record: Record ID event: For longitudinal projects, the unique event name instrument: Unique instrument name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). all_records: If True, then all records will be exported as a single PDF file. Note: If this is True, then record, event, and instrument parameters are all ignored. compact_display: If True, then the PDF will be exported in compact display mode. Returns: Content of the file and dictionary of useful metadata Examples: >>> proj.export_pdf() (b'%PDF-1.3\\\\n3 0 obj\\\\n..., {...}) \"\"\" # load up payload payload = self . _initialize_payload ( content = \"pdf\" , return_format_type = \"json\" ) keys_to_add = ( record , event , instrument , repeat_instance , all_records , compact_display , ) str_keys = ( \"record\" , \"event\" , \"instrument\" , \"repeat_instance\" , \"allRecords\" , \"compactDisplay\" , ) for key , data in zip ( str_keys , keys_to_add ): data = cast ( str , data ) if data : payload [ key ] = data payload [ \"action\" ] = \"export\" content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map import_instrument_event_mappings ( self , to_import , return_format_type = 'json' , import_format = 'json' ) Import the project's instrument to event mapping !!! note This only works for longitudinal projects. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, import_format will be json-encoded 'json' Returns: Type Description Union[int, str] Number of instrument-event mappings imported Examples: Import instrument-event mappings >>> instrument_event_mappings = [{ \"arm_num\" : \"1\" , \"unique_event_name\" : \"event_1_arm_1\" , \"form\" : \"form_1\" }] >>> proj . import_instrument_event_mappings ( instrument_event_mappings ) 1 Source code in redcap/methods/instruments.py def import_instrument_event_mappings ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): # pylint: disable=line-too-long \"\"\" Import the project's instrument to event mapping Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, import_format will be json-encoded Returns: Union[int, str]: Number of instrument-event mappings imported Examples: Import instrument-event mappings >>> instrument_event_mappings = [{\"arm_num\": \"1\", \"unique_event_name\": \"event_1_arm_1\", \"form\": \"form_1\"}] >>> proj.import_instrument_event_mappings(instrument_event_mappings) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"formEventMapping\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"Instruments"},{"location":"api_reference/instruments/#instruments","text":"REDCap API methods for Project instruments","title":"Instruments"},{"location":"api_reference/instruments/#redcap.methods.instruments.Instruments","text":"Responsible for all API methods under 'Instruments' in the API Playground Source code in redcap/methods/instruments.py class Instruments ( Base ): \"\"\"Responsible for all API methods under 'Instruments' in the API Playground\"\"\" def export_instruments ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Export the Instruments of the Project Args: format_type: Response return format Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Instruments Examples: >>> proj.export_instruments() [{'instrument_name': 'form_1', 'instrument_label': 'Form 1'}] \"\"\" payload = self . _initialize_payload ( content = \"instrument\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"instrument\" , format_type = format_type , ) #### pylint: disable=too-many-locals def export_pdf ( self , record : Optional [ str ] = None , event : Optional [ str ] = None , instrument : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , all_records : Optional [ bool ] = None , compact_display : Optional [ bool ] = None , ) -> FileMap : \"\"\" Export PDF file of instruments, either as blank or with data Args: record: Record ID event: For longitudinal projects, the unique event name instrument: Unique instrument name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). all_records: If True, then all records will be exported as a single PDF file. Note: If this is True, then record, event, and instrument parameters are all ignored. compact_display: If True, then the PDF will be exported in compact display mode. Returns: Content of the file and dictionary of useful metadata Examples: >>> proj.export_pdf() (b'%PDF-1.3\\\\n3 0 obj\\\\n..., {...}) \"\"\" # load up payload payload = self . _initialize_payload ( content = \"pdf\" , return_format_type = \"json\" ) keys_to_add = ( record , event , instrument , repeat_instance , all_records , compact_display , ) str_keys = ( \"record\" , \"event\" , \"instrument\" , \"repeat_instance\" , \"allRecords\" , \"compactDisplay\" , ) for key , data in zip ( str_keys , keys_to_add ): data = cast ( str , data ) if data : payload [ key ] = data payload [ \"action\" ] = \"export\" content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map #### pylint: enable=too-many-locals def export_instrument_event_mappings ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's instrument to event mapping Args: format_type: Return the form event mappings in native objects, csv or xml, `'df''` will return a `pandas.DataFrame` arms: Limit exported form event mappings to these arms df_kwargs: Passed to pandas.read_csv to control construction of returned DataFrame Returns: Union[str, List[Dict[str, Any]], pd.DataFrame]: Instrument-event mapping for the project Examples: >>> proj.export_instrument_event_mappings() [{'arm_num': 1, 'unique_event_name': 'event_1_arm_1', 'form': 'form_1'}] \"\"\" payload = self . _initialize_payload ( content = \"formEventMapping\" , format_type = format_type ) if arms : for i , value in enumerate ( arms ): payload [ f \"arms[ { i } ]\" ] = value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"formEventMapping\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_instrument_event_mappings ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): # pylint: disable=line-too-long \"\"\" Import the project's instrument to event mapping Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, import_format will be json-encoded Returns: Union[int, str]: Number of instrument-event mappings imported Examples: Import instrument-event mappings >>> instrument_event_mappings = [{\"arm_num\": \"1\", \"unique_event_name\": \"event_1_arm_1\", \"form\": \"form_1\"}] >>> proj.import_instrument_event_mappings(instrument_event_mappings) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"formEventMapping\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"Instruments"},{"location":"api_reference/instruments/#redcap.methods.instruments.Instruments.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/instruments/#redcap.methods.instruments.Instruments.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/instruments/#redcap.methods.instruments.Instruments.forms","text":"Project form names","title":"forms"},{"location":"api_reference/instruments/#redcap.methods.instruments.Instruments.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/instruments/#redcap.methods.instruments.Instruments.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/instruments/#redcap.methods.instruments.Instruments.token","text":"API token to a project","title":"token"},{"location":"api_reference/instruments/#redcap.methods.instruments.Instruments.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/instruments/#redcap.methods.instruments.Instruments.export_instrument_event_mappings","text":"Export the project's instrument to event mapping Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the form event mappings in native objects, csv or xml, 'df'' will return a pandas.DataFrame 'json' arms Optional[List[str]] Limit exported form event mappings to these arms None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame None Returns: Type Description Union[str, List[Dict[str, Any]], pd.DataFrame] Instrument-event mapping for the project Examples: >>> proj . export_instrument_event_mappings () [{ 'arm_num' : 1 , 'unique_event_name' : 'event_1_arm_1' , 'form' : 'form_1' }] Source code in redcap/methods/instruments.py def export_instrument_event_mappings ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's instrument to event mapping Args: format_type: Return the form event mappings in native objects, csv or xml, `'df''` will return a `pandas.DataFrame` arms: Limit exported form event mappings to these arms df_kwargs: Passed to pandas.read_csv to control construction of returned DataFrame Returns: Union[str, List[Dict[str, Any]], pd.DataFrame]: Instrument-event mapping for the project Examples: >>> proj.export_instrument_event_mappings() [{'arm_num': 1, 'unique_event_name': 'event_1_arm_1', 'form': 'form_1'}] \"\"\" payload = self . _initialize_payload ( content = \"formEventMapping\" , format_type = format_type ) if arms : for i , value in enumerate ( arms ): payload [ f \"arms[ { i } ]\" ] = value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"formEventMapping\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_instrument_event_mappings()"},{"location":"api_reference/instruments/#redcap.methods.instruments.Instruments.export_instruments","text":"Export the Instruments of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of Instruments Examples: >>> proj . export_instruments () [{ 'instrument_name' : 'form_1' , 'instrument_label' : 'Form 1' }] Source code in redcap/methods/instruments.py def export_instruments ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Export the Instruments of the Project Args: format_type: Response return format Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Instruments Examples: >>> proj.export_instruments() [{'instrument_name': 'form_1', 'instrument_label': 'Form 1'}] \"\"\" payload = self . _initialize_payload ( content = \"instrument\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"instrument\" , format_type = format_type , )","title":"export_instruments()"},{"location":"api_reference/instruments/#redcap.methods.instruments.Instruments.export_pdf","text":"Export PDF file of instruments, either as blank or with data Parameters: Name Type Description Default record Optional[str] Record ID None event Optional[str] For longitudinal projects, the unique event name None instrument Optional[str] Unique instrument name None repeat_instance Optional[int] (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). None all_records Optional[bool] If True, then all records will be exported as a single PDF file. Note: If this is True, then record, event, and instrument parameters are all ignored. None compact_display Optional[bool] If True, then the PDF will be exported in compact display mode. None Returns: Type Description Tuple[bytes, dict] Content of the file and dictionary of useful metadata Examples: >>> proj . export_pdf () ( b '%PDF-1.3 \\n 3 0 obj \\n ..., {...}) Source code in redcap/methods/instruments.py def export_pdf ( self , record : Optional [ str ] = None , event : Optional [ str ] = None , instrument : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , all_records : Optional [ bool ] = None , compact_display : Optional [ bool ] = None , ) -> FileMap : \"\"\" Export PDF file of instruments, either as blank or with data Args: record: Record ID event: For longitudinal projects, the unique event name instrument: Unique instrument name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). all_records: If True, then all records will be exported as a single PDF file. Note: If this is True, then record, event, and instrument parameters are all ignored. compact_display: If True, then the PDF will be exported in compact display mode. Returns: Content of the file and dictionary of useful metadata Examples: >>> proj.export_pdf() (b'%PDF-1.3\\\\n3 0 obj\\\\n..., {...}) \"\"\" # load up payload payload = self . _initialize_payload ( content = \"pdf\" , return_format_type = \"json\" ) keys_to_add = ( record , event , instrument , repeat_instance , all_records , compact_display , ) str_keys = ( \"record\" , \"event\" , \"instrument\" , \"repeat_instance\" , \"allRecords\" , \"compactDisplay\" , ) for key , data in zip ( str_keys , keys_to_add ): data = cast ( str , data ) if data : payload [ key ] = data payload [ \"action\" ] = \"export\" content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map","title":"export_pdf()"},{"location":"api_reference/instruments/#redcap.methods.instruments.Instruments.import_instrument_event_mappings","text":"Import the project's instrument to event mapping !!! note This only works for longitudinal projects. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, import_format will be json-encoded 'json' Returns: Type Description Union[int, str] Number of instrument-event mappings imported Examples: Import instrument-event mappings >>> instrument_event_mappings = [{ \"arm_num\" : \"1\" , \"unique_event_name\" : \"event_1_arm_1\" , \"form\" : \"form_1\" }] >>> proj . import_instrument_event_mappings ( instrument_event_mappings ) 1 Source code in redcap/methods/instruments.py def import_instrument_event_mappings ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): # pylint: disable=line-too-long \"\"\" Import the project's instrument to event mapping Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, import_format will be json-encoded Returns: Union[int, str]: Number of instrument-event mappings imported Examples: Import instrument-event mappings >>> instrument_event_mappings = [{\"arm_num\": \"1\", \"unique_event_name\": \"event_1_arm_1\", \"form\": \"form_1\"}] >>> proj.import_instrument_event_mappings(instrument_event_mappings) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"formEventMapping\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_instrument_event_mappings()"},{"location":"api_reference/logging/","text":"Logging REDCap API methods for Project logs Logging ( Base ) Responsible for all API methods under 'Logging' in the API Playground Source code in redcap/methods/logging.py class Logging ( Base ): \"\"\"Responsible for all API methods under 'Logging' in the API Playground\"\"\" # pylint: disable=too-many-locals def export_logging ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , return_format_type : Optional [ Literal [ \"json\" , \"csv\" , \"xml\" ]] = None , log_type : Optional [ Literal [ \"export\" , \"manage\" , \"user\" , \"record\" , \"record_add\" , \"record_edit\" , \"record_delete\" , \"lock_record\" , \"page_view\" , ] ] = None , user : Optional [ str ] = None , record : Optional [ str ] = None , dag : Optional [ str ] = None , begin_time : Optional [ datetime ] = None , end_time : Optional [ datetime ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's logs Args: format_type: Return the metadata in native objects, csv or xml. `'df'` will return a `pandas.DataFrame` return_format_type: Response format. By default, response will be json-decoded. log_type: Filter by specific event types user: Filter by events created by a certain user record: Filter by events created for a certain record dag: Filter by events created by a certain data access group (group ID) begin_time: Filter by events created after a given timestamp end_time: Filter by events created before a given timestamp df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. Returns: Union[str, List[Dict[str, Any]], \"pd.DataFrame\"]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.export_logging() [{'timestamp': ..., 'username': ..., 'action': 'Manage/Design ', 'details': 'Create project ...'}, ...] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"log\" , format_type = format_type ) optional_args = [ ( \"returnFormat\" , return_format_type ), ( \"logtype\" , log_type ), ( \"user\" , user ), ( \"record\" , record ), ( \"dag\" , dag ), ( \"beginTime\" , begin_time ), ( \"endTime\" , end_time ), ] for arg in optional_args : arg_name , arg_value = arg if arg_value : if arg_name in [ \"beginTime\" , \"endTime\" ]: arg_value = cast ( datetime , arg_value ) arg_value = arg_value . strftime ( \"%Y-%m- %d %H:%M:%S\" ) payload [ arg_name ] = arg_value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"log\" , format_type = format_type , df_kwargs = df_kwargs , ) # pylint: enable=too-many-locals def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server export_logging ( self , format_type = 'json' , return_format_type = None , log_type = None , user = None , record = None , dag = None , begin_time = None , end_time = None , df_kwargs = None ) Export the project's logs Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the metadata in native objects, csv or xml. 'df' will return a pandas.DataFrame 'json' return_format_type Optional[Literal['json', 'csv', 'xml']] Response format. By default, response will be json-decoded. None log_type Optional[Literal['export', 'manage', 'user', 'record', 'record_add', 'record_edit', 'record_delete', 'lock_record', 'page_view']] Filter by specific event types None user Optional[str] Filter by events created by a certain user None record Optional[str] Filter by events created for a certain record None dag Optional[str] Filter by events created by a certain data access group (group ID) None begin_time Optional[datetime.datetime] Filter by events created after a given timestamp None end_time Optional[datetime.datetime] Filter by events created before a given timestamp None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. None Returns: Type Description Union[str, List[Dict[str, Any]], \"pd.DataFrame\"] List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj . export_logging () [{ 'timestamp' : ... , 'username' : ... , 'action' : 'Manage/Design ' , 'details' : 'Create project ...' }, ... ] Source code in redcap/methods/logging.py def export_logging ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , return_format_type : Optional [ Literal [ \"json\" , \"csv\" , \"xml\" ]] = None , log_type : Optional [ Literal [ \"export\" , \"manage\" , \"user\" , \"record\" , \"record_add\" , \"record_edit\" , \"record_delete\" , \"lock_record\" , \"page_view\" , ] ] = None , user : Optional [ str ] = None , record : Optional [ str ] = None , dag : Optional [ str ] = None , begin_time : Optional [ datetime ] = None , end_time : Optional [ datetime ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's logs Args: format_type: Return the metadata in native objects, csv or xml. `'df'` will return a `pandas.DataFrame` return_format_type: Response format. By default, response will be json-decoded. log_type: Filter by specific event types user: Filter by events created by a certain user record: Filter by events created for a certain record dag: Filter by events created by a certain data access group (group ID) begin_time: Filter by events created after a given timestamp end_time: Filter by events created before a given timestamp df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. Returns: Union[str, List[Dict[str, Any]], \"pd.DataFrame\"]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.export_logging() [{'timestamp': ..., 'username': ..., 'action': 'Manage/Design ', 'details': 'Create project ...'}, ...] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"log\" , format_type = format_type ) optional_args = [ ( \"returnFormat\" , return_format_type ), ( \"logtype\" , log_type ), ( \"user\" , user ), ( \"record\" , record ), ( \"dag\" , dag ), ( \"beginTime\" , begin_time ), ( \"endTime\" , end_time ), ] for arg in optional_args : arg_name , arg_value = arg if arg_value : if arg_name in [ \"beginTime\" , \"endTime\" ]: arg_value = cast ( datetime , arg_value ) arg_value = arg_value . strftime ( \"%Y-%m- %d %H:%M:%S\" ) payload [ arg_name ] = arg_value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"log\" , format_type = format_type , df_kwargs = df_kwargs , ) # pylint: enable=too-many-locals","title":"Logging"},{"location":"api_reference/logging/#logging","text":"REDCap API methods for Project logs","title":"Logging"},{"location":"api_reference/logging/#redcap.methods.logging.Logging","text":"Responsible for all API methods under 'Logging' in the API Playground Source code in redcap/methods/logging.py class Logging ( Base ): \"\"\"Responsible for all API methods under 'Logging' in the API Playground\"\"\" # pylint: disable=too-many-locals def export_logging ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , return_format_type : Optional [ Literal [ \"json\" , \"csv\" , \"xml\" ]] = None , log_type : Optional [ Literal [ \"export\" , \"manage\" , \"user\" , \"record\" , \"record_add\" , \"record_edit\" , \"record_delete\" , \"lock_record\" , \"page_view\" , ] ] = None , user : Optional [ str ] = None , record : Optional [ str ] = None , dag : Optional [ str ] = None , begin_time : Optional [ datetime ] = None , end_time : Optional [ datetime ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's logs Args: format_type: Return the metadata in native objects, csv or xml. `'df'` will return a `pandas.DataFrame` return_format_type: Response format. By default, response will be json-decoded. log_type: Filter by specific event types user: Filter by events created by a certain user record: Filter by events created for a certain record dag: Filter by events created by a certain data access group (group ID) begin_time: Filter by events created after a given timestamp end_time: Filter by events created before a given timestamp df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. Returns: Union[str, List[Dict[str, Any]], \"pd.DataFrame\"]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.export_logging() [{'timestamp': ..., 'username': ..., 'action': 'Manage/Design ', 'details': 'Create project ...'}, ...] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"log\" , format_type = format_type ) optional_args = [ ( \"returnFormat\" , return_format_type ), ( \"logtype\" , log_type ), ( \"user\" , user ), ( \"record\" , record ), ( \"dag\" , dag ), ( \"beginTime\" , begin_time ), ( \"endTime\" , end_time ), ] for arg in optional_args : arg_name , arg_value = arg if arg_value : if arg_name in [ \"beginTime\" , \"endTime\" ]: arg_value = cast ( datetime , arg_value ) arg_value = arg_value . strftime ( \"%Y-%m- %d %H:%M:%S\" ) payload [ arg_name ] = arg_value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"log\" , format_type = format_type , df_kwargs = df_kwargs , ) # pylint: enable=too-many-locals","title":"Logging"},{"location":"api_reference/logging/#redcap.methods.logging.Logging.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/logging/#redcap.methods.logging.Logging.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/logging/#redcap.methods.logging.Logging.forms","text":"Project form names","title":"forms"},{"location":"api_reference/logging/#redcap.methods.logging.Logging.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/logging/#redcap.methods.logging.Logging.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/logging/#redcap.methods.logging.Logging.token","text":"API token to a project","title":"token"},{"location":"api_reference/logging/#redcap.methods.logging.Logging.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/logging/#redcap.methods.logging.Logging.export_logging","text":"Export the project's logs Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the metadata in native objects, csv or xml. 'df' will return a pandas.DataFrame 'json' return_format_type Optional[Literal['json', 'csv', 'xml']] Response format. By default, response will be json-decoded. None log_type Optional[Literal['export', 'manage', 'user', 'record', 'record_add', 'record_edit', 'record_delete', 'lock_record', 'page_view']] Filter by specific event types None user Optional[str] Filter by events created by a certain user None record Optional[str] Filter by events created for a certain record None dag Optional[str] Filter by events created by a certain data access group (group ID) None begin_time Optional[datetime.datetime] Filter by events created after a given timestamp None end_time Optional[datetime.datetime] Filter by events created before a given timestamp None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. None Returns: Type Description Union[str, List[Dict[str, Any]], \"pd.DataFrame\"] List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj . export_logging () [{ 'timestamp' : ... , 'username' : ... , 'action' : 'Manage/Design ' , 'details' : 'Create project ...' }, ... ] Source code in redcap/methods/logging.py def export_logging ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , return_format_type : Optional [ Literal [ \"json\" , \"csv\" , \"xml\" ]] = None , log_type : Optional [ Literal [ \"export\" , \"manage\" , \"user\" , \"record\" , \"record_add\" , \"record_edit\" , \"record_delete\" , \"lock_record\" , \"page_view\" , ] ] = None , user : Optional [ str ] = None , record : Optional [ str ] = None , dag : Optional [ str ] = None , begin_time : Optional [ datetime ] = None , end_time : Optional [ datetime ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's logs Args: format_type: Return the metadata in native objects, csv or xml. `'df'` will return a `pandas.DataFrame` return_format_type: Response format. By default, response will be json-decoded. log_type: Filter by specific event types user: Filter by events created by a certain user record: Filter by events created for a certain record dag: Filter by events created by a certain data access group (group ID) begin_time: Filter by events created after a given timestamp end_time: Filter by events created before a given timestamp df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. Returns: Union[str, List[Dict[str, Any]], \"pd.DataFrame\"]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.export_logging() [{'timestamp': ..., 'username': ..., 'action': 'Manage/Design ', 'details': 'Create project ...'}, ...] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"log\" , format_type = format_type ) optional_args = [ ( \"returnFormat\" , return_format_type ), ( \"logtype\" , log_type ), ( \"user\" , user ), ( \"record\" , record ), ( \"dag\" , dag ), ( \"beginTime\" , begin_time ), ( \"endTime\" , end_time ), ] for arg in optional_args : arg_name , arg_value = arg if arg_value : if arg_name in [ \"beginTime\" , \"endTime\" ]: arg_value = cast ( datetime , arg_value ) arg_value = arg_value . strftime ( \"%Y-%m- %d %H:%M:%S\" ) payload [ arg_name ] = arg_value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"log\" , format_type = format_type , df_kwargs = df_kwargs , ) # pylint: enable=too-many-locals","title":"export_logging()"},{"location":"api_reference/metadata/","text":"Metadata REDCap API methods for Project metadata Metadata ( Base ) Responsible for all API methods under 'Metadata' in the API Playground Source code in redcap/methods/metadata.py class Metadata ( Base ): \"\"\"Responsible for all API methods under 'Metadata' in the API Playground\"\"\" def export_metadata ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , fields : Optional [ List [ str ]] = None , forms : Optional [ List [ str ]] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's metadata Args: format_type: Return the metadata in native objects, csv, or xml. `'df'` will return a `pandas.DataFrame` fields: Limit exported metadata to these fields forms: Limit exported metadata to these forms df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default `{'index_col': 'field_name'}` Returns: Union[str, List[Dict], pd.DataFrame]: Metadata structure for the project. Examples: >>> proj.export_metadata(format_type=\"df\") form_name section_header ... matrix_ranking field_annotation field_name ... record_id form_1 NaN ... NaN NaN field_1 form_1 NaN ... NaN NaN checkbox_field form_1 NaN ... NaN NaN upload_field form_1 NaN ... NaN NaN ... \"\"\" payload = self . _initialize_payload ( content = \"metadata\" , format_type = format_type ) to_add = [ fields , forms ] str_add = [ \"fields\" , \"forms\" ] for key , data in zip ( str_add , to_add ): if data : for i , value in enumerate ( data ): payload [ f \" { key } [ { i } ]\" ] = value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"metadata\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_metadata ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , date_format : Literal [ \"YMD\" , \"DMY\" , \"MDY\" ] = \"YMD\" , ): \"\"\" Import metadata (Data Dictionary) into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import_format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded date_format: Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. Returns: Union[int, str]: The number of imported fields Examples: >>> metadata = proj.export_metadata(format_type=\"csv\") >>> proj.import_metadata(metadata, import_format=\"csv\") 4 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"metadata\" , ) payload [ \"dateFormat\" ] = date_format return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server export_metadata ( self , format_type = 'json' , fields = None , forms = None , df_kwargs = None ) Export the project's metadata Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the metadata in native objects, csv, or xml. 'df' will return a pandas.DataFrame 'json' fields Optional[List[str]] Limit exported metadata to these fields None forms Optional[List[str]] Limit exported metadata to these forms None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default {'index_col': 'field_name'} None Returns: Type Description Union[str, List[Dict], pd.DataFrame] Metadata structure for the project. Examples: >>> proj . export_metadata ( format_type = \"df\" ) form_name section_header ... matrix_ranking field_annotation field_name ... record_id form_1 NaN ... NaN NaN field_1 form_1 NaN ... NaN NaN checkbox_field form_1 NaN ... NaN NaN upload_field form_1 NaN ... NaN NaN ... Source code in redcap/methods/metadata.py def export_metadata ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , fields : Optional [ List [ str ]] = None , forms : Optional [ List [ str ]] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's metadata Args: format_type: Return the metadata in native objects, csv, or xml. `'df'` will return a `pandas.DataFrame` fields: Limit exported metadata to these fields forms: Limit exported metadata to these forms df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default `{'index_col': 'field_name'}` Returns: Union[str, List[Dict], pd.DataFrame]: Metadata structure for the project. Examples: >>> proj.export_metadata(format_type=\"df\") form_name section_header ... matrix_ranking field_annotation field_name ... record_id form_1 NaN ... NaN NaN field_1 form_1 NaN ... NaN NaN checkbox_field form_1 NaN ... NaN NaN upload_field form_1 NaN ... NaN NaN ... \"\"\" payload = self . _initialize_payload ( content = \"metadata\" , format_type = format_type ) to_add = [ fields , forms ] str_add = [ \"fields\" , \"forms\" ] for key , data in zip ( str_add , to_add ): if data : for i , value in enumerate ( data ): payload [ f \" { key } [ { i } ]\" ] = value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"metadata\" , format_type = format_type , df_kwargs = df_kwargs , ) import_metadata ( self , to_import , return_format_type = 'json' , import_format = 'json' , date_format = 'YMD' ) Import metadata (Data Dictionary) into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import_format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' date_format Literal['YMD', 'DMY', 'MDY'] Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. 'YMD' Returns: Type Description Union[int, str] The number of imported fields Examples: >>> metadata = proj . export_metadata ( format_type = \"csv\" ) >>> proj . import_metadata ( metadata , import_format = \"csv\" ) 4 Source code in redcap/methods/metadata.py def import_metadata ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , date_format : Literal [ \"YMD\" , \"DMY\" , \"MDY\" ] = \"YMD\" , ): \"\"\" Import metadata (Data Dictionary) into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import_format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded date_format: Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. Returns: Union[int, str]: The number of imported fields Examples: >>> metadata = proj.export_metadata(format_type=\"csv\") >>> proj.import_metadata(metadata, import_format=\"csv\") 4 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"metadata\" , ) payload [ \"dateFormat\" ] = date_format return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"Metadata"},{"location":"api_reference/metadata/#metadata","text":"REDCap API methods for Project metadata","title":"Metadata"},{"location":"api_reference/metadata/#redcap.methods.metadata.Metadata","text":"Responsible for all API methods under 'Metadata' in the API Playground Source code in redcap/methods/metadata.py class Metadata ( Base ): \"\"\"Responsible for all API methods under 'Metadata' in the API Playground\"\"\" def export_metadata ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , fields : Optional [ List [ str ]] = None , forms : Optional [ List [ str ]] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's metadata Args: format_type: Return the metadata in native objects, csv, or xml. `'df'` will return a `pandas.DataFrame` fields: Limit exported metadata to these fields forms: Limit exported metadata to these forms df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default `{'index_col': 'field_name'}` Returns: Union[str, List[Dict], pd.DataFrame]: Metadata structure for the project. Examples: >>> proj.export_metadata(format_type=\"df\") form_name section_header ... matrix_ranking field_annotation field_name ... record_id form_1 NaN ... NaN NaN field_1 form_1 NaN ... NaN NaN checkbox_field form_1 NaN ... NaN NaN upload_field form_1 NaN ... NaN NaN ... \"\"\" payload = self . _initialize_payload ( content = \"metadata\" , format_type = format_type ) to_add = [ fields , forms ] str_add = [ \"fields\" , \"forms\" ] for key , data in zip ( str_add , to_add ): if data : for i , value in enumerate ( data ): payload [ f \" { key } [ { i } ]\" ] = value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"metadata\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_metadata ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , date_format : Literal [ \"YMD\" , \"DMY\" , \"MDY\" ] = \"YMD\" , ): \"\"\" Import metadata (Data Dictionary) into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import_format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded date_format: Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. Returns: Union[int, str]: The number of imported fields Examples: >>> metadata = proj.export_metadata(format_type=\"csv\") >>> proj.import_metadata(metadata, import_format=\"csv\") 4 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"metadata\" , ) payload [ \"dateFormat\" ] = date_format return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"Metadata"},{"location":"api_reference/metadata/#redcap.methods.metadata.Metadata.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/metadata/#redcap.methods.metadata.Metadata.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/metadata/#redcap.methods.metadata.Metadata.forms","text":"Project form names","title":"forms"},{"location":"api_reference/metadata/#redcap.methods.metadata.Metadata.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/metadata/#redcap.methods.metadata.Metadata.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/metadata/#redcap.methods.metadata.Metadata.token","text":"API token to a project","title":"token"},{"location":"api_reference/metadata/#redcap.methods.metadata.Metadata.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/metadata/#redcap.methods.metadata.Metadata.export_metadata","text":"Export the project's metadata Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the metadata in native objects, csv, or xml. 'df' will return a pandas.DataFrame 'json' fields Optional[List[str]] Limit exported metadata to these fields None forms Optional[List[str]] Limit exported metadata to these forms None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default {'index_col': 'field_name'} None Returns: Type Description Union[str, List[Dict], pd.DataFrame] Metadata structure for the project. Examples: >>> proj . export_metadata ( format_type = \"df\" ) form_name section_header ... matrix_ranking field_annotation field_name ... record_id form_1 NaN ... NaN NaN field_1 form_1 NaN ... NaN NaN checkbox_field form_1 NaN ... NaN NaN upload_field form_1 NaN ... NaN NaN ... Source code in redcap/methods/metadata.py def export_metadata ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , fields : Optional [ List [ str ]] = None , forms : Optional [ List [ str ]] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's metadata Args: format_type: Return the metadata in native objects, csv, or xml. `'df'` will return a `pandas.DataFrame` fields: Limit exported metadata to these fields forms: Limit exported metadata to these forms df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default `{'index_col': 'field_name'}` Returns: Union[str, List[Dict], pd.DataFrame]: Metadata structure for the project. Examples: >>> proj.export_metadata(format_type=\"df\") form_name section_header ... matrix_ranking field_annotation field_name ... record_id form_1 NaN ... NaN NaN field_1 form_1 NaN ... NaN NaN checkbox_field form_1 NaN ... NaN NaN upload_field form_1 NaN ... NaN NaN ... \"\"\" payload = self . _initialize_payload ( content = \"metadata\" , format_type = format_type ) to_add = [ fields , forms ] str_add = [ \"fields\" , \"forms\" ] for key , data in zip ( str_add , to_add ): if data : for i , value in enumerate ( data ): payload [ f \" { key } [ { i } ]\" ] = value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"metadata\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_metadata()"},{"location":"api_reference/metadata/#redcap.methods.metadata.Metadata.import_metadata","text":"Import metadata (Data Dictionary) into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import_format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' date_format Literal['YMD', 'DMY', 'MDY'] Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. 'YMD' Returns: Type Description Union[int, str] The number of imported fields Examples: >>> metadata = proj . export_metadata ( format_type = \"csv\" ) >>> proj . import_metadata ( metadata , import_format = \"csv\" ) 4 Source code in redcap/methods/metadata.py def import_metadata ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , date_format : Literal [ \"YMD\" , \"DMY\" , \"MDY\" ] = \"YMD\" , ): \"\"\" Import metadata (Data Dictionary) into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import_format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded date_format: Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. Returns: Union[int, str]: The number of imported fields Examples: >>> metadata = proj.export_metadata(format_type=\"csv\") >>> proj.import_metadata(metadata, import_format=\"csv\") 4 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"metadata\" , ) payload [ \"dateFormat\" ] = date_format return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_metadata()"},{"location":"api_reference/project/","text":"Project User facing class for interacting with a REDCap Project Project ( Arms , DataAccessGroups , Events , FieldNames , FileRepository , Files , Instruments , Logging , Metadata , ProjectInfo , Records , Repeating , Reports , Surveys , Users , UserRoles , Version ) Main class for interacting with REDCap projects Attributes: Name Type Description verify_ssl Verify SSL, default True. Can pass path to CA_BUNDLE !!! note Your REDCap token should be kept secret ! Treat it like a password and NEVER save it directly in your script/application. Rather it should be obscured and retrieved 'behind the scenes'. For example, saving the token as an environment variable and retrieving it with os.getenv . The creation of the TOKEN string in the example is not shown, for the above reasons Examples: >>> from redcap import Project >>> URL = \"https://redcapdemo.vumc.org/api/\" >>> proj = Project ( URL , TOKEN ) >>> proj . field_names [ 'record_id' , 'field_1' , 'checkbox_field' , 'upload_field' ] >>> proj . is_longitudinal True >>> proj . def_field 'record_id' The url and token attributes are read-only, to prevent users from accidentally overwriting them >>> proj . url = \"whoops\" Traceback ( most recent call last ): ... AttributeError : ... Source code in redcap/project.py class Project ( methods . arms . Arms , methods . data_access_groups . DataAccessGroups , methods . events . Events , methods . field_names . FieldNames , methods . file_repository . FileRepository , methods . files . Files , methods . instruments . Instruments , methods . logging . Logging , methods . metadata . Metadata , methods . project_info . ProjectInfo , methods . records . Records , methods . repeating . Repeating , methods . reports . Reports , methods . surveys . Surveys , methods . users . Users , methods . user_roles . UserRoles , methods . version . Version , ): \"\"\"Main class for interacting with REDCap projects Attributes: verify_ssl: Verify SSL, default True. Can pass path to CA_BUNDLE Note: Your REDCap token should be kept **secret**! Treat it like a password and NEVER save it directly in your script/application. Rather it should be obscured and retrieved 'behind the scenes'. For example, saving the token as an environment variable and retrieving it with `os.getenv`. The creation of the `TOKEN` string in the example is not shown, for the above reasons Examples: >>> from redcap import Project >>> URL = \"https://redcapdemo.vumc.org/api/\" >>> proj = Project(URL, TOKEN) >>> proj.field_names ['record_id', 'field_1', 'checkbox_field', 'upload_field'] >>> proj.is_longitudinal True >>> proj.def_field 'record_id' The url and token attributes are read-only, to prevent users from accidentally overwriting them >>> proj.url = \"whoops\" Traceback (most recent call last): ... AttributeError: ... \"\"\" @property def redcap_version ( self ) -> Optional [ semantic_version . Version ]: \"\"\"REDCap version of the Project\"\"\" self . _redcap_version : Optional [ semantic_version . Version ] try : return self . _redcap_version except AttributeError : # weird pylint bug on windows where it can't find Version.export_version() # possible too many parents it's inheriting from? We also need to disable # useless-supression since this is a windows only issue # pylint: disable=no-member,useless-suppression self . _redcap_version = self . export_version () # pylint: enable=no-member,useless-suppression return self . _redcap_version def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format redcap_version : Optional [ semantic_version . base . Version ] property readonly REDCap version of the Project token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server create_folder_in_repository ( self , name , folder_id = None , dag_id = None , role_id = None , format_type = 'json' , return_format_type = 'json' ) inherited Create a New Folder in the File Repository Parameters: Name Type Description Default name str The desired name of the folder to be created (max length = 150 characters) required folder_id Optional[int] The folder_id of a specific folder in the File Repository for which you wish to create this sub-folder. If none is provided, the folder will be created in the top-level directory of the File Repository. None dag_id Optional[int] The dag_id of the DAG (Data Access Group) to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all DAGs and users in no DAGs. None role_id Optional[int] The role_id of the User Role to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all User Roles and users in no User Roles. None format_type Literal['json', 'csv', 'xml'] Return the metadata in native objects, csv or xml. 'json' return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[str, List[Dict[str, Any]]] List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj . create_folder_in_repository ( name = \"New Folder\" ) [{ 'folder_id' : ... }] Source code in redcap/project.py def create_folder_in_repository ( self , name : str , folder_id : Optional [ int ] = None , dag_id : Optional [ int ] = None , role_id : Optional [ int ] = None , format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Create a New Folder in the File Repository Args: name: The desired name of the folder to be created (max length = 150 characters) folder_id: The folder_id of a specific folder in the File Repository for which you wish to create this sub-folder. If none is provided, the folder will be created in the top-level directory of the File Repository. dag_id: The dag_id of the DAG (Data Access Group) to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all DAGs and users in no DAGs. role_id: The role_id of the User Role to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all User Roles and users in no User Roles. format_type: Return the metadata in native objects, csv or xml. return_format_type: Response format. By default, response will be json-decoded. Returns: Union[str, List[Dict[str, Any]]]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.create_folder_in_repository(name=\"New Folder\") [{'folder_id': ...}] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" , format_type = format_type , return_format_type = return_format_type , ) payload [ \"action\" ] = \"createFolder\" payload [ \"name\" ] = name if folder_id : payload [ \"folder_id\" ] = folder_id if dag_id : payload [ \"dag_id\" ] = dag_id if role_id : payload [ \"role_id\" ] = role_id return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) return cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) delete_arms ( self , arms , return_format_type = 'json' ) inherited Delete Arms from the Project !!! note Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an arm also automatically deletes all events that belong to that arm, and will also automatically delete any records/data that have been collected under that arm (this is non-reversible data loss). This only works for longitudinal projects. Parameters: Name Type Description Default arms List[str] List of arm numbers to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of arms deleted Examples: Create a new arm >>> new_arm = [{ \"arm_num\" : 2 , \"name\" : \"Arm 2\" }] >>> proj . import_arms ( new_arm ) 1 Delete the new arm >>> proj . delete_arms ([ 2 ]) 1 Source code in redcap/project.py def delete_arms ( self , arms : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete Arms from the Project Note: Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an arm also automatically deletes all events that belong to that arm, and will also automatically delete any records/data that have been collected under that arm (this is non-reversible data loss). This only works for longitudinal projects. Args: arms: List of arm numbers to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of arms deleted Examples: Create a new arm >>> new_arm = [{\"arm_num\": 2, \"name\": \"Arm 2\"}] >>> proj.import_arms(new_arm) 1 Delete the new arm >>> proj.delete_arms([2]) 1 \"\"\" payload = self . _initialize_payload ( content = \"arm\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response delete_dags ( self , dags , return_format_type = 'json' ) inherited Delete dags from the project. Parameters: Name Type Description Default dags List[str] List of dags to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of dags deleted Examples: Create a new data access group >>> new_dag = [{ \"data_access_group_name\" : \"New DAG\" , \"unique_group_name\" : \"\" }] >>> proj . import_dags ( new_dag ) 1 We know that 'New DAG' will automatically be assigned 'new_dag' as it's unique group name >>> proj . delete_dags ([ \"new_dag\" ]) 1 Source code in redcap/project.py def delete_dags ( self , dags : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete dags from the project. Args: dags: List of dags to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of dags deleted Examples: Create a new data access group >>> new_dag = [{\"data_access_group_name\": \"New DAG\", \"unique_group_name\": \"\"}] >>> proj.import_dags(new_dag) 1 We know that 'New DAG' will automatically be assigned 'new_dag' as it's unique group name >>> proj.delete_dags([\"new_dag\"]) 1 \"\"\" payload = self . _initialize_payload ( content = \"dag\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of dags into dict, and append to payload dags_dict = { f \"dags[ { idx } ]\" : dag for idx , dag in enumerate ( dags )} payload . update ( dags_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response delete_events ( self , events , return_format_type = 'json' ) inherited Delete Events from the Project !!! note Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an event will automatically delete any records/data that have been collected under that event (this is non-reversible data loss). This only works for longitudinal projects. Parameters: Name Type Description Default events List[str] List of unique event names to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of events deleted Examples: Create a new event >>> new_event = [{ \"event_name\" : \"Event 2\" , \"arm_num\" : \"1\" }] >>> proj . import_events ( new_event ) 1 Delete the new event >>> proj . delete_events ([ \"event_2_arm_1\" ]) 1 Source code in redcap/project.py def delete_events ( self , events : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete Events from the Project Note: Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an event will automatically delete any records/data that have been collected under that event (this is non-reversible data loss). This only works for longitudinal projects. Args: events: List of unique event names to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of events deleted Examples: Create a new event >>> new_event = [{\"event_name\": \"Event 2\", \"arm_num\": \"1\"}] >>> proj.import_events(new_event) 1 Delete the new event >>> proj.delete_events([\"event_2_arm_1\"]) 1 \"\"\" payload = self . _initialize_payload ( content = \"event\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of events into dict, and append to payload events_dict = { f \"events[ { idx } ]\" : event for idx , event in enumerate ( events )} payload . update ( events_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response delete_file ( self , record , field , event = None ) inherited Delete a file from REDCap !!! note There is no undo button to this. Parameters: Name Type Description Default record str Record ID required field str Field name required event Optional[str] For longitudinal projects, the unique event name None Returns: Type Description List[dict] Empty JSON object Exceptions: Type Description ValueError Incorrect file field RedcapError Bad Request e.g. invalid record_id Examples: Import a tempfile and then delete it >>> import tempfile >>> tmp_file = tempfile . TemporaryFile () >>> proj . import_file ( ... record = \"2\" , ... field = \"upload_field\" , ... file_name = \"myupload.txt\" , ... file_object = tmp_file , ... event = \"event_1_arm_1\" , ... ) [{}] >>> proj . delete_file ( record = \"2\" , field = \"upload_field\" , event = \"event_1_arm_1\" ) [{}] Source code in redcap/project.py def delete_file ( self , record : str , field : str , event : Optional [ str ] = None , ) -> EmptyJson : \"\"\" Delete a file from REDCap Note: There is no undo button to this. Args: record: Record ID field: Field name event: For longitudinal projects, the unique event name Returns: Empty JSON object Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: Import a tempfile and then delete it >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file( ... record=\"2\", ... field=\"upload_field\", ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... event=\"event_1_arm_1\", ... ) [{}] >>> proj.delete_file(record=\"2\", field=\"upload_field\", event=\"event_1_arm_1\") [{}] \"\"\" self . _check_file_field ( field ) # Load up payload payload = self . _initialize_payload ( content = \"file\" ) payload [ \"action\" ] = \"delete\" payload [ \"record\" ] = record payload [ \"field\" ] = field if event : payload [ \"event\" ] = event return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" ) ) delete_file_from_repository ( self , doc_id , return_format_type = 'json' ) inherited Delete a File from the File Repository Once deleted, the file will remain in the Recycle Bin folder for up to 30 days. Parameters: Name Type Description Default doc_id int The doc_id of the file in the File Repository required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description List[dict] Empty JSON object Examples: >>> file_dir = proj . export_file_repository () >>> test_folder = [ folder for folder in file_dir if folder [ \"name\" ] == \"test\" ] . pop () >>> test_dir = proj . export_file_repository ( folder_id = test_folder [ \"folder_id\" ]) >>> test_file = [ file for file in test_dir if file [ \"name\" ] == \"test_in_folder.txt\" ] . pop () >>> proj . delete_file_from_repository ( doc_id = test_file [ \"doc_id\" ]) [{}] Source code in redcap/project.py def delete_file_from_repository ( self , doc_id : int , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ) -> EmptyJson : # pylint: disable=line-too-long \"\"\" Delete a File from the File Repository Once deleted, the file will remain in the Recycle Bin folder for up to 30 days. Args: doc_id: The doc_id of the file in the File Repository return_format_type: Response format. By default, response will be json-decoded. Returns: Empty JSON object Examples: >>> file_dir = proj.export_file_repository() >>> test_folder = [folder for folder in file_dir if folder[\"name\"] == \"test\"].pop() >>> test_dir = proj.export_file_repository(folder_id=test_folder[\"folder_id\"]) >>> test_file = [file for file in test_dir if file[\"name\"] == \"test_in_folder.txt\"].pop() >>> proj.delete_file_from_repository(doc_id=test_file[\"doc_id\"]) [{}] \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"fileRepository\" , return_format_type = return_format_type ) # there's no format field in this call payload [ \"action\" ] = \"delete\" payload [ \"doc_id\" ] = doc_id return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" ) ) delete_records ( self , records , arm = None , instrument = None , event = None , repeat_instance = None , delete_logging = False , return_format_type = 'json' ) inherited Delete records from the project. Parameters: Name Type Description Default records List[str] List of record IDs to delete from the project required arm Optional[str] the arm number of the arm in which the record(s) should be deleted. (This can only be used if the project is longitudinal with more than one arm.) NOTE: If the arm parameter is not provided, the specified records will be deleted from all arms in which they exist. Whereas, if arm is provided, they will only be deleted from the specified arm. None instrument Optional[str] the unique instrument name (column B in the Data Dictionary) of an instrument (as a string) if you wish to delete the data for all fields on the specified instrument for the records specified. None event Optional[str] the unique event name - only for longitudinal projects. NOTE: If instrument is provided for a longitudinal project, the event parameter is mandatory. None repeat_instance Optional[int] the repeating instance number for a repeating instrument or repeating event. NOTE: If project has repeating instruments/events, it will remove only the data for that repeating instance. None delete_logging bool provide a value of False (\"keep logging\") or True (\"delete logging\"). This activity when deleting the record?\" setting enabled by an administrator on the Edit Project Settings page. The default value for PyCap is False False return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of records deleted Examples: >>> new_records = [ ... { \"record_id\" : 3 , \"redcap_repeat_instance\" : 1 , \"field_1\" : 1 }, ... { \"record_id\" : 4 , \"redcap_repeat_instance\" : 1 } ... ] >>> proj . import_records ( new_records ) { 'count' : 2 } >>> proj . delete_records ([ \"3\" , \"4\" ]) 2 >>> new_record = [ ... { \"record_id\" : 3 , \"redcap_event_name\" : \"event_1_arm_1\" , \"redcap_repeat_instance\" : 1 , \"field_1\" : 1 ,}, ... { \"record_id\" : 3 , \"redcap_event_name\" : \"event_1_arm_1\" , \"redcap_repeat_instance\" : 2 , \"field_1\" : 0 ,}, ... ] >>> proj . import_records ( new_record ) { 'count' : 1 } >>> proj . delete_records ( records = [ \"3\" ], event = \"event_1_arm_1\" , repeat_instance = 2 ) 1 >>> proj . export_records ( records = [ \"3\" ]) [{ 'record_id' : '3' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '0' , 'upload_field' : '' , 'form_1_complete' : '0' }] >>> proj . delete_records ( records = [ \"3\" ]) 1 Source code in redcap/project.py def delete_records ( self , records : List [ str ], arm : Optional [ str ] = None , instrument : Optional [ str ] = None , event : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , delete_logging : bool = False , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): # pylint: disable=line-too-long \"\"\" Delete records from the project. Args: records: List of record IDs to delete from the project arm: the arm number of the arm in which the record(s) should be deleted. (This can only be used if the project is longitudinal with more than one arm.) NOTE: If the arm parameter is not provided, the specified records will be deleted from all arms in which they exist. Whereas, if arm is provided, they will only be deleted from the specified arm. instrument: the unique instrument name (column B in the Data Dictionary) of an instrument (as a string) if you wish to delete the data for all fields on the specified instrument for the records specified. event: the unique event name - only for longitudinal projects. NOTE: If instrument is provided for a longitudinal project, the event parameter is mandatory. repeat_instance: the repeating instance number for a repeating instrument or repeating event. NOTE: If project has repeating instruments/events, it will remove only the data for that repeating instance. delete_logging: provide a value of False (\"keep logging\") or True (\"delete logging\"). This activity when deleting the record?\" setting enabled by an administrator on the Edit Project Settings page. The default value for PyCap is False return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of records deleted Examples: >>> new_records = [ ... {\"record_id\": 3, \"redcap_repeat_instance\": 1, \"field_1\": 1}, ... {\"record_id\": 4, \"redcap_repeat_instance\": 1} ... ] >>> proj.import_records(new_records) {'count': 2} >>> proj.delete_records([\"3\", \"4\"]) 2 >>> new_record = [ ... {\"record_id\": 3, \"redcap_event_name\": \"event_1_arm_1\", \"redcap_repeat_instance\": 1, \"field_1\": 1,}, ... {\"record_id\": 3, \"redcap_event_name\": \"event_1_arm_1\", \"redcap_repeat_instance\": 2, \"field_1\": 0,}, ... ] >>> proj.import_records(new_record) {'count': 1} >>> proj.delete_records(records=[\"3\"], event=\"event_1_arm_1\", repeat_instance=2) 1 >>> proj.export_records(records=[\"3\"]) [{'record_id': '3', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '0', 'upload_field': '', 'form_1_complete': '0'}] >>> proj.delete_records(records=[\"3\"]) 1 \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"record\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" if delete_logging : payload [ \"delete_logging\" ] = \"1\" else : payload [ \"delete_logging\" ] = \"0\" if arm : payload [ \"arm\" ] = arm if instrument : payload [ \"instrument\" ] = instrument if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = repeat_instance # Turn list of records into dict, and append to payload records_dict = { f \"records[ { idx } ]\" : record for idx , record in enumerate ( records ) } payload . update ( records_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response delete_user_roles ( self , roles , return_format_type = 'json' ) inherited Delete user roles from the project. Parameters: Name Type Description Default roles List[str] List of user roles to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of user roles deleted Examples: Create a new user role >>> new_role = [{ \"role_label\" : \"New Role\" }] >>> proj . import_user_roles ( new_role ) 1 We don't know what the 'unique_role_name' is for the newly created role, so we have to look it up by 'role_label' >>> roles = proj . export_user_roles () >>> new_role_id = [ ... role for role in roles ... if role [ \"role_label\" ] == \"New Role\" ... ][ 0 ][ \"unique_role_name\" ] Delete the role >>> proj . delete_user_roles ([ new_role_id ]) 1 Source code in redcap/project.py def delete_user_roles ( self , roles : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete user roles from the project. Args: roles: List of user roles to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of user roles deleted Examples: Create a new user role >>> new_role = [{\"role_label\": \"New Role\"}] >>> proj.import_user_roles(new_role) 1 We don't know what the 'unique_role_name' is for the newly created role, so we have to look it up by 'role_label' >>> roles = proj.export_user_roles() >>> new_role_id = [ ... role for role in roles ... if role[\"role_label\"] == \"New Role\" ... ][0][\"unique_role_name\"] Delete the role >>> proj.delete_user_roles([new_role_id]) 1 \"\"\" payload = self . _initialize_payload ( content = \"userRole\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of user roles into dict, and append to payload roles_dict = { f \"roles[ { idx } ]\" : role for idx , role in enumerate ( roles )} payload . update ( roles_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response delete_users ( self , users , return_format_type = 'json' ) inherited Delete users from the project. Parameters: Name Type Description Default users List[str] List of usernames to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of users deleted Examples: >>> new_user = [{ \"username\" : \"pandeharris@gmail.com\" }] >>> proj . import_users ( new_user ) 1 >>> proj . delete_users ([ \"pandeharris@gmail.com\" ], return_format_type = \"xml\" ) '1' Source code in redcap/project.py def delete_users ( self , users : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete users from the project. Args: users: List of usernames to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of users deleted Examples: >>> new_user = [{\"username\": \"pandeharris@gmail.com\"}] >>> proj.import_users(new_user) 1 >>> proj.delete_users([\"pandeharris@gmail.com\"], return_format_type=\"xml\") '1' \"\"\" payload = self . _initialize_payload ( content = \"user\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of users into dict, and append to payload users_dict = { f \"users[ { idx } ]\" : user for idx , user in enumerate ( users )} payload . update ( users_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response export_arms ( self , format_type = 'json' , arms = None ) inherited Export the Arms of the Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' arms Optional[List[str]] An array of arm numbers that you wish to pull arms for (by default, all arms are pulled) None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of Arms Examples: >>> proj . export_arms () [{ 'arm_num' : 1 , 'name' : 'Arm 1' }] Source code in redcap/project.py def export_arms ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , ): \"\"\" Export the Arms of the Project Note: This only works for longitudinal projects. Args: format_type: Response return format arms: An array of arm numbers that you wish to pull arms for (by default, all arms are pulled) Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Arms Examples: >>> proj.export_arms() [{'arm_num': 1, 'name': 'Arm 1'}] \"\"\" payload = self . _initialize_payload ( content = \"arm\" , format_type = format_type ) if arms : # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"arm\" , format_type = format_type , ) export_dags ( self , format_type = 'json' , df_kwargs = None ) inherited Export the DAGs of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of DAGs Examples: >>> proj . export_dags () [{ 'data_access_group_name' : 'Test DAG' , 'unique_group_name' : 'test_dag' , 'data_access_group_id' : ... }] Source code in redcap/project.py def export_dags ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long \"\"\" Export the DAGs of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of DAGs Examples: >>> proj.export_dags() [{'data_access_group_name': 'Test DAG', 'unique_group_name': 'test_dag', 'data_access_group_id': ...}] \"\"\" # pylint:enable=line-too-long payload = self . _initialize_payload ( content = \"dag\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"dag\" , format_type = format_type , df_kwargs = df_kwargs , ) export_events ( self , format_type = 'json' , arms = None ) inherited Export the Events of the Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' arms Optional[List[str]] An array of arm numbers that you wish to pull events for (by default, all events are pulled) None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of Events Examples: >>> proj . export_events () [{ 'event_name' : 'Event 1' , 'arm_num' : 1 , 'unique_event_name' : 'event_1_arm_1' , 'custom_event_label' : '' , 'event_id' : ... }, { 'event_name' : 'Event 2' , ... }] Source code in redcap/project.py def export_events ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , ): \"\"\" Export the Events of the Project Note: This only works for longitudinal projects. Args: format_type: Response return format arms: An array of arm numbers that you wish to pull events for (by default, all events are pulled) Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Events Examples: >>> proj.export_events() [{'event_name': 'Event 1', 'arm_num': 1, 'unique_event_name': 'event_1_arm_1', 'custom_event_label': '', 'event_id': ...}, {'event_name': 'Event 2', ...}] \"\"\" payload = self . _initialize_payload ( content = \"event\" , format_type = format_type ) if arms : # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"event\" , format_type = format_type , ) export_field_names ( self , format_type = 'json' , field = None , df_kwargs = None ) inherited Export the project's export field names Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the metadata in native objects, csv or xml. 'df' will return a pandas.DataFrame 'json' field Optional[str] Limit exported field name to this field (only single field supported). When not provided, all fields returned None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. by default {'index_col': 'original_field_name'} None Returns: Type Description Union[str, List[Dict[str, Any]], \"pd.DataFrame\"] Metadata structure for the project. Examples: >>> proj . export_field_names () [{ 'original_field_name' : 'record_id' , 'choice_value' : '' , 'export_field_name' : 'record_id' }, { 'original_field_name' : 'field_1' , 'choice_value' : '' , 'export_field_name' : 'field_1' }, { 'original_field_name' : 'checkbox_field' , 'choice_value' : '1' , 'export_field_name' : 'checkbox_field___1' }, { 'original_field_name' : 'checkbox_field' , 'choice_value' : '2' , 'export_field_name' : 'checkbox_field___2' }, { 'original_field_name' : 'form_1_complete' , 'choice_value' : '' , 'export_field_name' : 'form_1_complete' }] Source code in redcap/project.py def export_field_names ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , field : Optional [ str ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long \"\"\" Export the project's export field names Args: format_type: Return the metadata in native objects, csv or xml. `'df'` will return a `pandas.DataFrame` field: Limit exported field name to this field (only single field supported). When not provided, all fields returned df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. by default `{'index_col': 'original_field_name'}` Returns: Union[str, List[Dict[str, Any]], \"pd.DataFrame\"]: Metadata structure for the project. Examples: >>> proj.export_field_names() [{'original_field_name': 'record_id', 'choice_value': '', 'export_field_name': 'record_id'}, {'original_field_name': 'field_1', 'choice_value': '', 'export_field_name': 'field_1'}, {'original_field_name': 'checkbox_field', 'choice_value': '1', 'export_field_name': 'checkbox_field___1'}, {'original_field_name': 'checkbox_field', 'choice_value': '2', 'export_field_name': 'checkbox_field___2'}, {'original_field_name': 'form_1_complete', 'choice_value': '', 'export_field_name': 'form_1_complete'}] \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"exportFieldNames\" , format_type = format_type ) if field : payload [ \"field\" ] = field return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"exportFieldNames\" , format_type = format_type , df_kwargs = df_kwargs , ) export_file ( self , record , field , event = None , repeat_instance = None ) inherited Export the contents of a file stored for a particular record !!! note Unlike other export methods, this only works on a single record. Parameters: Name Type Description Default record str Record ID required field str Field name containing the file to be exported. required event Optional[str] For longitudinal projects, the unique event name None repeat_instance Optional[int] (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). None Returns: Type Description Tuple[bytes, dict] Content of the file and content-type dictionary Exceptions: Type Description ValueError Incorrect file field RedcapError Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> proj . export_file ( record = \"1\" , field = \"upload_field\" , event = \"event_1_arm_1\" ) ( b 'test upload \\n ' , { 'name' : 'test_upload.txt' , 'charset' : 'UTF-8' }) Source code in redcap/project.py def export_file ( self , record : str , field : str , event : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , ) -> FileMap : \"\"\" Export the contents of a file stored for a particular record Note: Unlike other export methods, this only works on a single record. Args: record: Record ID field: Field name containing the file to be exported. event: For longitudinal projects, the unique event name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Returns: Content of the file and content-type dictionary Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> proj.export_file(record=\"1\", field=\"upload_field\", event=\"event_1_arm_1\") (b'test upload\\\\n', {'name': 'test_upload.txt', 'charset': 'UTF-8'}) \"\"\" self . _check_file_field ( field ) # load up payload payload = self . _initialize_payload ( content = \"file\" ) # there's no format field in this call payload [ \"action\" ] = \"export\" payload [ \"field\" ] = field payload [ \"record\" ] = record if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = str ( repeat_instance ) content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map export_file_from_repository ( self , doc_id , return_format_type = 'json' ) inherited Export the contents of a file stored in the File Repository Parameters: Name Type Description Default doc_id int The doc_id of the file in the File Repository required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Tuple[bytes, dict] Content of the file and content-type dictionary Examples: >>> file_dir = proj . export_file_repository () >>> text_file = [ file for file in file_dir if file [ \"name\" ] == \"test.txt\" ] . pop () >>> proj . export_file_from_repository ( doc_id = text_file [ \"doc_id\" ]) ( b 'hello' , { 'name' : 'test.txt' , 'charset' : 'UTF-8' }) Source code in redcap/project.py def export_file_from_repository ( self , doc_id : int , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ) -> FileMap : \"\"\" Export the contents of a file stored in the File Repository Args: doc_id: The doc_id of the file in the File Repository return_format_type: Response format. By default, response will be json-decoded. Returns: Content of the file and content-type dictionary Examples: >>> file_dir = proj.export_file_repository() >>> text_file = [file for file in file_dir if file[\"name\"] == \"test.txt\"].pop() >>> proj.export_file_from_repository(doc_id=text_file[\"doc_id\"]) (b'hello', {'name': 'test.txt', 'charset': 'UTF-8'}) \"\"\" payload = self . _initialize_payload ( content = \"fileRepository\" , return_format_type = return_format_type ) # there's no format field in this call payload [ \"action\" ] = \"export\" payload [ \"doc_id\" ] = doc_id content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map export_file_repository ( self , folder_id = None , format_type = 'json' , return_format_type = 'json' ) inherited Export of list of files/folders in the File Repository Only exports the top-level of files/folders. To see which files are contained within a folder, use the folder_id parameter Parameters: Name Type Description Default folder_id Optional[int] The folder_id of a specific folder in the File Repository for which you wish to search for files/folders. If none is provided, the search will be conducted in the top-level directory of the File Repository. None format_type Literal['json', 'csv', 'xml'] Return the metadata in native objects, csv or xml. 'json' return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[str, List[Dict[str, Any]]] List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj . export_file_repository () [{ 'folder_id' : ... , 'name' : 'New Folder' }, ... ] Source code in redcap/project.py def export_file_repository ( self , folder_id : Optional [ int ] = None , format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Export of list of files/folders in the File Repository Only exports the top-level of files/folders. To see which files are contained within a folder, use the `folder_id` parameter Args: folder_id: The folder_id of a specific folder in the File Repository for which you wish to search for files/folders. If none is provided, the search will be conducted in the top-level directory of the File Repository. format_type: Return the metadata in native objects, csv or xml. return_format_type: Response format. By default, response will be json-decoded. Returns: Union[str, List[Dict[str, Any]]]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.export_file_repository() [{'folder_id': ..., 'name': 'New Folder'}, ...] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" , format_type = format_type , return_format_type = return_format_type , ) payload [ \"action\" ] = \"list\" if folder_id : payload [ \"folder_id\" ] = folder_id return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) return cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) export_instrument_event_mappings ( self , format_type = 'json' , arms = None , df_kwargs = None ) inherited Export the project's instrument to event mapping Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the form event mappings in native objects, csv or xml, 'df'' will return a pandas.DataFrame 'json' arms Optional[List[str]] Limit exported form event mappings to these arms None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame None Returns: Type Description Union[str, List[Dict[str, Any]], pd.DataFrame] Instrument-event mapping for the project Examples: >>> proj . export_instrument_event_mappings () [{ 'arm_num' : 1 , 'unique_event_name' : 'event_1_arm_1' , 'form' : 'form_1' }] Source code in redcap/project.py def export_instrument_event_mappings ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's instrument to event mapping Args: format_type: Return the form event mappings in native objects, csv or xml, `'df''` will return a `pandas.DataFrame` arms: Limit exported form event mappings to these arms df_kwargs: Passed to pandas.read_csv to control construction of returned DataFrame Returns: Union[str, List[Dict[str, Any]], pd.DataFrame]: Instrument-event mapping for the project Examples: >>> proj.export_instrument_event_mappings() [{'arm_num': 1, 'unique_event_name': 'event_1_arm_1', 'form': 'form_1'}] \"\"\" payload = self . _initialize_payload ( content = \"formEventMapping\" , format_type = format_type ) if arms : for i , value in enumerate ( arms ): payload [ f \"arms[ { i } ]\" ] = value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"formEventMapping\" , format_type = format_type , df_kwargs = df_kwargs , ) export_instruments ( self , format_type = 'json' ) inherited Export the Instruments of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of Instruments Examples: >>> proj . export_instruments () [{ 'instrument_name' : 'form_1' , 'instrument_label' : 'Form 1' }] Source code in redcap/project.py def export_instruments ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Export the Instruments of the Project Args: format_type: Response return format Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Instruments Examples: >>> proj.export_instruments() [{'instrument_name': 'form_1', 'instrument_label': 'Form 1'}] \"\"\" payload = self . _initialize_payload ( content = \"instrument\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"instrument\" , format_type = format_type , ) export_logging ( self , format_type = 'json' , return_format_type = None , log_type = None , user = None , record = None , dag = None , begin_time = None , end_time = None , df_kwargs = None ) inherited Export the project's logs Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the metadata in native objects, csv or xml. 'df' will return a pandas.DataFrame 'json' return_format_type Optional[Literal['json', 'csv', 'xml']] Response format. By default, response will be json-decoded. None log_type Optional[Literal['export', 'manage', 'user', 'record', 'record_add', 'record_edit', 'record_delete', 'lock_record', 'page_view']] Filter by specific event types None user Optional[str] Filter by events created by a certain user None record Optional[str] Filter by events created for a certain record None dag Optional[str] Filter by events created by a certain data access group (group ID) None begin_time Optional[datetime.datetime] Filter by events created after a given timestamp None end_time Optional[datetime.datetime] Filter by events created before a given timestamp None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. None Returns: Type Description Union[str, List[Dict[str, Any]], \"pd.DataFrame\"] List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj . export_logging () [{ 'timestamp' : ... , 'username' : ... , 'action' : 'Manage/Design ' , 'details' : 'Create project ...' }, ... ] Source code in redcap/project.py def export_logging ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , return_format_type : Optional [ Literal [ \"json\" , \"csv\" , \"xml\" ]] = None , log_type : Optional [ Literal [ \"export\" , \"manage\" , \"user\" , \"record\" , \"record_add\" , \"record_edit\" , \"record_delete\" , \"lock_record\" , \"page_view\" , ] ] = None , user : Optional [ str ] = None , record : Optional [ str ] = None , dag : Optional [ str ] = None , begin_time : Optional [ datetime ] = None , end_time : Optional [ datetime ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's logs Args: format_type: Return the metadata in native objects, csv or xml. `'df'` will return a `pandas.DataFrame` return_format_type: Response format. By default, response will be json-decoded. log_type: Filter by specific event types user: Filter by events created by a certain user record: Filter by events created for a certain record dag: Filter by events created by a certain data access group (group ID) begin_time: Filter by events created after a given timestamp end_time: Filter by events created before a given timestamp df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. Returns: Union[str, List[Dict[str, Any]], \"pd.DataFrame\"]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.export_logging() [{'timestamp': ..., 'username': ..., 'action': 'Manage/Design ', 'details': 'Create project ...'}, ...] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"log\" , format_type = format_type ) optional_args = [ ( \"returnFormat\" , return_format_type ), ( \"logtype\" , log_type ), ( \"user\" , user ), ( \"record\" , record ), ( \"dag\" , dag ), ( \"beginTime\" , begin_time ), ( \"endTime\" , end_time ), ] for arg in optional_args : arg_name , arg_value = arg if arg_value : if arg_name in [ \"beginTime\" , \"endTime\" ]: arg_value = cast ( datetime , arg_value ) arg_value = arg_value . strftime ( \"%Y-%m- %d %H:%M:%S\" ) payload [ arg_name ] = arg_value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"log\" , format_type = format_type , df_kwargs = df_kwargs , ) # pylint: enable=too-many-locals export_metadata ( self , format_type = 'json' , fields = None , forms = None , df_kwargs = None ) inherited Export the project's metadata Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the metadata in native objects, csv, or xml. 'df' will return a pandas.DataFrame 'json' fields Optional[List[str]] Limit exported metadata to these fields None forms Optional[List[str]] Limit exported metadata to these forms None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default {'index_col': 'field_name'} None Returns: Type Description Union[str, List[Dict], pd.DataFrame] Metadata structure for the project. Examples: >>> proj . export_metadata ( format_type = \"df\" ) form_name section_header ... matrix_ranking field_annotation field_name ... record_id form_1 NaN ... NaN NaN field_1 form_1 NaN ... NaN NaN checkbox_field form_1 NaN ... NaN NaN upload_field form_1 NaN ... NaN NaN ... Source code in redcap/project.py def export_metadata ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , fields : Optional [ List [ str ]] = None , forms : Optional [ List [ str ]] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's metadata Args: format_type: Return the metadata in native objects, csv, or xml. `'df'` will return a `pandas.DataFrame` fields: Limit exported metadata to these fields forms: Limit exported metadata to these forms df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default `{'index_col': 'field_name'}` Returns: Union[str, List[Dict], pd.DataFrame]: Metadata structure for the project. Examples: >>> proj.export_metadata(format_type=\"df\") form_name section_header ... matrix_ranking field_annotation field_name ... record_id form_1 NaN ... NaN NaN field_1 form_1 NaN ... NaN NaN checkbox_field form_1 NaN ... NaN NaN upload_field form_1 NaN ... NaN NaN ... \"\"\" payload = self . _initialize_payload ( content = \"metadata\" , format_type = format_type ) to_add = [ fields , forms ] str_add = [ \"fields\" , \"forms\" ] for key , data in zip ( str_add , to_add ): if data : for i , value in enumerate ( data ): payload [ f \" { key } [ { i } ]\" ] = value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"metadata\" , format_type = format_type , df_kwargs = df_kwargs , ) export_pdf ( self , record = None , event = None , instrument = None , repeat_instance = None , all_records = None , compact_display = None ) inherited Export PDF file of instruments, either as blank or with data Parameters: Name Type Description Default record Optional[str] Record ID None event Optional[str] For longitudinal projects, the unique event name None instrument Optional[str] Unique instrument name None repeat_instance Optional[int] (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). None all_records Optional[bool] If True, then all records will be exported as a single PDF file. Note: If this is True, then record, event, and instrument parameters are all ignored. None compact_display Optional[bool] If True, then the PDF will be exported in compact display mode. None Returns: Type Description Tuple[bytes, dict] Content of the file and dictionary of useful metadata Examples: >>> proj . export_pdf () ( b '%PDF-1.3 \\n 3 0 obj \\n ..., {...}) Source code in redcap/project.py def export_pdf ( self , record : Optional [ str ] = None , event : Optional [ str ] = None , instrument : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , all_records : Optional [ bool ] = None , compact_display : Optional [ bool ] = None , ) -> FileMap : \"\"\" Export PDF file of instruments, either as blank or with data Args: record: Record ID event: For longitudinal projects, the unique event name instrument: Unique instrument name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). all_records: If True, then all records will be exported as a single PDF file. Note: If this is True, then record, event, and instrument parameters are all ignored. compact_display: If True, then the PDF will be exported in compact display mode. Returns: Content of the file and dictionary of useful metadata Examples: >>> proj.export_pdf() (b'%PDF-1.3\\\\n3 0 obj\\\\n..., {...}) \"\"\" # load up payload payload = self . _initialize_payload ( content = \"pdf\" , return_format_type = \"json\" ) keys_to_add = ( record , event , instrument , repeat_instance , all_records , compact_display , ) str_keys = ( \"record\" , \"event\" , \"instrument\" , \"repeat_instance\" , \"allRecords\" , \"compactDisplay\" , ) for key , data in zip ( str_keys , keys_to_add ): data = cast ( str , data ) if data : payload [ key ] = data payload [ \"action\" ] = \"export\" content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map export_project_info ( self , format_type = 'json' , df_kwargs = None ) inherited Export Project Information Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[str, List[Dict[str, Any]], pandas.DataFrame] Project information Examples: >>> proj . export_project_info () { 'project_id' : ... ... 'in_production' : 0 , 'project_language' : 'English' , 'purpose' : 0 , 'purpose_other' : '' , ... 'project_grant_number' : '' , 'project_pi_firstname' : '' , 'project_pi_lastname' : '' , ... 'bypass_branching_erase_field_prompt' : 0 } Source code in redcap/project.py def export_project_info ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export Project Information Args: format_type: Format of returned data df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[str, List[Dict[str, Any]], pandas.DataFrame]: Project information Examples: >>> proj.export_project_info() {'project_id': ... ... 'in_production': 0, 'project_language': 'English', 'purpose': 0, 'purpose_other': '', ... 'project_grant_number': '', 'project_pi_firstname': '', 'project_pi_lastname': '', ... 'bypass_branching_erase_field_prompt': 0} \"\"\" payload = self . _initialize_payload ( content = \"project\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"project\" , format_type = format_type , df_kwargs = df_kwargs , ) export_records ( self , format_type = 'json' , records = None , fields = None , forms = None , events = None , raw_or_label = 'raw' , raw_or_label_headers = 'raw' , event_name = 'label' , record_type = 'flat' , export_survey_fields = False , export_data_access_groups = False , export_checkbox_labels = False , filter_logic = None , date_begin = None , date_end = None , decimal_character = None , export_blank_for_gray_form_status = None , df_kwargs = None ) inherited Export data from the REDCap project. Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data. 'json' returns json-decoded objects while 'csv' and 'xml' return other formats. 'df' will attempt to return a pandas.DataFrame 'json' records Optional[List[str]] Array of record names specifying specific records to export. By default, all records are exported None fields Union[List[str], str] Single field name or array of field names specifying specific fields to pull. By default, all fields are exported None forms Union[List[str], str] Single form name or array of form names to export. If in the web UI, the form name has a space in it, replace the space with an underscore. By default, all forms are exported None events Optional[List[str]] An array of unique event names from which to export records Note: This only applies to longitudinal projects None raw_or_label Literal['raw', 'label', 'both'] Export the raw coded values or labels for the options of multiple choice fields, or both 'raw' raw_or_label_headers Literal['raw', 'label'] Export the column names of the instrument as their raw value or their labeled value 'raw' event_name Literal['label', 'unique'] Export the unique event name or the event label 'label' record_type Literal['flat', 'eav'] Database output structure type 'flat' export_survey_fields bool Specifies whether or not to export the survey identifier field (e.g., \"redcap_survey_identifier\") or survey timestamp fields (e.g., form_name+\"_timestamp\") when surveys are utilized in the project False export_data_access_groups bool Specifies whether or not to export the \"redcap_data_access_group\" field when data access groups are utilized in the project Note: This flag is only viable if the user whose token is being used to make the API request is not in a data access group. If the user is in a group, then this flag will revert to its default value. False export_checkbox_labels bool Specify whether to export checkbox values as their label on export. False filter_logic Optional[str] Filter which records are returned using REDCap conditional syntax None date_begin Optional[datetime.datetime] Filter on records created after a date None date_end Optional[datetime.datetime] Filter on records created before a date None decimal_character Optional[Literal[',', '.']] Force all numbers into same decimal format None export_blank_for_gray_form_status Optional[bool] Whether or not to export blank values for instrument complete status fields that have a gray status icon None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, {'index_col': self.def_field} None Returns: Type Description Union[List[Dict[str, Any]], str, pd.DataFrame] Exported data Examples: >>> proj . export_records () [{ 'record_id' : '1' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '1' , 'upload_field' : 'test_upload.txt' , 'form_1_complete' : '2' }, { 'record_id' : '2' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '0' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '0' , 'upload_field' : 'myupload.txt' , 'form_1_complete' : '0' }] >>> proj . export_records ( filter_logic = \"[field_1] = 1\" ) [{ 'record_id' : '1' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '1' , 'upload_field' : 'test_upload.txt' , 'form_1_complete' : '2' }] >>> proj . export_records ( ... format_type = \"csv\" , ... fields = [ \"field_1\" , \"checkbox_field\" ], ... raw_or_label = \"label\" ... ) 'record_id,redcap_event_name,redcap_repeat_instrument,redcap_repeat_instance,field_1,checkbox_field___1,checkbox_field___2 \\n 1,\"Event 1\",,1,Yes,Unchecked,Checked \\n 2,\"Event 1\",,1,No,Unchecked,Unchecked \\n ' >>> import pandas as pd >>> pd . set_option ( \"display.max_columns\" , 3 ) >>> proj . export_records ( format_type = \"df\" ) redcap_repeat_instrument ... form_1_complete record_id redcap_event_name ... 1 event_1_arm_1 NaN ... 2 2 event_1_arm_1 NaN ... 0 ... Source code in redcap/project.py def export_records ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , records : Optional [ List [ str ]] = None , fields : Optional [ Union [ List [ str ], str ]] = None , forms : Optional [ Union [ List [ str ], str ]] = None , events : Optional [ List [ str ]] = None , raw_or_label : Literal [ \"raw\" , \"label\" , \"both\" ] = \"raw\" , raw_or_label_headers : Literal [ \"raw\" , \"label\" ] = \"raw\" , event_name : Literal [ \"label\" , \"unique\" ] = \"label\" , record_type : Literal [ \"flat\" , \"eav\" ] = \"flat\" , export_survey_fields : bool = False , export_data_access_groups : bool = False , export_checkbox_labels : bool = False , filter_logic : Optional [ str ] = None , date_begin : Optional [ datetime ] = None , date_end : Optional [ datetime ] = None , decimal_character : Optional [ Literal [ \",\" , \".\" ]] = None , export_blank_for_gray_form_status : Optional [ bool ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long r \"\"\" Export data from the REDCap project. Args: format_type: Format of returned data. `'json'` returns json-decoded objects while `'csv'` and `'xml'` return other formats. `'df'` will attempt to return a `pandas.DataFrame` records: Array of record names specifying specific records to export. By default, all records are exported fields: Single field name or array of field names specifying specific fields to pull. By default, all fields are exported forms: Single form name or array of form names to export. If in the web UI, the form name has a space in it, replace the space with an underscore. By default, all forms are exported events: An array of unique event names from which to export records Note: This only applies to longitudinal projects raw_or_label: Export the raw coded values or labels for the options of multiple choice fields, or both raw_or_label_headers: Export the column names of the instrument as their raw value or their labeled value event_name: Export the unique event name or the event label record_type: Database output structure type export_survey_fields: Specifies whether or not to export the survey identifier field (e.g., \"redcap_survey_identifier\") or survey timestamp fields (e.g., form_name+\"_timestamp\") when surveys are utilized in the project export_data_access_groups: Specifies whether or not to export the `\"redcap_data_access_group\"` field when data access groups are utilized in the project Note: This flag is only viable if the user whose token is being used to make the API request is *not* in a data access group. If the user is in a group, then this flag will revert to its default value. export_checkbox_labels: Specify whether to export checkbox values as their label on export. filter_logic: Filter which records are returned using REDCap conditional syntax date_begin: Filter on records created after a date date_end: Filter on records created before a date decimal_character: Force all numbers into same decimal format export_blank_for_gray_form_status: Whether or not to export blank values for instrument complete status fields that have a gray status icon df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, `{'index_col': self.def_field}` Returns: Union[List[Dict[str, Any]], str, pd.DataFrame]: Exported data Examples: >>> proj.export_records() [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '1', 'upload_field': 'test_upload.txt', 'form_1_complete': '2'}, {'record_id': '2', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '0', 'checkbox_field___1': '0', 'checkbox_field___2': '0', 'upload_field': 'myupload.txt', 'form_1_complete': '0'}] >>> proj.export_records(filter_logic=\"[field_1] = 1\") [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '1', 'upload_field': 'test_upload.txt', 'form_1_complete': '2'}] >>> proj.export_records( ... format_type=\"csv\", ... fields=[\"field_1\", \"checkbox_field\"], ... raw_or_label=\"label\" ... ) 'record_id,redcap_event_name,redcap_repeat_instrument,redcap_repeat_instance,field_1,checkbox_field___1,checkbox_field___2\\n1,\"Event 1\",,1,Yes,Unchecked,Checked\\n2,\"Event 1\",,1,No,Unchecked,Unchecked\\n' >>> import pandas as pd >>> pd.set_option(\"display.max_columns\", 3) >>> proj.export_records(format_type=\"df\") redcap_repeat_instrument ... form_1_complete record_id redcap_event_name ... 1 event_1_arm_1 NaN ... 2 2 event_1_arm_1 NaN ... 0 ... \"\"\" # pylint: enable=line-too-long payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"record\" , format_type = format_type , record_type = record_type ) if isinstance ( fields , str ): fields = [ fields ] if isinstance ( forms , str ): forms = [ forms ] fields = self . _backfill_fields ( fields , forms ) keys_to_add = ( records , fields , forms , events , raw_or_label , raw_or_label_headers , event_name , export_survey_fields , export_data_access_groups , export_checkbox_labels , filter_logic , decimal_character , export_blank_for_gray_form_status , ) str_keys = ( \"records\" , \"fields\" , \"forms\" , \"events\" , \"rawOrLabel\" , \"rawOrLabelHeaders\" , \"eventName\" , \"exportSurveyFields\" , \"exportDataAccessGroups\" , \"exportCheckboxLabel\" , \"filterLogic\" , \"decimalCharacter\" , \"exportBlankForGrayFormStatus\" , ) for key , data in zip ( str_keys , keys_to_add ): if data : if key in ( \"fields\" , \"records\" , \"forms\" , \"events\" ): data = cast ( List [ str ], data ) for i , value in enumerate ( data ): payload [ f \" { key } [ { i } ]\" ] = value else : payload [ key ] = data if date_begin : payload [ \"dateRangeBegin\" ] = date_begin . strftime ( \"%Y-%m- %d %H:%M:%S\" ) if date_end : payload [ \"dateRangeEnd\" ] = date_end . strftime ( \"%Y-%m- %d %H:%M:%S\" ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"record\" , format_type = format_type , df_kwargs = df_kwargs , record_type = record_type , ) export_repeating_instruments_events ( self , format_type = 'json' , df_kwargs = None ) inherited Export the project's repeating instruments and events settings Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the repeating instruments and events in native objects, csv or xml, 'df'' will return a pandas.DataFrame 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame None Returns: Type Description Union[str, List[Dict[str, Any]], pd.DataFrame] Repeating instruments and events for the project Examples: >>> proj . export_repeating_instruments_events () [{ 'event_name' : 'event_1_arm_1' , 'form_name' : '' , 'custom_form_label' : '' }] Source code in redcap/project.py def export_repeating_instruments_events ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's repeating instruments and events settings Args: format_type: Return the repeating instruments and events in native objects, csv or xml, `'df''` will return a `pandas.DataFrame` df_kwargs: Passed to pandas.read_csv to control construction of returned DataFrame Returns: Union[str, List[Dict[str, Any]], pd.DataFrame]: Repeating instruments and events for the project Examples: >>> proj.export_repeating_instruments_events() [{'event_name': 'event_1_arm_1', 'form_name': '', 'custom_form_label': ''}] \"\"\" payload = self . _initialize_payload ( content = \"repeatingFormsEvents\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"repeatingFormsEvents\" , format_type = format_type , df_kwargs = df_kwargs , ) export_report ( self , report_id , format_type = 'json' , raw_or_label = 'raw' , raw_or_label_headers = 'raw' , export_checkbox_labels = False , csv_delimiter = ',' , df_kwargs = None ) inherited Export a report of the Project Parameters: Name Type Description Default report_id str The report ID number provided next to the report name on the report list page required format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data. 'json' returns json-decoded objects while 'csv' and 'xml' return strings. 'df' will attempt to return a pandas.DataFrame . 'json' raw_or_label Literal['raw', 'label'] Export the raw coded values or labels for the options of multiple choice fields 'raw' raw_or_label_headers Literal['raw', 'label'] For the CSV headers, export the variable/field names (raw) or the field labels (label) 'raw' export_checkbox_labels bool Specifies the format of checkbox field values specifically when exporting the data as labels (i.e. when rawOrLabel=label ). When exporting labels, by default (without providing the exportCheckboxLabel flag or if exportCheckboxLabel=false), all checkboxes will either have a value 'Checked' if they are checked or 'Unchecked' if not checked. But if exportCheckboxLabel is set to true, it will instead export the checkbox value as the checkbox option's label (e.g., 'Choice 1') if checked or it will be blank/empty (no value) if not checked False csv_delimiter Literal[',', 'tab', ';', '|', '^'] For the csv format, choose how the csv delimiter. ',' Exceptions: Type Description ValueError Unsupported format specified Returns: Type Description Union[List[Dict[str, Any]], str, pd.DataFrame] Data from the report ordered by the record (primary key of project) and then by event id Examples: >>> proj . export_report ( report_id = \"4292\" ) [{ 'record_id' : '1' , 'redcap_event_name' : 'event_1_arm_1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '1' }] Source code in redcap/project.py def export_report ( self , report_id : str , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , raw_or_label : Literal [ \"raw\" , \"label\" ] = \"raw\" , raw_or_label_headers : Literal [ \"raw\" , \"label\" ] = \"raw\" , export_checkbox_labels : bool = False , csv_delimiter : Literal [ \",\" , \"tab\" , \";\" , \"|\" , \"^\" ] = \",\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export a report of the Project Args: report_id: The report ID number provided next to the report name on the report list page format_type: Format of returned data. `'json'` returns json-decoded objects while `'csv'` and `'xml'` return strings. `'df'` will attempt to return a `pandas.DataFrame`. raw_or_label: Export the raw coded values or labels for the options of multiple choice fields raw_or_label_headers: For the CSV headers, export the variable/field names (raw) or the field labels (label) export_checkbox_labels: Specifies the format of checkbox field values specifically when exporting the data as labels (i.e. when `rawOrLabel=label`). When exporting labels, by default (without providing the exportCheckboxLabel flag or if exportCheckboxLabel=false), all checkboxes will either have a value 'Checked' if they are checked or 'Unchecked' if not checked. But if exportCheckboxLabel is set to true, it will instead export the checkbox value as the checkbox option's label (e.g., 'Choice 1') if checked or it will be blank/empty (no value) if not checked csv_delimiter: For the csv format, choose how the csv delimiter. Raises: ValueError: Unsupported format specified Returns: Union[List[Dict[str, Any]], str, pd.DataFrame]: Data from the report ordered by the record (primary key of project) and then by event id Examples: >>> proj.export_report(report_id=\"4292\") # doctest: +SKIP [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'checkbox_field___1': '0', 'checkbox_field___2': '1'}] \"\"\" payload = self . _initialize_payload ( content = \"report\" , format_type = format_type ) keys_to_add = ( report_id , raw_or_label , raw_or_label_headers , export_checkbox_labels , csv_delimiter , ) str_keys = ( \"report_id\" , \"rawOrLabel\" , \"rawOrLabelHeaders\" , \"exportCheckboxLabel\" , \"csvDelimiter\" , ) for key , data in zip ( str_keys , keys_to_add ): data = cast ( str , data ) if data : payload [ key ] = data return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"report\" , format_type = format_type , df_kwargs = df_kwargs , ) export_survey_access_code ( self , record , instrument , event = None , repeat_instance = 1 ) inherited Export a Survey Access Code for a Participant !!! note The passed instrument must be set up as a survey instrument. Parameters: Name Type Description Default record str Name of the record required instrument str Name of instrument as seen in the Data Dictionary (metadata). required event Optional[str] Unique event name, only used in longitudinal projects None repeat_instance int only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. 1 Returns: Type Description str A survey access code for a specified record and data collection instrument Examples: >>> proj . export_survey_access_code ( record = \"1\" , instrument = \"form_1\" , event = \"event_1_arm_1\" ) '...' Source code in redcap/project.py def export_survey_access_code ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : # pylint: disable=line-too-long \"\"\" Export a Survey Access Code for a Participant Note: The passed instrument must be set up as a survey instrument. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: A survey access code for a specified record and data collection instrument Examples: >>> proj.export_survey_access_code(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") '...' \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"surveyAccessCode\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" )) export_survey_link ( self , record , instrument , event = None , repeat_instance = 1 ) inherited Export one survey link !!! note The passed instrument must be set up as a survey instrument. Parameters: Name Type Description Default record str Name of the record required instrument str Name of instrument as seen in the Data Dictionary (metadata). required event Optional[str] Unique event name, only used in longitudinal projects None repeat_instance int only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. 1 Returns: Type Description str URL of survey link requested Examples: >>> proj . export_survey_link ( record = \"1\" , instrument = \"form_1\" , event = \"event_1_arm_1\" ) 'https://redcapdemo.vumc.org/surveys/?s=...' Source code in redcap/project.py def export_survey_link ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : \"\"\" Export one survey link Note: The passed instrument must be set up as a survey instrument. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: URL of survey link requested Examples: >>> proj.export_survey_link(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") 'https://redcapdemo.vumc.org/surveys/?s=...' \"\"\" payload = self . _initialize_payload ( content = \"surveyLink\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" )) export_survey_participant_list ( self , instrument , format_type = 'json' , event = None , df_kwargs = None ) inherited Export the Survey Participant List !!! note The passed instrument must be set up as a survey instrument. Parameters: Name Type Description Default instrument str Name of instrument as seen in the Data Dictionary (metadata). required format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data 'json' event Optional[str] Unique event name, only used in longitudinal projects None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of survey participants, along with other useful metadata such as the record, response status, etc. Examples: >>> proj . export_survey_participant_list ( instrument = \"form_1\" , event = \"event_1_arm_1\" ) [{ 'email' : '' , ... 'survey_access_code' : ... }, { 'email' : '' , ... 'survey_access_code' : ... }] Source code in redcap/project.py def export_survey_participant_list ( self , instrument : str , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , event : Optional [ str ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the Survey Participant List Note: The passed instrument must be set up as a survey instrument. Args: instrument: Name of instrument as seen in the Data Dictionary (metadata). format_type: Format of returned data event: Unique event name, only used in longitudinal projects df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of survey participants, along with other useful metadata such as the record, response status, etc. Examples: >>> proj.export_survey_participant_list(instrument=\"form_1\", event=\"event_1_arm_1\") [{'email': '', ... 'survey_access_code': ...}, {'email': '', ... 'survey_access_code': ...}] \"\"\" payload = self . _initialize_payload ( content = \"participantList\" , format_type = format_type , ) payload [ \"instrument\" ] = instrument if event : payload [ \"event\" ] = event return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"participantList\" , format_type = format_type , df_kwargs = df_kwargs , ) export_survey_queue_link ( self , record ) inherited Export one survey queue link !!! note The passed instrument must be set up as a survey instrument. The survey queue must be enabled for the project. Parameters: Name Type Description Default record str Name of the record required Returns: Type Description str URL of survey queue link requested Examples: >>> proj . export_survey_queue_link ( record = \"1\" ) 'https://redcapdemo.vumc.org/surveys/?sq=...' Source code in redcap/project.py def export_survey_queue_link ( self , record : str , ) -> str : \"\"\" Export one survey queue link Note: The passed instrument must be set up as a survey instrument. The survey queue must be enabled for the project. Args: record: Name of the record Returns: URL of survey queue link requested Examples: >>> proj.export_survey_queue_link(record=\"1\") 'https://redcapdemo.vumc.org/surveys/?sq=...' \"\"\" payload = self . _initialize_payload ( content = \"surveyQueueLink\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record return cast ( str , self . _call_api ( payload , return_type = \"str\" )) export_survey_return_code ( self , record , instrument , event = None , repeat_instance = 1 ) inherited Export a Survey Return Code for a Participant !!! note The passed instrument must be set up as a survey instrument, which has return codes enabled. Parameters: Name Type Description Default record str Name of the record required instrument str Name of instrument as seen in the Data Dictionary (metadata). required event Optional[str] Unique event name, only used in longitudinal projects None repeat_instance int only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. 1 Returns: Type Description str A survey return code for a specified record and data collection instrument Examples: >>> proj . export_survey_return_code ( record = \"1\" , instrument = \"form_1\" , event = \"event_1_arm_1\" ) '...' Source code in redcap/project.py def export_survey_return_code ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : # pylint: disable=line-too-long \"\"\" Export a Survey Return Code for a Participant Note: The passed instrument must be set up as a survey instrument, which has return codes enabled. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: A survey return code for a specified record and data collection instrument Examples: >>> proj.export_survey_return_code(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") '...' \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"surveyReturnCode\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" )) export_user_dag_assignment ( self , format_type = 'json' , df_kwargs = None ) inherited Export the User-DAG assignment of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of User-DAGs assignments Examples: >>> proj . export_user_dag_assignment () [{ 'username' : ... , 'redcap_data_access_group' : '' }] Source code in redcap/project.py def export_user_dag_assignment ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the User-DAG assignment of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of User-DAGs assignments Examples: >>> proj.export_user_dag_assignment() [{'username': ..., 'redcap_data_access_group': ''}] \"\"\" payload = self . _initialize_payload ( content = \"userDagMapping\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userDagMapping\" , format_type = format_type , df_kwargs = df_kwargs , ) export_user_role_assignment ( self , format_type = 'json' , df_kwargs = None ) inherited Export the User-Role assignments of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of user-role assignments Examples: >>> proj . export_user_role_assignment () [{ 'username' : ... , 'unique_role_name' : '' , 'data_access_group' : '' }] Source code in redcap/project.py def export_user_role_assignment ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the User-Role assignments of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of user-role assignments Examples: >>> proj.export_user_role_assignment() [{'username': ..., 'unique_role_name': '', 'data_access_group': ''}] \"\"\" payload = self . _initialize_payload ( content = \"userRoleMapping\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userRoleMapping\" , format_type = format_type , df_kwargs = df_kwargs , ) export_user_roles ( self , format_type = 'json' , df_kwargs = None ) inherited Export the user roles of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of user roles with assigned user rights Examples: >>> proj . export_user_roles () [{ 'unique_role_name' : ... , 'role_label' : 'Test role' , 'design' : '0' , 'alerts' : '0' , 'user_rights' : '0' , 'data_access_groups' : '0' , 'reports' : '0' , 'stats_and_charts' : '0' , 'manage_survey_participants' : '0' , 'calendar' : '0' , 'data_import_tool' : '0' , 'data_comparison_tool' : '0' , 'logging' : '0' , 'email_logging' : '0' , 'file_repository' : '0' , 'data_quality_create' : '0' , 'data_quality_execute' : '0' , 'api_export' : '0' , 'api_import' : '0' , 'api_modules' : '0' , 'mobile_app' : '0' , 'mobile_app_download_data' : '0' , 'record_create' : '0' , 'record_rename' : '0' , 'record_delete' : '0' , 'lock_records_customization' : '0' , 'lock_records' : '0' , ... , 'forms' : { 'form_1' : 2 }, 'forms_export' : { 'form_1' : 0 }}] Source code in redcap/project.py def export_user_roles ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the user roles of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of user roles with assigned user rights Examples: >>> proj.export_user_roles() [{'unique_role_name': ..., 'role_label': 'Test role', 'design': '0', 'alerts': '0', 'user_rights': '0', 'data_access_groups': '0', 'reports': '0', 'stats_and_charts': '0', 'manage_survey_participants': '0', 'calendar': '0', 'data_import_tool': '0', 'data_comparison_tool': '0', 'logging': '0', 'email_logging': '0', 'file_repository': '0', 'data_quality_create': '0', 'data_quality_execute': '0', 'api_export': '0', 'api_import': '0', 'api_modules': '0', 'mobile_app': '0', 'mobile_app_download_data': '0', 'record_create': '0', 'record_rename': '0', 'record_delete': '0', 'lock_records_customization': '0', 'lock_records': '0', ..., 'forms': {'form_1': 2}, 'forms_export': {'form_1': 0}}] \"\"\" payload = self . _initialize_payload ( content = \"userRole\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userRole\" , format_type = format_type , df_kwargs = df_kwargs , ) export_users ( self , format_type = 'json' , df_kwargs = None ) inherited Export the users of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of users with metadata Examples: >>> proj . export_users () [{ 'username' : ... , 'email' : ... , 'expiration' : '' , 'data_access_group' : '' , 'data_access_group_id' : '' , 'design' : 1 , 'alerts' : 1 , 'user_rights' : 1 , 'data_access_groups' : 1 , 'reports' : 1 , ... }] Source code in redcap/project.py def export_users ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the users of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of users with metadata Examples: >>> proj.export_users() [{'username': ..., 'email': ..., 'expiration': '', 'data_access_group': '', 'data_access_group_id': '', 'design': 1, 'alerts': 1, 'user_rights': 1, 'data_access_groups': 1, 'reports': 1, ...}] \"\"\" payload = self . _initialize_payload ( content = \"user\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"user\" , format_type = format_type , df_kwargs = df_kwargs , ) export_version ( self ) inherited Get the REDCap version Returns: Type Description Optional[semantic_version.base.Version] REDCap version running on the url provided Examples: >>> import semantic_version >>> redcap_version = proj . export_version () >>> assert redcap_version >= semantic_version . Version ( \"12.0.1\" ) Source code in redcap/project.py def export_version ( self ) -> Optional [ semantic_version . Version ]: \"\"\" Get the REDCap version Returns: REDCap version running on the url provided Examples: >>> import semantic_version >>> redcap_version = proj.export_version() >>> assert redcap_version >= semantic_version.Version(\"12.0.1\") \"\"\" payload = self . _initialize_payload ( \"version\" ) resp = None redcap_version = self . _call_api ( payload , return_type = \"str\" ) if semantic_version . validate ( redcap_version ): resp = semantic_version . Version ( redcap_version ) return resp generate_next_record_name ( self ) inherited Get the next record name Returns: Type Description str The next record name for a project with auto-numbering records enabled Examples: >>> proj . generate_next_record_name () '3' Source code in redcap/project.py def generate_next_record_name ( self ) -> str : \"\"\" Get the next record name Returns: The next record name for a project with auto-numbering records enabled Examples: >>> proj.generate_next_record_name() '3' \"\"\" # Force the csv format here since if the project uses data access groups # or just non-standard record names then the result will not be JSON-compliant payload = self . _initialize_payload ( content = \"generateNextRecordName\" , format_type = \"csv\" ) return cast ( str , self . _call_api ( payload , return_type = \"str\" )) import_arms ( self , to_import , return_format_type = 'json' , import_format = 'json' , override = 0 ) inherited Import Arms into the REDCap Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' override Optional[int] 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Arms in the project while importing new Arms. If override=0, then you can only add new Arms or rename existing ones. 0 Returns: Type Description Union[int, str] Number of Arms added or updated Examples: Create a new arm >>> new_arm = [{ \"arm_num\" : 2 , \"name\" : \"Arm 2\" }] >>> proj . import_arms ( new_arm ) 1 Source code in redcap/project.py def import_arms ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , override : Optional [ int ] = 0 , ): \"\"\" Import Arms into the REDCap Project Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded override: 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Arms in the project while importing new Arms. If override=0, then you can only add new Arms or rename existing ones. Returns: Union[int, str]: Number of Arms added or updated Examples: Create a new arm >>> new_arm = [{\"arm_num\": 2, \"name\": \"Arm 2\"}] >>> proj.import_arms(new_arm) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"arm\" , ) payload [ \"action\" ] = \"import\" payload [ \"override\" ] = override return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response import_dags ( self , to_import , return_format_type = 'json' , import_format = 'json' ) inherited Import DAGs into the REDCap Project !!! note DAGs can be renamed by simply changing the group name (data_access_group_name). DAGs can be created by providing group name value while unique group name should be set to blank. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of DAGs added or updated Examples: Create a new data access group >>> new_dag = [{ \"data_access_group_name\" : \"New DAG\" , \"unique_group_name\" : \"\" }] >>> proj . import_dags ( new_dag ) 1 Source code in redcap/project.py def import_dags ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import DAGs into the REDCap Project Note: DAGs can be renamed by simply changing the group name (data_access_group_name). DAGs can be created by providing group name value while unique group name should be set to blank. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of DAGs added or updated Examples: Create a new data access group >>> new_dag = [{\"data_access_group_name\": \"New DAG\", \"unique_group_name\": \"\"}] >>> proj.import_dags(new_dag) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"dag\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response import_events ( self , to_import , return_format_type = 'json' , import_format = 'json' , override = 0 ) inherited Import Events into the REDCap Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' override Optional[int] 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Events in the project while importing new Events. If override=0, then you can only add new Events or rename existing ones. 0 Returns: Type Description Union[int, str] Number of Events added or updated Examples: Create a new event >>> new_event = [{ \"event_name\" : \"Event 2\" , \"arm_num\" : \"1\" }] >>> proj . import_events ( new_event ) 1 Source code in redcap/project.py def import_events ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , override : Optional [ int ] = 0 , ): \"\"\" Import Events into the REDCap Project Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded override: 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Events in the project while importing new Events. If override=0, then you can only add new Events or rename existing ones. Returns: Union[int, str]: Number of Events added or updated Examples: Create a new event >>> new_event = [{\"event_name\": \"Event 2\", \"arm_num\": \"1\"}] >>> proj.import_events(new_event) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"event\" , ) payload [ \"action\" ] = \"import\" payload [ \"override\" ] = override return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response import_file ( self , record , field , file_name , file_object , event = None , repeat_instance = None ) inherited Import the contents of a file represented by file_object to a particular records field Parameters: Name Type Description Default record str Record ID required field str Field name where the file will go required file_name str File name visible in REDCap UI required file_object IO File object as returned by open required event Optional[str] For longitudinal projects, the unique event name None repeat_instance Union[int, str] (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). None Returns: Type Description List[dict] Empty JSON object Exceptions: Type Description ValueError Incorrect file field RedcapError Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> import tempfile >>> tmp_file = tempfile . TemporaryFile () >>> proj . import_file ( ... record = \"2\" , ... field = \"upload_field\" , ... file_name = \"myupload.txt\" , ... file_object = tmp_file , ... event = \"event_1_arm_1\" , ... ) [{}] Source code in redcap/project.py def import_file ( self , record : str , field : str , file_name : str , file_object : IO , event : Optional [ str ] = None , repeat_instance : Optional [ Union [ int , str ]] = None , ) -> EmptyJson : \"\"\" Import the contents of a file represented by file_object to a particular records field Args: record: Record ID field: Field name where the file will go file_name: File name visible in REDCap UI file_object: File object as returned by `open` event: For longitudinal projects, the unique event name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Returns: Empty JSON object Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file( ... record=\"2\", ... field=\"upload_field\", ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... event=\"event_1_arm_1\", ... ) [{}] \"\"\" self . _check_file_field ( field ) # load up payload payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"file\" ) payload [ \"action\" ] = \"import\" payload [ \"field\" ] = field payload [ \"record\" ] = record if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = repeat_instance file_upload_dict : FileUpload = { \"file\" : ( file_name , file_object )} return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" , file = file_upload_dict ), ) import_file_into_repository ( self , file_name , file_object , folder_id = None ) inherited Import the contents of a file represented by file_object into the file repository Parameters: Name Type Description Default file_name str File name visible in REDCap UI required file_object IO File object as returned by open required folder_id Optional[int] The folder_id of a specific folder in the File Repository where you wish to store the file. If none is provided, the file will be stored in the top-level directory of the File Repository. None Returns: Type Description List[dict] Empty JSON object Examples: >>> import tempfile >>> tmp_file = tempfile . TemporaryFile () >>> proj . import_file_into_repository ( ... file_name = \"myupload.txt\" , ... file_object = tmp_file , ... ) [{}] Source code in redcap/project.py def import_file_into_repository ( self , file_name : str , file_object : IO , folder_id : Optional [ int ] = None , ) -> EmptyJson : \"\"\" Import the contents of a file represented by file_object into the file repository Args: file_name: File name visible in REDCap UI file_object: File object as returned by `open` folder_id: The folder_id of a specific folder in the File Repository where you wish to store the file. If none is provided, the file will be stored in the top-level directory of the File Repository. Returns: Empty JSON object Examples: >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file_into_repository( ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... ) [{}] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" ) payload [ \"action\" ] = \"import\" if folder_id : payload [ \"folder_id\" ] = folder_id file_upload_dict : FileUpload = { \"file\" : ( file_name , file_object )} return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" , file = file_upload_dict ), ) import_instrument_event_mappings ( self , to_import , return_format_type = 'json' , import_format = 'json' ) inherited Import the project's instrument to event mapping !!! note This only works for longitudinal projects. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, import_format will be json-encoded 'json' Returns: Type Description Union[int, str] Number of instrument-event mappings imported Examples: Import instrument-event mappings >>> instrument_event_mappings = [{ \"arm_num\" : \"1\" , \"unique_event_name\" : \"event_1_arm_1\" , \"form\" : \"form_1\" }] >>> proj . import_instrument_event_mappings ( instrument_event_mappings ) 1 Source code in redcap/project.py def import_instrument_event_mappings ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): # pylint: disable=line-too-long \"\"\" Import the project's instrument to event mapping Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, import_format will be json-encoded Returns: Union[int, str]: Number of instrument-event mappings imported Examples: Import instrument-event mappings >>> instrument_event_mappings = [{\"arm_num\": \"1\", \"unique_event_name\": \"event_1_arm_1\", \"form\": \"form_1\"}] >>> proj.import_instrument_event_mappings(instrument_event_mappings) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"formEventMapping\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response import_metadata ( self , to_import , return_format_type = 'json' , import_format = 'json' , date_format = 'YMD' ) inherited Import metadata (Data Dictionary) into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import_format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' date_format Literal['YMD', 'DMY', 'MDY'] Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. 'YMD' Returns: Type Description Union[int, str] The number of imported fields Examples: >>> metadata = proj . export_metadata ( format_type = \"csv\" ) >>> proj . import_metadata ( metadata , import_format = \"csv\" ) 4 Source code in redcap/project.py def import_metadata ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , date_format : Literal [ \"YMD\" , \"DMY\" , \"MDY\" ] = \"YMD\" , ): \"\"\" Import metadata (Data Dictionary) into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import_format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded date_format: Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. Returns: Union[int, str]: The number of imported fields Examples: >>> metadata = proj.export_metadata(format_type=\"csv\") >>> proj.import_metadata(metadata, import_format=\"csv\") 4 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"metadata\" , ) payload [ \"dateFormat\" ] = date_format return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response import_records ( self , to_import , return_format_type = 'json' , return_content = 'count' , overwrite = 'normal' , import_format = 'json' , date_format = 'YMD' , force_auto_number = False ) inherited Import data into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] Note: If you pass a df, csv, or xml string, you should use the import_format parameter appropriately. Note: Keys of the dictionaries should be subset of project's, fields, but this isn't a requirement. If you provide keys that aren't defined fields, the returned response will contain an 'error' key. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' return_content Literal['count', 'ids', 'auto_ids', 'nothing'] By default, the response contains a 'count' key with the number of records just imported. By specifying 'ids', a list of ids imported will be returned. 'nothing' will only return the HTTP status code and no message. 'count' overwrite Literal['normal', 'overwrite'] 'overwrite' will erase values previously stored in the database if not specified in the to_import dictionaries. 'normal' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' date_format Literal['YMD', 'DMY', 'MDY'] Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. 'YMD' force_auto_number bool Enables automatic assignment of record IDs of imported records by REDCap. If this is set to true, and auto-numbering for records is enabled for the project, auto-numbering of imported records will be enabled. False Exceptions: Type Description RedcapError Bad request made, double check field names and other inputs Returns: Type Description Union[Dict, str] response from REDCap API, json-decoded if return_format == 'json' Examples: >>> new_record = [{ \"record_id\" : 3 , \"redcap_repeat_instance\" : 1 , \"field_1\" : 1 }] >>> proj . import_records ( new_record ) { 'count' : 1 } Source code in redcap/project.py def import_records ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_content : Literal [ \"count\" , \"ids\" , \"auto_ids\" , \"nothing\" ] = \"count\" , overwrite : Literal [ \"normal\" , \"overwrite\" ] = \"normal\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , date_format : Literal [ \"YMD\" , \"DMY\" , \"MDY\" ] = \"YMD\" , force_auto_number : bool = False , ): \"\"\" Import data into the REDCap Project Args: to_import: Note: If you pass a df, csv, or xml string, you should use the `import_format` parameter appropriately. Note: Keys of the dictionaries should be subset of project's, fields, but this isn't a requirement. If you provide keys that aren't defined fields, the returned response will contain an `'error'` key. return_format_type: Response format. By default, response will be json-decoded. return_content: By default, the response contains a 'count' key with the number of records just imported. By specifying 'ids', a list of ids imported will be returned. 'nothing' will only return the HTTP status code and no message. overwrite: `'overwrite'` will erase values previously stored in the database if not specified in the to_import dictionaries. import_format: Format of incoming data. By default, to_import will be json-encoded date_format: Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. force_auto_number: Enables automatic assignment of record IDs of imported records by REDCap. If this is set to true, and auto-numbering for records is enabled for the project, auto-numbering of imported records will be enabled. Raises: RedcapError: Bad request made, double check field names and other inputs Returns: Union[Dict, str]: response from REDCap API, json-decoded if `return_format` == `'json'` Examples: >>> new_record = [{\"record_id\": 3, \"redcap_repeat_instance\": 1, \"field_1\": 1}] >>> proj.import_records(new_record) {'count': 1} \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"record\" , ) payload [ \"overwriteBehavior\" ] = overwrite payload [ \"returnContent\" ] = return_content payload [ \"dateFormat\" ] = date_format payload [ \"forceAutoNumber\" ] = force_auto_number return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" , import_records_format = return_content , ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response import_repeating_instruments_events ( self , to_import , return_format_type = 'json' , import_format = 'json' ) inherited Import repeating instrument and event settings into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] The number of repeated instruments activated Examples: >>> rep_instruments = proj . export_repeating_instruments_events ( format_type = \"csv\" ) >>> proj . import_repeating_instruments_events ( rep_instruments , import_format = \"csv\" ) 1 Source code in redcap/project.py def import_repeating_instruments_events ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import repeating instrument and event settings into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: The number of repeated instruments activated Examples: >>> rep_instruments = proj.export_repeating_instruments_events(format_type=\"csv\") >>> proj.import_repeating_instruments_events(rep_instruments, import_format=\"csv\") 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"repeatingFormsEvents\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response import_user_dag_assignment ( self , to_import , return_format_type = 'json' , import_format = 'json' ) inherited Import User-DAG assignments into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of User-DAGs assignments added or updated Examples: Create a new user >>> new_user = \"pandeharris@gmail.com\" >>> proj . import_users ([{ \"username\" : new_user }]) 1 Add that user to a DAG >>> dag_mapping = [ ... { \"username\" : new_user , \"redcap_data_access_group\" : \"test_dag\" } ... ] >>> proj . import_user_dag_assignment ( dag_mapping ) 1 New user-DAG mapping >>> proj . export_user_dag_assignment () [{ 'username' : 'pandeharris@gmail.com' , 'redcap_data_access_group' : 'test_dag' }, { 'username' : ... , 'redcap_data_access_group' : '' }] Remove the user >>> proj . delete_users ([ new_user ]) 1 Source code in redcap/project.py def import_user_dag_assignment ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import User-DAG assignments into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of User-DAGs assignments added or updated Examples: Create a new user >>> new_user = \"pandeharris@gmail.com\" >>> proj.import_users([{\"username\": new_user}]) 1 Add that user to a DAG >>> dag_mapping = [ ... {\"username\": new_user, \"redcap_data_access_group\": \"test_dag\"} ... ] >>> proj.import_user_dag_assignment(dag_mapping) 1 New user-DAG mapping >>> proj.export_user_dag_assignment() [{'username': 'pandeharris@gmail.com', 'redcap_data_access_group': 'test_dag'}, {'username': ..., 'redcap_data_access_group': ''}] Remove the user >>> proj.delete_users([new_user]) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userDagMapping\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response import_user_role_assignment ( self , to_import , return_format_type = 'json' , import_format = 'json' ) inherited Import User-Role assignments into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of user-role assignments added or updated Examples: >>> user_role_assignments = proj . export_user_role_assignment () >>> proj . import_user_role_assignment ( user_role_assignments ) 1 Source code in redcap/project.py def import_user_role_assignment ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import User-Role assignments into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of user-role assignments added or updated Examples: >>> user_role_assignments = proj.export_user_role_assignment() >>> proj.import_user_role_assignment(user_role_assignments) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userRoleMapping\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response import_user_roles ( self , to_import , return_format_type = 'json' , import_format = 'json' ) inherited Import user roles into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of user roles added or updated Examples: >>> roles = proj . export_user_roles () >>> proj . import_user_roles ( roles ) 1 Source code in redcap/project.py def import_user_roles ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import user roles into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of user roles added or updated Examples: >>> roles = proj.export_user_roles() >>> proj.import_user_roles(roles) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userRole\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response import_users ( self , to_import , return_format_type = 'json' , import_format = 'json' ) inherited Import users/user rights into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of users added or updated Examples: Add test user. Only username is required >>> test_user = [{ \"username\" : \"pandeharris@gmail.com\" }] >>> proj . import_users ( test_user ) 1 All currently valid options for user rights >>> test_user = [ ... { \"username\" : \"pandeharris@gmail.com\" , \"email\" : \"pandeharris@gmail.com\" , ... \"firstname\" : \"REDCap Trial\" , \"lastname\" : \"User\" , \"expiration\" : \"\" , ... \"data_access_group\" : \"\" , \"data_access_group_id\" : \"\" , \"design\" : 0 , ... \"user_rights\" : 0 , \"data_export\" : 2 , \"reports\" : 1 , \"stats_and_charts\" : 1 , ... \"manage_survey_participants\" : 1 , \"calendar\" : 1 , \"data_access_groups\" : 0 , ... \"data_import_tool\" : 0 , \"data_comparison_tool\" : 0 , \"logging\" : 0 , ... \"file_repository\" : 1 , \"data_quality_create\" : 0 , \"data_quality_execute\" : 0 , ... \"api_export\" : 0 , \"api_import\" : 0 , \"mobile_app\" : 0 , ... \"mobile_app_download_data\" : 0 , \"record_create\" : 1 , \"record_rename\" : 0 , ... \"record_delete\" : 0 , \"lock_records_all_forms\" : 0 , \"lock_records\" : 0 , ... \"lock_records_customization\" : 0 , \"forms\" : { \"form_1\" : 3 }} ... ] >>> proj . import_users ( test_user ) 1 Source code in redcap/project.py def import_users ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import users/user rights into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of users added or updated Examples: Add test user. Only username is required >>> test_user = [{\"username\": \"pandeharris@gmail.com\"}] >>> proj.import_users(test_user) 1 All currently valid options for user rights >>> test_user = [ ... {\"username\": \"pandeharris@gmail.com\", \"email\": \"pandeharris@gmail.com\", ... \"firstname\": \"REDCap Trial\", \"lastname\": \"User\", \"expiration\": \"\", ... \"data_access_group\": \"\", \"data_access_group_id\": \"\", \"design\": 0, ... \"user_rights\": 0, \"data_export\": 2, \"reports\": 1, \"stats_and_charts\": 1, ... \"manage_survey_participants\": 1, \"calendar\": 1, \"data_access_groups\": 0, ... \"data_import_tool\": 0, \"data_comparison_tool\": 0, \"logging\": 0, ... \"file_repository\": 1, \"data_quality_create\": 0, \"data_quality_execute\": 0, ... \"api_export\": 0, \"api_import\": 0, \"mobile_app\": 0, ... \"mobile_app_download_data\": 0, \"record_create\": 1, \"record_rename\": 0, ... \"record_delete\": 0, \"lock_records_all_forms\": 0, \"lock_records\": 0, ... \"lock_records_customization\": 0, \"forms\": {\"form_1\": 3}} ... ] >>> proj.import_users(test_user) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"user\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response switch_dag ( self , dag ) inherited Allows the current API user to switch (assign/reassign/unassign) their current Data Access Group assignment. The current user must have been assigned to multiple DAGs via the DAG Switcher page in the project Parameters: Name Type Description Default dag str The unique group name of the Data Access Group to which you wish to switch required Returns: Type Description Literal['1'] \"1\" if the user successfully switched DAGs Examples: >>> proj . switch_dag ( \"test_dag\" ) '1' Source code in redcap/project.py def switch_dag ( self , dag : str , ) -> Literal [ \"1\" ]: \"\"\" Allows the current API user to switch (assign/reassign/unassign) their current Data Access Group assignment. The current user must have been assigned to multiple DAGs via the DAG Switcher page in the project Args: dag: The unique group name of the Data Access Group to which you wish to switch Returns: \"1\" if the user successfully switched DAGs Examples: >>> proj.switch_dag(\"test_dag\") # doctest: +SKIP '1' \"\"\" # API docs say that \"1\" is the only valid value payload = self . _initialize_payload ( content = \"dag\" , return_format_type = \"csv\" ) payload [ \"action\" ] = \"switch\" payload [ \"dag\" ] = dag response = cast ( Literal [ \"1\" ], self . _call_api ( payload , return_type = \"str\" )) return response","title":"Project"},{"location":"api_reference/project/#project","text":"User facing class for interacting with a REDCap Project","title":"Project"},{"location":"api_reference/project/#redcap.project.Project","text":"Main class for interacting with REDCap projects Attributes: Name Type Description verify_ssl Verify SSL, default True. Can pass path to CA_BUNDLE !!! note Your REDCap token should be kept secret ! Treat it like a password and NEVER save it directly in your script/application. Rather it should be obscured and retrieved 'behind the scenes'. For example, saving the token as an environment variable and retrieving it with os.getenv . The creation of the TOKEN string in the example is not shown, for the above reasons Examples: >>> from redcap import Project >>> URL = \"https://redcapdemo.vumc.org/api/\" >>> proj = Project ( URL , TOKEN ) >>> proj . field_names [ 'record_id' , 'field_1' , 'checkbox_field' , 'upload_field' ] >>> proj . is_longitudinal True >>> proj . def_field 'record_id' The url and token attributes are read-only, to prevent users from accidentally overwriting them >>> proj . url = \"whoops\" Traceback ( most recent call last ): ... AttributeError : ... Source code in redcap/project.py class Project ( methods . arms . Arms , methods . data_access_groups . DataAccessGroups , methods . events . Events , methods . field_names . FieldNames , methods . file_repository . FileRepository , methods . files . Files , methods . instruments . Instruments , methods . logging . Logging , methods . metadata . Metadata , methods . project_info . ProjectInfo , methods . records . Records , methods . repeating . Repeating , methods . reports . Reports , methods . surveys . Surveys , methods . users . Users , methods . user_roles . UserRoles , methods . version . Version , ): \"\"\"Main class for interacting with REDCap projects Attributes: verify_ssl: Verify SSL, default True. Can pass path to CA_BUNDLE Note: Your REDCap token should be kept **secret**! Treat it like a password and NEVER save it directly in your script/application. Rather it should be obscured and retrieved 'behind the scenes'. For example, saving the token as an environment variable and retrieving it with `os.getenv`. The creation of the `TOKEN` string in the example is not shown, for the above reasons Examples: >>> from redcap import Project >>> URL = \"https://redcapdemo.vumc.org/api/\" >>> proj = Project(URL, TOKEN) >>> proj.field_names ['record_id', 'field_1', 'checkbox_field', 'upload_field'] >>> proj.is_longitudinal True >>> proj.def_field 'record_id' The url and token attributes are read-only, to prevent users from accidentally overwriting them >>> proj.url = \"whoops\" Traceback (most recent call last): ... AttributeError: ... \"\"\" @property def redcap_version ( self ) -> Optional [ semantic_version . Version ]: \"\"\"REDCap version of the Project\"\"\" self . _redcap_version : Optional [ semantic_version . Version ] try : return self . _redcap_version except AttributeError : # weird pylint bug on windows where it can't find Version.export_version() # possible too many parents it's inheriting from? We also need to disable # useless-supression since this is a windows only issue # pylint: disable=no-member,useless-suppression self . _redcap_version = self . export_version () # pylint: enable=no-member,useless-suppression return self . _redcap_version","title":"Project"},{"location":"api_reference/project/#redcap.project.Project.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/project/#redcap.project.Project.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/project/#redcap.project.Project.forms","text":"Project form names","title":"forms"},{"location":"api_reference/project/#redcap.project.Project.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/project/#redcap.project.Project.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/project/#redcap.project.Project.redcap_version","text":"REDCap version of the Project","title":"redcap_version"},{"location":"api_reference/project/#redcap.project.Project.token","text":"API token to a project","title":"token"},{"location":"api_reference/project/#redcap.project.Project.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/project/#redcap.project.Project.create_folder_in_repository","text":"Create a New Folder in the File Repository Parameters: Name Type Description Default name str The desired name of the folder to be created (max length = 150 characters) required folder_id Optional[int] The folder_id of a specific folder in the File Repository for which you wish to create this sub-folder. If none is provided, the folder will be created in the top-level directory of the File Repository. None dag_id Optional[int] The dag_id of the DAG (Data Access Group) to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all DAGs and users in no DAGs. None role_id Optional[int] The role_id of the User Role to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all User Roles and users in no User Roles. None format_type Literal['json', 'csv', 'xml'] Return the metadata in native objects, csv or xml. 'json' return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[str, List[Dict[str, Any]]] List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj . create_folder_in_repository ( name = \"New Folder\" ) [{ 'folder_id' : ... }] Source code in redcap/project.py def create_folder_in_repository ( self , name : str , folder_id : Optional [ int ] = None , dag_id : Optional [ int ] = None , role_id : Optional [ int ] = None , format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Create a New Folder in the File Repository Args: name: The desired name of the folder to be created (max length = 150 characters) folder_id: The folder_id of a specific folder in the File Repository for which you wish to create this sub-folder. If none is provided, the folder will be created in the top-level directory of the File Repository. dag_id: The dag_id of the DAG (Data Access Group) to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all DAGs and users in no DAGs. role_id: The role_id of the User Role to which you wish to restrict access for this folder. If none is provided, the folder will accessible to users in all User Roles and users in no User Roles. format_type: Return the metadata in native objects, csv or xml. return_format_type: Response format. By default, response will be json-decoded. Returns: Union[str, List[Dict[str, Any]]]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.create_folder_in_repository(name=\"New Folder\") [{'folder_id': ...}] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" , format_type = format_type , return_format_type = return_format_type , ) payload [ \"action\" ] = \"createFolder\" payload [ \"name\" ] = name if folder_id : payload [ \"folder_id\" ] = folder_id if dag_id : payload [ \"dag_id\" ] = dag_id if role_id : payload [ \"role_id\" ] = role_id return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) return cast ( Union [ Json , str ], self . _call_api ( payload , return_type ))","title":"create_folder_in_repository()"},{"location":"api_reference/project/#redcap.project.Project.delete_arms","text":"Delete Arms from the Project !!! note Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an arm also automatically deletes all events that belong to that arm, and will also automatically delete any records/data that have been collected under that arm (this is non-reversible data loss). This only works for longitudinal projects. Parameters: Name Type Description Default arms List[str] List of arm numbers to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of arms deleted Examples: Create a new arm >>> new_arm = [{ \"arm_num\" : 2 , \"name\" : \"Arm 2\" }] >>> proj . import_arms ( new_arm ) 1 Delete the new arm >>> proj . delete_arms ([ 2 ]) 1 Source code in redcap/project.py def delete_arms ( self , arms : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete Arms from the Project Note: Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an arm also automatically deletes all events that belong to that arm, and will also automatically delete any records/data that have been collected under that arm (this is non-reversible data loss). This only works for longitudinal projects. Args: arms: List of arm numbers to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of arms deleted Examples: Create a new arm >>> new_arm = [{\"arm_num\": 2, \"name\": \"Arm 2\"}] >>> proj.import_arms(new_arm) 1 Delete the new arm >>> proj.delete_arms([2]) 1 \"\"\" payload = self . _initialize_payload ( content = \"arm\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"delete_arms()"},{"location":"api_reference/project/#redcap.project.Project.delete_dags","text":"Delete dags from the project. Parameters: Name Type Description Default dags List[str] List of dags to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of dags deleted Examples: Create a new data access group >>> new_dag = [{ \"data_access_group_name\" : \"New DAG\" , \"unique_group_name\" : \"\" }] >>> proj . import_dags ( new_dag ) 1 We know that 'New DAG' will automatically be assigned 'new_dag' as it's unique group name >>> proj . delete_dags ([ \"new_dag\" ]) 1 Source code in redcap/project.py def delete_dags ( self , dags : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete dags from the project. Args: dags: List of dags to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of dags deleted Examples: Create a new data access group >>> new_dag = [{\"data_access_group_name\": \"New DAG\", \"unique_group_name\": \"\"}] >>> proj.import_dags(new_dag) 1 We know that 'New DAG' will automatically be assigned 'new_dag' as it's unique group name >>> proj.delete_dags([\"new_dag\"]) 1 \"\"\" payload = self . _initialize_payload ( content = \"dag\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of dags into dict, and append to payload dags_dict = { f \"dags[ { idx } ]\" : dag for idx , dag in enumerate ( dags )} payload . update ( dags_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"delete_dags()"},{"location":"api_reference/project/#redcap.project.Project.delete_events","text":"Delete Events from the Project !!! note Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an event will automatically delete any records/data that have been collected under that event (this is non-reversible data loss). This only works for longitudinal projects. Parameters: Name Type Description Default events List[str] List of unique event names to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of events deleted Examples: Create a new event >>> new_event = [{ \"event_name\" : \"Event 2\" , \"arm_num\" : \"1\" }] >>> proj . import_events ( new_event ) 1 Delete the new event >>> proj . delete_events ([ \"event_2_arm_1\" ]) 1 Source code in redcap/project.py def delete_events ( self , events : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete Events from the Project Note: Because of this method's destructive nature, it is only available for use for projects in Development status. Additionally, please be aware that deleting an event will automatically delete any records/data that have been collected under that event (this is non-reversible data loss). This only works for longitudinal projects. Args: events: List of unique event names to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of events deleted Examples: Create a new event >>> new_event = [{\"event_name\": \"Event 2\", \"arm_num\": \"1\"}] >>> proj.import_events(new_event) 1 Delete the new event >>> proj.delete_events([\"event_2_arm_1\"]) 1 \"\"\" payload = self . _initialize_payload ( content = \"event\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of events into dict, and append to payload events_dict = { f \"events[ { idx } ]\" : event for idx , event in enumerate ( events )} payload . update ( events_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"delete_events()"},{"location":"api_reference/project/#redcap.project.Project.delete_file","text":"Delete a file from REDCap !!! note There is no undo button to this. Parameters: Name Type Description Default record str Record ID required field str Field name required event Optional[str] For longitudinal projects, the unique event name None Returns: Type Description List[dict] Empty JSON object Exceptions: Type Description ValueError Incorrect file field RedcapError Bad Request e.g. invalid record_id Examples: Import a tempfile and then delete it >>> import tempfile >>> tmp_file = tempfile . TemporaryFile () >>> proj . import_file ( ... record = \"2\" , ... field = \"upload_field\" , ... file_name = \"myupload.txt\" , ... file_object = tmp_file , ... event = \"event_1_arm_1\" , ... ) [{}] >>> proj . delete_file ( record = \"2\" , field = \"upload_field\" , event = \"event_1_arm_1\" ) [{}] Source code in redcap/project.py def delete_file ( self , record : str , field : str , event : Optional [ str ] = None , ) -> EmptyJson : \"\"\" Delete a file from REDCap Note: There is no undo button to this. Args: record: Record ID field: Field name event: For longitudinal projects, the unique event name Returns: Empty JSON object Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: Import a tempfile and then delete it >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file( ... record=\"2\", ... field=\"upload_field\", ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... event=\"event_1_arm_1\", ... ) [{}] >>> proj.delete_file(record=\"2\", field=\"upload_field\", event=\"event_1_arm_1\") [{}] \"\"\" self . _check_file_field ( field ) # Load up payload payload = self . _initialize_payload ( content = \"file\" ) payload [ \"action\" ] = \"delete\" payload [ \"record\" ] = record payload [ \"field\" ] = field if event : payload [ \"event\" ] = event return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" ) )","title":"delete_file()"},{"location":"api_reference/project/#redcap.project.Project.delete_file_from_repository","text":"Delete a File from the File Repository Once deleted, the file will remain in the Recycle Bin folder for up to 30 days. Parameters: Name Type Description Default doc_id int The doc_id of the file in the File Repository required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description List[dict] Empty JSON object Examples: >>> file_dir = proj . export_file_repository () >>> test_folder = [ folder for folder in file_dir if folder [ \"name\" ] == \"test\" ] . pop () >>> test_dir = proj . export_file_repository ( folder_id = test_folder [ \"folder_id\" ]) >>> test_file = [ file for file in test_dir if file [ \"name\" ] == \"test_in_folder.txt\" ] . pop () >>> proj . delete_file_from_repository ( doc_id = test_file [ \"doc_id\" ]) [{}] Source code in redcap/project.py def delete_file_from_repository ( self , doc_id : int , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ) -> EmptyJson : # pylint: disable=line-too-long \"\"\" Delete a File from the File Repository Once deleted, the file will remain in the Recycle Bin folder for up to 30 days. Args: doc_id: The doc_id of the file in the File Repository return_format_type: Response format. By default, response will be json-decoded. Returns: Empty JSON object Examples: >>> file_dir = proj.export_file_repository() >>> test_folder = [folder for folder in file_dir if folder[\"name\"] == \"test\"].pop() >>> test_dir = proj.export_file_repository(folder_id=test_folder[\"folder_id\"]) >>> test_file = [file for file in test_dir if file[\"name\"] == \"test_in_folder.txt\"].pop() >>> proj.delete_file_from_repository(doc_id=test_file[\"doc_id\"]) [{}] \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"fileRepository\" , return_format_type = return_format_type ) # there's no format field in this call payload [ \"action\" ] = \"delete\" payload [ \"doc_id\" ] = doc_id return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" ) )","title":"delete_file_from_repository()"},{"location":"api_reference/project/#redcap.project.Project.delete_records","text":"Delete records from the project. Parameters: Name Type Description Default records List[str] List of record IDs to delete from the project required arm Optional[str] the arm number of the arm in which the record(s) should be deleted. (This can only be used if the project is longitudinal with more than one arm.) NOTE: If the arm parameter is not provided, the specified records will be deleted from all arms in which they exist. Whereas, if arm is provided, they will only be deleted from the specified arm. None instrument Optional[str] the unique instrument name (column B in the Data Dictionary) of an instrument (as a string) if you wish to delete the data for all fields on the specified instrument for the records specified. None event Optional[str] the unique event name - only for longitudinal projects. NOTE: If instrument is provided for a longitudinal project, the event parameter is mandatory. None repeat_instance Optional[int] the repeating instance number for a repeating instrument or repeating event. NOTE: If project has repeating instruments/events, it will remove only the data for that repeating instance. None delete_logging bool provide a value of False (\"keep logging\") or True (\"delete logging\"). This activity when deleting the record?\" setting enabled by an administrator on the Edit Project Settings page. The default value for PyCap is False False return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of records deleted Examples: >>> new_records = [ ... { \"record_id\" : 3 , \"redcap_repeat_instance\" : 1 , \"field_1\" : 1 }, ... { \"record_id\" : 4 , \"redcap_repeat_instance\" : 1 } ... ] >>> proj . import_records ( new_records ) { 'count' : 2 } >>> proj . delete_records ([ \"3\" , \"4\" ]) 2 >>> new_record = [ ... { \"record_id\" : 3 , \"redcap_event_name\" : \"event_1_arm_1\" , \"redcap_repeat_instance\" : 1 , \"field_1\" : 1 ,}, ... { \"record_id\" : 3 , \"redcap_event_name\" : \"event_1_arm_1\" , \"redcap_repeat_instance\" : 2 , \"field_1\" : 0 ,}, ... ] >>> proj . import_records ( new_record ) { 'count' : 1 } >>> proj . delete_records ( records = [ \"3\" ], event = \"event_1_arm_1\" , repeat_instance = 2 ) 1 >>> proj . export_records ( records = [ \"3\" ]) [{ 'record_id' : '3' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '0' , 'upload_field' : '' , 'form_1_complete' : '0' }] >>> proj . delete_records ( records = [ \"3\" ]) 1 Source code in redcap/project.py def delete_records ( self , records : List [ str ], arm : Optional [ str ] = None , instrument : Optional [ str ] = None , event : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , delete_logging : bool = False , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): # pylint: disable=line-too-long \"\"\" Delete records from the project. Args: records: List of record IDs to delete from the project arm: the arm number of the arm in which the record(s) should be deleted. (This can only be used if the project is longitudinal with more than one arm.) NOTE: If the arm parameter is not provided, the specified records will be deleted from all arms in which they exist. Whereas, if arm is provided, they will only be deleted from the specified arm. instrument: the unique instrument name (column B in the Data Dictionary) of an instrument (as a string) if you wish to delete the data for all fields on the specified instrument for the records specified. event: the unique event name - only for longitudinal projects. NOTE: If instrument is provided for a longitudinal project, the event parameter is mandatory. repeat_instance: the repeating instance number for a repeating instrument or repeating event. NOTE: If project has repeating instruments/events, it will remove only the data for that repeating instance. delete_logging: provide a value of False (\"keep logging\") or True (\"delete logging\"). This activity when deleting the record?\" setting enabled by an administrator on the Edit Project Settings page. The default value for PyCap is False return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of records deleted Examples: >>> new_records = [ ... {\"record_id\": 3, \"redcap_repeat_instance\": 1, \"field_1\": 1}, ... {\"record_id\": 4, \"redcap_repeat_instance\": 1} ... ] >>> proj.import_records(new_records) {'count': 2} >>> proj.delete_records([\"3\", \"4\"]) 2 >>> new_record = [ ... {\"record_id\": 3, \"redcap_event_name\": \"event_1_arm_1\", \"redcap_repeat_instance\": 1, \"field_1\": 1,}, ... {\"record_id\": 3, \"redcap_event_name\": \"event_1_arm_1\", \"redcap_repeat_instance\": 2, \"field_1\": 0,}, ... ] >>> proj.import_records(new_record) {'count': 1} >>> proj.delete_records(records=[\"3\"], event=\"event_1_arm_1\", repeat_instance=2) 1 >>> proj.export_records(records=[\"3\"]) [{'record_id': '3', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '0', 'upload_field': '', 'form_1_complete': '0'}] >>> proj.delete_records(records=[\"3\"]) 1 \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"record\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" if delete_logging : payload [ \"delete_logging\" ] = \"1\" else : payload [ \"delete_logging\" ] = \"0\" if arm : payload [ \"arm\" ] = arm if instrument : payload [ \"instrument\" ] = instrument if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = repeat_instance # Turn list of records into dict, and append to payload records_dict = { f \"records[ { idx } ]\" : record for idx , record in enumerate ( records ) } payload . update ( records_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"delete_records()"},{"location":"api_reference/project/#redcap.project.Project.delete_user_roles","text":"Delete user roles from the project. Parameters: Name Type Description Default roles List[str] List of user roles to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of user roles deleted Examples: Create a new user role >>> new_role = [{ \"role_label\" : \"New Role\" }] >>> proj . import_user_roles ( new_role ) 1 We don't know what the 'unique_role_name' is for the newly created role, so we have to look it up by 'role_label' >>> roles = proj . export_user_roles () >>> new_role_id = [ ... role for role in roles ... if role [ \"role_label\" ] == \"New Role\" ... ][ 0 ][ \"unique_role_name\" ] Delete the role >>> proj . delete_user_roles ([ new_role_id ]) 1 Source code in redcap/project.py def delete_user_roles ( self , roles : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete user roles from the project. Args: roles: List of user roles to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of user roles deleted Examples: Create a new user role >>> new_role = [{\"role_label\": \"New Role\"}] >>> proj.import_user_roles(new_role) 1 We don't know what the 'unique_role_name' is for the newly created role, so we have to look it up by 'role_label' >>> roles = proj.export_user_roles() >>> new_role_id = [ ... role for role in roles ... if role[\"role_label\"] == \"New Role\" ... ][0][\"unique_role_name\"] Delete the role >>> proj.delete_user_roles([new_role_id]) 1 \"\"\" payload = self . _initialize_payload ( content = \"userRole\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of user roles into dict, and append to payload roles_dict = { f \"roles[ { idx } ]\" : role for idx , role in enumerate ( roles )} payload . update ( roles_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"delete_user_roles()"},{"location":"api_reference/project/#redcap.project.Project.delete_users","text":"Delete users from the project. Parameters: Name Type Description Default users List[str] List of usernames to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of users deleted Examples: >>> new_user = [{ \"username\" : \"pandeharris@gmail.com\" }] >>> proj . import_users ( new_user ) 1 >>> proj . delete_users ([ \"pandeharris@gmail.com\" ], return_format_type = \"xml\" ) '1' Source code in redcap/project.py def delete_users ( self , users : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete users from the project. Args: users: List of usernames to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of users deleted Examples: >>> new_user = [{\"username\": \"pandeharris@gmail.com\"}] >>> proj.import_users(new_user) 1 >>> proj.delete_users([\"pandeharris@gmail.com\"], return_format_type=\"xml\") '1' \"\"\" payload = self . _initialize_payload ( content = \"user\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of users into dict, and append to payload users_dict = { f \"users[ { idx } ]\" : user for idx , user in enumerate ( users )} payload . update ( users_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"delete_users()"},{"location":"api_reference/project/#redcap.project.Project.export_arms","text":"Export the Arms of the Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' arms Optional[List[str]] An array of arm numbers that you wish to pull arms for (by default, all arms are pulled) None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of Arms Examples: >>> proj . export_arms () [{ 'arm_num' : 1 , 'name' : 'Arm 1' }] Source code in redcap/project.py def export_arms ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , ): \"\"\" Export the Arms of the Project Note: This only works for longitudinal projects. Args: format_type: Response return format arms: An array of arm numbers that you wish to pull arms for (by default, all arms are pulled) Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Arms Examples: >>> proj.export_arms() [{'arm_num': 1, 'name': 'Arm 1'}] \"\"\" payload = self . _initialize_payload ( content = \"arm\" , format_type = format_type ) if arms : # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"arm\" , format_type = format_type , )","title":"export_arms()"},{"location":"api_reference/project/#redcap.project.Project.export_dags","text":"Export the DAGs of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of DAGs Examples: >>> proj . export_dags () [{ 'data_access_group_name' : 'Test DAG' , 'unique_group_name' : 'test_dag' , 'data_access_group_id' : ... }] Source code in redcap/project.py def export_dags ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long \"\"\" Export the DAGs of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of DAGs Examples: >>> proj.export_dags() [{'data_access_group_name': 'Test DAG', 'unique_group_name': 'test_dag', 'data_access_group_id': ...}] \"\"\" # pylint:enable=line-too-long payload = self . _initialize_payload ( content = \"dag\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"dag\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_dags()"},{"location":"api_reference/project/#redcap.project.Project.export_events","text":"Export the Events of the Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' arms Optional[List[str]] An array of arm numbers that you wish to pull events for (by default, all events are pulled) None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of Events Examples: >>> proj . export_events () [{ 'event_name' : 'Event 1' , 'arm_num' : 1 , 'unique_event_name' : 'event_1_arm_1' , 'custom_event_label' : '' , 'event_id' : ... }, { 'event_name' : 'Event 2' , ... }] Source code in redcap/project.py def export_events ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , ): \"\"\" Export the Events of the Project Note: This only works for longitudinal projects. Args: format_type: Response return format arms: An array of arm numbers that you wish to pull events for (by default, all events are pulled) Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Events Examples: >>> proj.export_events() [{'event_name': 'Event 1', 'arm_num': 1, 'unique_event_name': 'event_1_arm_1', 'custom_event_label': '', 'event_id': ...}, {'event_name': 'Event 2', ...}] \"\"\" payload = self . _initialize_payload ( content = \"event\" , format_type = format_type ) if arms : # Turn list of arms into dict, and append to payload arms_dict = { f \"arms[ { idx } ]\" : arm for idx , arm in enumerate ( arms )} payload . update ( arms_dict ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"event\" , format_type = format_type , )","title":"export_events()"},{"location":"api_reference/project/#redcap.project.Project.export_field_names","text":"Export the project's export field names Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the metadata in native objects, csv or xml. 'df' will return a pandas.DataFrame 'json' field Optional[str] Limit exported field name to this field (only single field supported). When not provided, all fields returned None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. by default {'index_col': 'original_field_name'} None Returns: Type Description Union[str, List[Dict[str, Any]], \"pd.DataFrame\"] Metadata structure for the project. Examples: >>> proj . export_field_names () [{ 'original_field_name' : 'record_id' , 'choice_value' : '' , 'export_field_name' : 'record_id' }, { 'original_field_name' : 'field_1' , 'choice_value' : '' , 'export_field_name' : 'field_1' }, { 'original_field_name' : 'checkbox_field' , 'choice_value' : '1' , 'export_field_name' : 'checkbox_field___1' }, { 'original_field_name' : 'checkbox_field' , 'choice_value' : '2' , 'export_field_name' : 'checkbox_field___2' }, { 'original_field_name' : 'form_1_complete' , 'choice_value' : '' , 'export_field_name' : 'form_1_complete' }] Source code in redcap/project.py def export_field_names ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , field : Optional [ str ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long \"\"\" Export the project's export field names Args: format_type: Return the metadata in native objects, csv or xml. `'df'` will return a `pandas.DataFrame` field: Limit exported field name to this field (only single field supported). When not provided, all fields returned df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. by default `{'index_col': 'original_field_name'}` Returns: Union[str, List[Dict[str, Any]], \"pd.DataFrame\"]: Metadata structure for the project. Examples: >>> proj.export_field_names() [{'original_field_name': 'record_id', 'choice_value': '', 'export_field_name': 'record_id'}, {'original_field_name': 'field_1', 'choice_value': '', 'export_field_name': 'field_1'}, {'original_field_name': 'checkbox_field', 'choice_value': '1', 'export_field_name': 'checkbox_field___1'}, {'original_field_name': 'checkbox_field', 'choice_value': '2', 'export_field_name': 'checkbox_field___2'}, {'original_field_name': 'form_1_complete', 'choice_value': '', 'export_field_name': 'form_1_complete'}] \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"exportFieldNames\" , format_type = format_type ) if field : payload [ \"field\" ] = field return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"exportFieldNames\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_field_names()"},{"location":"api_reference/project/#redcap.project.Project.export_file","text":"Export the contents of a file stored for a particular record !!! note Unlike other export methods, this only works on a single record. Parameters: Name Type Description Default record str Record ID required field str Field name containing the file to be exported. required event Optional[str] For longitudinal projects, the unique event name None repeat_instance Optional[int] (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). None Returns: Type Description Tuple[bytes, dict] Content of the file and content-type dictionary Exceptions: Type Description ValueError Incorrect file field RedcapError Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> proj . export_file ( record = \"1\" , field = \"upload_field\" , event = \"event_1_arm_1\" ) ( b 'test upload \\n ' , { 'name' : 'test_upload.txt' , 'charset' : 'UTF-8' }) Source code in redcap/project.py def export_file ( self , record : str , field : str , event : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , ) -> FileMap : \"\"\" Export the contents of a file stored for a particular record Note: Unlike other export methods, this only works on a single record. Args: record: Record ID field: Field name containing the file to be exported. event: For longitudinal projects, the unique event name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Returns: Content of the file and content-type dictionary Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> proj.export_file(record=\"1\", field=\"upload_field\", event=\"event_1_arm_1\") (b'test upload\\\\n', {'name': 'test_upload.txt', 'charset': 'UTF-8'}) \"\"\" self . _check_file_field ( field ) # load up payload payload = self . _initialize_payload ( content = \"file\" ) # there's no format field in this call payload [ \"action\" ] = \"export\" payload [ \"field\" ] = field payload [ \"record\" ] = record if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = str ( repeat_instance ) content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map","title":"export_file()"},{"location":"api_reference/project/#redcap.project.Project.export_file_from_repository","text":"Export the contents of a file stored in the File Repository Parameters: Name Type Description Default doc_id int The doc_id of the file in the File Repository required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Tuple[bytes, dict] Content of the file and content-type dictionary Examples: >>> file_dir = proj . export_file_repository () >>> text_file = [ file for file in file_dir if file [ \"name\" ] == \"test.txt\" ] . pop () >>> proj . export_file_from_repository ( doc_id = text_file [ \"doc_id\" ]) ( b 'hello' , { 'name' : 'test.txt' , 'charset' : 'UTF-8' }) Source code in redcap/project.py def export_file_from_repository ( self , doc_id : int , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ) -> FileMap : \"\"\" Export the contents of a file stored in the File Repository Args: doc_id: The doc_id of the file in the File Repository return_format_type: Response format. By default, response will be json-decoded. Returns: Content of the file and content-type dictionary Examples: >>> file_dir = proj.export_file_repository() >>> text_file = [file for file in file_dir if file[\"name\"] == \"test.txt\"].pop() >>> proj.export_file_from_repository(doc_id=text_file[\"doc_id\"]) (b'hello', {'name': 'test.txt', 'charset': 'UTF-8'}) \"\"\" payload = self . _initialize_payload ( content = \"fileRepository\" , return_format_type = return_format_type ) # there's no format field in this call payload [ \"action\" ] = \"export\" payload [ \"doc_id\" ] = doc_id content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map","title":"export_file_from_repository()"},{"location":"api_reference/project/#redcap.project.Project.export_file_repository","text":"Export of list of files/folders in the File Repository Only exports the top-level of files/folders. To see which files are contained within a folder, use the folder_id parameter Parameters: Name Type Description Default folder_id Optional[int] The folder_id of a specific folder in the File Repository for which you wish to search for files/folders. If none is provided, the search will be conducted in the top-level directory of the File Repository. None format_type Literal['json', 'csv', 'xml'] Return the metadata in native objects, csv or xml. 'json' return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[str, List[Dict[str, Any]]] List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj . export_file_repository () [{ 'folder_id' : ... , 'name' : 'New Folder' }, ... ] Source code in redcap/project.py def export_file_repository ( self , folder_id : Optional [ int ] = None , format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Export of list of files/folders in the File Repository Only exports the top-level of files/folders. To see which files are contained within a folder, use the `folder_id` parameter Args: folder_id: The folder_id of a specific folder in the File Repository for which you wish to search for files/folders. If none is provided, the search will be conducted in the top-level directory of the File Repository. format_type: Return the metadata in native objects, csv or xml. return_format_type: Response format. By default, response will be json-decoded. Returns: Union[str, List[Dict[str, Any]]]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.export_file_repository() [{'folder_id': ..., 'name': 'New Folder'}, ...] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" , format_type = format_type , return_format_type = return_format_type , ) payload [ \"action\" ] = \"list\" if folder_id : payload [ \"folder_id\" ] = folder_id return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) return cast ( Union [ Json , str ], self . _call_api ( payload , return_type ))","title":"export_file_repository()"},{"location":"api_reference/project/#redcap.project.Project.export_instrument_event_mappings","text":"Export the project's instrument to event mapping Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the form event mappings in native objects, csv or xml, 'df'' will return a pandas.DataFrame 'json' arms Optional[List[str]] Limit exported form event mappings to these arms None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame None Returns: Type Description Union[str, List[Dict[str, Any]], pd.DataFrame] Instrument-event mapping for the project Examples: >>> proj . export_instrument_event_mappings () [{ 'arm_num' : 1 , 'unique_event_name' : 'event_1_arm_1' , 'form' : 'form_1' }] Source code in redcap/project.py def export_instrument_event_mappings ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , arms : Optional [ List [ str ]] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's instrument to event mapping Args: format_type: Return the form event mappings in native objects, csv or xml, `'df''` will return a `pandas.DataFrame` arms: Limit exported form event mappings to these arms df_kwargs: Passed to pandas.read_csv to control construction of returned DataFrame Returns: Union[str, List[Dict[str, Any]], pd.DataFrame]: Instrument-event mapping for the project Examples: >>> proj.export_instrument_event_mappings() [{'arm_num': 1, 'unique_event_name': 'event_1_arm_1', 'form': 'form_1'}] \"\"\" payload = self . _initialize_payload ( content = \"formEventMapping\" , format_type = format_type ) if arms : for i , value in enumerate ( arms ): payload [ f \"arms[ { i } ]\" ] = value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"formEventMapping\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_instrument_event_mappings()"},{"location":"api_reference/project/#redcap.project.Project.export_instruments","text":"Export the Instruments of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of Instruments Examples: >>> proj . export_instruments () [{ 'instrument_name' : 'form_1' , 'instrument_label' : 'Form 1' }] Source code in redcap/project.py def export_instruments ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Export the Instruments of the Project Args: format_type: Response return format Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of Instruments Examples: >>> proj.export_instruments() [{'instrument_name': 'form_1', 'instrument_label': 'Form 1'}] \"\"\" payload = self . _initialize_payload ( content = \"instrument\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"instrument\" , format_type = format_type , )","title":"export_instruments()"},{"location":"api_reference/project/#redcap.project.Project.export_logging","text":"Export the project's logs Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the metadata in native objects, csv or xml. 'df' will return a pandas.DataFrame 'json' return_format_type Optional[Literal['json', 'csv', 'xml']] Response format. By default, response will be json-decoded. None log_type Optional[Literal['export', 'manage', 'user', 'record', 'record_add', 'record_edit', 'record_delete', 'lock_record', 'page_view']] Filter by specific event types None user Optional[str] Filter by events created by a certain user None record Optional[str] Filter by events created for a certain record None dag Optional[str] Filter by events created by a certain data access group (group ID) None begin_time Optional[datetime.datetime] Filter by events created after a given timestamp None end_time Optional[datetime.datetime] Filter by events created before a given timestamp None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. None Returns: Type Description Union[str, List[Dict[str, Any]], \"pd.DataFrame\"] List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj . export_logging () [{ 'timestamp' : ... , 'username' : ... , 'action' : 'Manage/Design ' , 'details' : 'Create project ...' }, ... ] Source code in redcap/project.py def export_logging ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , return_format_type : Optional [ Literal [ \"json\" , \"csv\" , \"xml\" ]] = None , log_type : Optional [ Literal [ \"export\" , \"manage\" , \"user\" , \"record\" , \"record_add\" , \"record_edit\" , \"record_delete\" , \"lock_record\" , \"page_view\" , ] ] = None , user : Optional [ str ] = None , record : Optional [ str ] = None , dag : Optional [ str ] = None , begin_time : Optional [ datetime ] = None , end_time : Optional [ datetime ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's logs Args: format_type: Return the metadata in native objects, csv or xml. `'df'` will return a `pandas.DataFrame` return_format_type: Response format. By default, response will be json-decoded. log_type: Filter by specific event types user: Filter by events created by a certain user record: Filter by events created for a certain record dag: Filter by events created by a certain data access group (group ID) begin_time: Filter by events created after a given timestamp end_time: Filter by events created before a given timestamp df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. Returns: Union[str, List[Dict[str, Any]], \"pd.DataFrame\"]: List of all changes made to this project, including data exports, data changes, and the creation or deletion of users Examples: >>> proj.export_logging() [{'timestamp': ..., 'username': ..., 'action': 'Manage/Design ', 'details': 'Create project ...'}, ...] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"log\" , format_type = format_type ) optional_args = [ ( \"returnFormat\" , return_format_type ), ( \"logtype\" , log_type ), ( \"user\" , user ), ( \"record\" , record ), ( \"dag\" , dag ), ( \"beginTime\" , begin_time ), ( \"endTime\" , end_time ), ] for arg in optional_args : arg_name , arg_value = arg if arg_value : if arg_name in [ \"beginTime\" , \"endTime\" ]: arg_value = cast ( datetime , arg_value ) arg_value = arg_value . strftime ( \"%Y-%m- %d %H:%M:%S\" ) payload [ arg_name ] = arg_value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"log\" , format_type = format_type , df_kwargs = df_kwargs , ) # pylint: enable=too-many-locals","title":"export_logging()"},{"location":"api_reference/project/#redcap.project.Project.export_metadata","text":"Export the project's metadata Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the metadata in native objects, csv, or xml. 'df' will return a pandas.DataFrame 'json' fields Optional[List[str]] Limit exported metadata to these fields None forms Optional[List[str]] Limit exported metadata to these forms None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default {'index_col': 'field_name'} None Returns: Type Description Union[str, List[Dict], pd.DataFrame] Metadata structure for the project. Examples: >>> proj . export_metadata ( format_type = \"df\" ) form_name section_header ... matrix_ranking field_annotation field_name ... record_id form_1 NaN ... NaN NaN field_1 form_1 NaN ... NaN NaN checkbox_field form_1 NaN ... NaN NaN upload_field form_1 NaN ... NaN NaN ... Source code in redcap/project.py def export_metadata ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , fields : Optional [ List [ str ]] = None , forms : Optional [ List [ str ]] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's metadata Args: format_type: Return the metadata in native objects, csv, or xml. `'df'` will return a `pandas.DataFrame` fields: Limit exported metadata to these fields forms: Limit exported metadata to these forms df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default `{'index_col': 'field_name'}` Returns: Union[str, List[Dict], pd.DataFrame]: Metadata structure for the project. Examples: >>> proj.export_metadata(format_type=\"df\") form_name section_header ... matrix_ranking field_annotation field_name ... record_id form_1 NaN ... NaN NaN field_1 form_1 NaN ... NaN NaN checkbox_field form_1 NaN ... NaN NaN upload_field form_1 NaN ... NaN NaN ... \"\"\" payload = self . _initialize_payload ( content = \"metadata\" , format_type = format_type ) to_add = [ fields , forms ] str_add = [ \"fields\" , \"forms\" ] for key , data in zip ( str_add , to_add ): if data : for i , value in enumerate ( data ): payload [ f \" { key } [ { i } ]\" ] = value return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"metadata\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_metadata()"},{"location":"api_reference/project/#redcap.project.Project.export_pdf","text":"Export PDF file of instruments, either as blank or with data Parameters: Name Type Description Default record Optional[str] Record ID None event Optional[str] For longitudinal projects, the unique event name None instrument Optional[str] Unique instrument name None repeat_instance Optional[int] (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). None all_records Optional[bool] If True, then all records will be exported as a single PDF file. Note: If this is True, then record, event, and instrument parameters are all ignored. None compact_display Optional[bool] If True, then the PDF will be exported in compact display mode. None Returns: Type Description Tuple[bytes, dict] Content of the file and dictionary of useful metadata Examples: >>> proj . export_pdf () ( b '%PDF-1.3 \\n 3 0 obj \\n ..., {...}) Source code in redcap/project.py def export_pdf ( self , record : Optional [ str ] = None , event : Optional [ str ] = None , instrument : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , all_records : Optional [ bool ] = None , compact_display : Optional [ bool ] = None , ) -> FileMap : \"\"\" Export PDF file of instruments, either as blank or with data Args: record: Record ID event: For longitudinal projects, the unique event name instrument: Unique instrument name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). all_records: If True, then all records will be exported as a single PDF file. Note: If this is True, then record, event, and instrument parameters are all ignored. compact_display: If True, then the PDF will be exported in compact display mode. Returns: Content of the file and dictionary of useful metadata Examples: >>> proj.export_pdf() (b'%PDF-1.3\\\\n3 0 obj\\\\n..., {...}) \"\"\" # load up payload payload = self . _initialize_payload ( content = \"pdf\" , return_format_type = \"json\" ) keys_to_add = ( record , event , instrument , repeat_instance , all_records , compact_display , ) str_keys = ( \"record\" , \"event\" , \"instrument\" , \"repeat_instance\" , \"allRecords\" , \"compactDisplay\" , ) for key , data in zip ( str_keys , keys_to_add ): data = cast ( str , data ) if data : payload [ key ] = data payload [ \"action\" ] = \"export\" content , headers = cast ( FileMap , self . _call_api ( payload = payload , return_type = \"file_map\" ) ) # REDCap adds some useful things in content-type content_map = {} if \"content-type\" in headers : splat = [ key_values . strip () for key_values in headers [ \"content-type\" ] . split ( \";\" ) ] key_values = [ ( key_values . split ( \"=\" )[ 0 ], key_values . split ( \"=\" )[ 1 ] . replace ( '\"' , \"\" )) for key_values in splat if \"=\" in key_values ] content_map = dict ( key_values ) return content , content_map","title":"export_pdf()"},{"location":"api_reference/project/#redcap.project.Project.export_project_info","text":"Export Project Information Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[str, List[Dict[str, Any]], pandas.DataFrame] Project information Examples: >>> proj . export_project_info () { 'project_id' : ... ... 'in_production' : 0 , 'project_language' : 'English' , 'purpose' : 0 , 'purpose_other' : '' , ... 'project_grant_number' : '' , 'project_pi_firstname' : '' , 'project_pi_lastname' : '' , ... 'bypass_branching_erase_field_prompt' : 0 } Source code in redcap/project.py def export_project_info ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export Project Information Args: format_type: Format of returned data df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[str, List[Dict[str, Any]], pandas.DataFrame]: Project information Examples: >>> proj.export_project_info() {'project_id': ... ... 'in_production': 0, 'project_language': 'English', 'purpose': 0, 'purpose_other': '', ... 'project_grant_number': '', 'project_pi_firstname': '', 'project_pi_lastname': '', ... 'bypass_branching_erase_field_prompt': 0} \"\"\" payload = self . _initialize_payload ( content = \"project\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"project\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_project_info()"},{"location":"api_reference/project/#redcap.project.Project.export_records","text":"Export data from the REDCap project. Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data. 'json' returns json-decoded objects while 'csv' and 'xml' return other formats. 'df' will attempt to return a pandas.DataFrame 'json' records Optional[List[str]] Array of record names specifying specific records to export. By default, all records are exported None fields Union[List[str], str] Single field name or array of field names specifying specific fields to pull. By default, all fields are exported None forms Union[List[str], str] Single form name or array of form names to export. If in the web UI, the form name has a space in it, replace the space with an underscore. By default, all forms are exported None events Optional[List[str]] An array of unique event names from which to export records Note: This only applies to longitudinal projects None raw_or_label Literal['raw', 'label', 'both'] Export the raw coded values or labels for the options of multiple choice fields, or both 'raw' raw_or_label_headers Literal['raw', 'label'] Export the column names of the instrument as their raw value or their labeled value 'raw' event_name Literal['label', 'unique'] Export the unique event name or the event label 'label' record_type Literal['flat', 'eav'] Database output structure type 'flat' export_survey_fields bool Specifies whether or not to export the survey identifier field (e.g., \"redcap_survey_identifier\") or survey timestamp fields (e.g., form_name+\"_timestamp\") when surveys are utilized in the project False export_data_access_groups bool Specifies whether or not to export the \"redcap_data_access_group\" field when data access groups are utilized in the project Note: This flag is only viable if the user whose token is being used to make the API request is not in a data access group. If the user is in a group, then this flag will revert to its default value. False export_checkbox_labels bool Specify whether to export checkbox values as their label on export. False filter_logic Optional[str] Filter which records are returned using REDCap conditional syntax None date_begin Optional[datetime.datetime] Filter on records created after a date None date_end Optional[datetime.datetime] Filter on records created before a date None decimal_character Optional[Literal[',', '.']] Force all numbers into same decimal format None export_blank_for_gray_form_status Optional[bool] Whether or not to export blank values for instrument complete status fields that have a gray status icon None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, {'index_col': self.def_field} None Returns: Type Description Union[List[Dict[str, Any]], str, pd.DataFrame] Exported data Examples: >>> proj . export_records () [{ 'record_id' : '1' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '1' , 'upload_field' : 'test_upload.txt' , 'form_1_complete' : '2' }, { 'record_id' : '2' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '0' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '0' , 'upload_field' : 'myupload.txt' , 'form_1_complete' : '0' }] >>> proj . export_records ( filter_logic = \"[field_1] = 1\" ) [{ 'record_id' : '1' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '1' , 'upload_field' : 'test_upload.txt' , 'form_1_complete' : '2' }] >>> proj . export_records ( ... format_type = \"csv\" , ... fields = [ \"field_1\" , \"checkbox_field\" ], ... raw_or_label = \"label\" ... ) 'record_id,redcap_event_name,redcap_repeat_instrument,redcap_repeat_instance,field_1,checkbox_field___1,checkbox_field___2 \\n 1,\"Event 1\",,1,Yes,Unchecked,Checked \\n 2,\"Event 1\",,1,No,Unchecked,Unchecked \\n ' >>> import pandas as pd >>> pd . set_option ( \"display.max_columns\" , 3 ) >>> proj . export_records ( format_type = \"df\" ) redcap_repeat_instrument ... form_1_complete record_id redcap_event_name ... 1 event_1_arm_1 NaN ... 2 2 event_1_arm_1 NaN ... 0 ... Source code in redcap/project.py def export_records ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , records : Optional [ List [ str ]] = None , fields : Optional [ Union [ List [ str ], str ]] = None , forms : Optional [ Union [ List [ str ], str ]] = None , events : Optional [ List [ str ]] = None , raw_or_label : Literal [ \"raw\" , \"label\" , \"both\" ] = \"raw\" , raw_or_label_headers : Literal [ \"raw\" , \"label\" ] = \"raw\" , event_name : Literal [ \"label\" , \"unique\" ] = \"label\" , record_type : Literal [ \"flat\" , \"eav\" ] = \"flat\" , export_survey_fields : bool = False , export_data_access_groups : bool = False , export_checkbox_labels : bool = False , filter_logic : Optional [ str ] = None , date_begin : Optional [ datetime ] = None , date_end : Optional [ datetime ] = None , decimal_character : Optional [ Literal [ \",\" , \".\" ]] = None , export_blank_for_gray_form_status : Optional [ bool ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long r \"\"\" Export data from the REDCap project. Args: format_type: Format of returned data. `'json'` returns json-decoded objects while `'csv'` and `'xml'` return other formats. `'df'` will attempt to return a `pandas.DataFrame` records: Array of record names specifying specific records to export. By default, all records are exported fields: Single field name or array of field names specifying specific fields to pull. By default, all fields are exported forms: Single form name or array of form names to export. If in the web UI, the form name has a space in it, replace the space with an underscore. By default, all forms are exported events: An array of unique event names from which to export records Note: This only applies to longitudinal projects raw_or_label: Export the raw coded values or labels for the options of multiple choice fields, or both raw_or_label_headers: Export the column names of the instrument as their raw value or their labeled value event_name: Export the unique event name or the event label record_type: Database output structure type export_survey_fields: Specifies whether or not to export the survey identifier field (e.g., \"redcap_survey_identifier\") or survey timestamp fields (e.g., form_name+\"_timestamp\") when surveys are utilized in the project export_data_access_groups: Specifies whether or not to export the `\"redcap_data_access_group\"` field when data access groups are utilized in the project Note: This flag is only viable if the user whose token is being used to make the API request is *not* in a data access group. If the user is in a group, then this flag will revert to its default value. export_checkbox_labels: Specify whether to export checkbox values as their label on export. filter_logic: Filter which records are returned using REDCap conditional syntax date_begin: Filter on records created after a date date_end: Filter on records created before a date decimal_character: Force all numbers into same decimal format export_blank_for_gray_form_status: Whether or not to export blank values for instrument complete status fields that have a gray status icon df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, `{'index_col': self.def_field}` Returns: Union[List[Dict[str, Any]], str, pd.DataFrame]: Exported data Examples: >>> proj.export_records() [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '1', 'upload_field': 'test_upload.txt', 'form_1_complete': '2'}, {'record_id': '2', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '0', 'checkbox_field___1': '0', 'checkbox_field___2': '0', 'upload_field': 'myupload.txt', 'form_1_complete': '0'}] >>> proj.export_records(filter_logic=\"[field_1] = 1\") [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '1', 'upload_field': 'test_upload.txt', 'form_1_complete': '2'}] >>> proj.export_records( ... format_type=\"csv\", ... fields=[\"field_1\", \"checkbox_field\"], ... raw_or_label=\"label\" ... ) 'record_id,redcap_event_name,redcap_repeat_instrument,redcap_repeat_instance,field_1,checkbox_field___1,checkbox_field___2\\n1,\"Event 1\",,1,Yes,Unchecked,Checked\\n2,\"Event 1\",,1,No,Unchecked,Unchecked\\n' >>> import pandas as pd >>> pd.set_option(\"display.max_columns\", 3) >>> proj.export_records(format_type=\"df\") redcap_repeat_instrument ... form_1_complete record_id redcap_event_name ... 1 event_1_arm_1 NaN ... 2 2 event_1_arm_1 NaN ... 0 ... \"\"\" # pylint: enable=line-too-long payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"record\" , format_type = format_type , record_type = record_type ) if isinstance ( fields , str ): fields = [ fields ] if isinstance ( forms , str ): forms = [ forms ] fields = self . _backfill_fields ( fields , forms ) keys_to_add = ( records , fields , forms , events , raw_or_label , raw_or_label_headers , event_name , export_survey_fields , export_data_access_groups , export_checkbox_labels , filter_logic , decimal_character , export_blank_for_gray_form_status , ) str_keys = ( \"records\" , \"fields\" , \"forms\" , \"events\" , \"rawOrLabel\" , \"rawOrLabelHeaders\" , \"eventName\" , \"exportSurveyFields\" , \"exportDataAccessGroups\" , \"exportCheckboxLabel\" , \"filterLogic\" , \"decimalCharacter\" , \"exportBlankForGrayFormStatus\" , ) for key , data in zip ( str_keys , keys_to_add ): if data : if key in ( \"fields\" , \"records\" , \"forms\" , \"events\" ): data = cast ( List [ str ], data ) for i , value in enumerate ( data ): payload [ f \" { key } [ { i } ]\" ] = value else : payload [ key ] = data if date_begin : payload [ \"dateRangeBegin\" ] = date_begin . strftime ( \"%Y-%m- %d %H:%M:%S\" ) if date_end : payload [ \"dateRangeEnd\" ] = date_end . strftime ( \"%Y-%m- %d %H:%M:%S\" ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"record\" , format_type = format_type , df_kwargs = df_kwargs , record_type = record_type , )","title":"export_records()"},{"location":"api_reference/project/#redcap.project.Project.export_repeating_instruments_events","text":"Export the project's repeating instruments and events settings Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the repeating instruments and events in native objects, csv or xml, 'df'' will return a pandas.DataFrame 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame None Returns: Type Description Union[str, List[Dict[str, Any]], pd.DataFrame] Repeating instruments and events for the project Examples: >>> proj . export_repeating_instruments_events () [{ 'event_name' : 'event_1_arm_1' , 'form_name' : '' , 'custom_form_label' : '' }] Source code in redcap/project.py def export_repeating_instruments_events ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's repeating instruments and events settings Args: format_type: Return the repeating instruments and events in native objects, csv or xml, `'df''` will return a `pandas.DataFrame` df_kwargs: Passed to pandas.read_csv to control construction of returned DataFrame Returns: Union[str, List[Dict[str, Any]], pd.DataFrame]: Repeating instruments and events for the project Examples: >>> proj.export_repeating_instruments_events() [{'event_name': 'event_1_arm_1', 'form_name': '', 'custom_form_label': ''}] \"\"\" payload = self . _initialize_payload ( content = \"repeatingFormsEvents\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"repeatingFormsEvents\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_repeating_instruments_events()"},{"location":"api_reference/project/#redcap.project.Project.export_report","text":"Export a report of the Project Parameters: Name Type Description Default report_id str The report ID number provided next to the report name on the report list page required format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data. 'json' returns json-decoded objects while 'csv' and 'xml' return strings. 'df' will attempt to return a pandas.DataFrame . 'json' raw_or_label Literal['raw', 'label'] Export the raw coded values or labels for the options of multiple choice fields 'raw' raw_or_label_headers Literal['raw', 'label'] For the CSV headers, export the variable/field names (raw) or the field labels (label) 'raw' export_checkbox_labels bool Specifies the format of checkbox field values specifically when exporting the data as labels (i.e. when rawOrLabel=label ). When exporting labels, by default (without providing the exportCheckboxLabel flag or if exportCheckboxLabel=false), all checkboxes will either have a value 'Checked' if they are checked or 'Unchecked' if not checked. But if exportCheckboxLabel is set to true, it will instead export the checkbox value as the checkbox option's label (e.g., 'Choice 1') if checked or it will be blank/empty (no value) if not checked False csv_delimiter Literal[',', 'tab', ';', '|', '^'] For the csv format, choose how the csv delimiter. ',' Exceptions: Type Description ValueError Unsupported format specified Returns: Type Description Union[List[Dict[str, Any]], str, pd.DataFrame] Data from the report ordered by the record (primary key of project) and then by event id Examples: >>> proj . export_report ( report_id = \"4292\" ) [{ 'record_id' : '1' , 'redcap_event_name' : 'event_1_arm_1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '1' }] Source code in redcap/project.py def export_report ( self , report_id : str , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , raw_or_label : Literal [ \"raw\" , \"label\" ] = \"raw\" , raw_or_label_headers : Literal [ \"raw\" , \"label\" ] = \"raw\" , export_checkbox_labels : bool = False , csv_delimiter : Literal [ \",\" , \"tab\" , \";\" , \"|\" , \"^\" ] = \",\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export a report of the Project Args: report_id: The report ID number provided next to the report name on the report list page format_type: Format of returned data. `'json'` returns json-decoded objects while `'csv'` and `'xml'` return strings. `'df'` will attempt to return a `pandas.DataFrame`. raw_or_label: Export the raw coded values or labels for the options of multiple choice fields raw_or_label_headers: For the CSV headers, export the variable/field names (raw) or the field labels (label) export_checkbox_labels: Specifies the format of checkbox field values specifically when exporting the data as labels (i.e. when `rawOrLabel=label`). When exporting labels, by default (without providing the exportCheckboxLabel flag or if exportCheckboxLabel=false), all checkboxes will either have a value 'Checked' if they are checked or 'Unchecked' if not checked. But if exportCheckboxLabel is set to true, it will instead export the checkbox value as the checkbox option's label (e.g., 'Choice 1') if checked or it will be blank/empty (no value) if not checked csv_delimiter: For the csv format, choose how the csv delimiter. Raises: ValueError: Unsupported format specified Returns: Union[List[Dict[str, Any]], str, pd.DataFrame]: Data from the report ordered by the record (primary key of project) and then by event id Examples: >>> proj.export_report(report_id=\"4292\") # doctest: +SKIP [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'checkbox_field___1': '0', 'checkbox_field___2': '1'}] \"\"\" payload = self . _initialize_payload ( content = \"report\" , format_type = format_type ) keys_to_add = ( report_id , raw_or_label , raw_or_label_headers , export_checkbox_labels , csv_delimiter , ) str_keys = ( \"report_id\" , \"rawOrLabel\" , \"rawOrLabelHeaders\" , \"exportCheckboxLabel\" , \"csvDelimiter\" , ) for key , data in zip ( str_keys , keys_to_add ): data = cast ( str , data ) if data : payload [ key ] = data return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"report\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_report()"},{"location":"api_reference/project/#redcap.project.Project.export_survey_access_code","text":"Export a Survey Access Code for a Participant !!! note The passed instrument must be set up as a survey instrument. Parameters: Name Type Description Default record str Name of the record required instrument str Name of instrument as seen in the Data Dictionary (metadata). required event Optional[str] Unique event name, only used in longitudinal projects None repeat_instance int only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. 1 Returns: Type Description str A survey access code for a specified record and data collection instrument Examples: >>> proj . export_survey_access_code ( record = \"1\" , instrument = \"form_1\" , event = \"event_1_arm_1\" ) '...' Source code in redcap/project.py def export_survey_access_code ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : # pylint: disable=line-too-long \"\"\" Export a Survey Access Code for a Participant Note: The passed instrument must be set up as a survey instrument. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: A survey access code for a specified record and data collection instrument Examples: >>> proj.export_survey_access_code(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") '...' \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"surveyAccessCode\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" ))","title":"export_survey_access_code()"},{"location":"api_reference/project/#redcap.project.Project.export_survey_link","text":"Export one survey link !!! note The passed instrument must be set up as a survey instrument. Parameters: Name Type Description Default record str Name of the record required instrument str Name of instrument as seen in the Data Dictionary (metadata). required event Optional[str] Unique event name, only used in longitudinal projects None repeat_instance int only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. 1 Returns: Type Description str URL of survey link requested Examples: >>> proj . export_survey_link ( record = \"1\" , instrument = \"form_1\" , event = \"event_1_arm_1\" ) 'https://redcapdemo.vumc.org/surveys/?s=...' Source code in redcap/project.py def export_survey_link ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : \"\"\" Export one survey link Note: The passed instrument must be set up as a survey instrument. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: URL of survey link requested Examples: >>> proj.export_survey_link(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") 'https://redcapdemo.vumc.org/surveys/?s=...' \"\"\" payload = self . _initialize_payload ( content = \"surveyLink\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" ))","title":"export_survey_link()"},{"location":"api_reference/project/#redcap.project.Project.export_survey_participant_list","text":"Export the Survey Participant List !!! note The passed instrument must be set up as a survey instrument. Parameters: Name Type Description Default instrument str Name of instrument as seen in the Data Dictionary (metadata). required format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data 'json' event Optional[str] Unique event name, only used in longitudinal projects None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of survey participants, along with other useful metadata such as the record, response status, etc. Examples: >>> proj . export_survey_participant_list ( instrument = \"form_1\" , event = \"event_1_arm_1\" ) [{ 'email' : '' , ... 'survey_access_code' : ... }, { 'email' : '' , ... 'survey_access_code' : ... }] Source code in redcap/project.py def export_survey_participant_list ( self , instrument : str , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , event : Optional [ str ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the Survey Participant List Note: The passed instrument must be set up as a survey instrument. Args: instrument: Name of instrument as seen in the Data Dictionary (metadata). format_type: Format of returned data event: Unique event name, only used in longitudinal projects df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of survey participants, along with other useful metadata such as the record, response status, etc. Examples: >>> proj.export_survey_participant_list(instrument=\"form_1\", event=\"event_1_arm_1\") [{'email': '', ... 'survey_access_code': ...}, {'email': '', ... 'survey_access_code': ...}] \"\"\" payload = self . _initialize_payload ( content = \"participantList\" , format_type = format_type , ) payload [ \"instrument\" ] = instrument if event : payload [ \"event\" ] = event return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"participantList\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_survey_participant_list()"},{"location":"api_reference/project/#redcap.project.Project.export_survey_queue_link","text":"Export one survey queue link !!! note The passed instrument must be set up as a survey instrument. The survey queue must be enabled for the project. Parameters: Name Type Description Default record str Name of the record required Returns: Type Description str URL of survey queue link requested Examples: >>> proj . export_survey_queue_link ( record = \"1\" ) 'https://redcapdemo.vumc.org/surveys/?sq=...' Source code in redcap/project.py def export_survey_queue_link ( self , record : str , ) -> str : \"\"\" Export one survey queue link Note: The passed instrument must be set up as a survey instrument. The survey queue must be enabled for the project. Args: record: Name of the record Returns: URL of survey queue link requested Examples: >>> proj.export_survey_queue_link(record=\"1\") 'https://redcapdemo.vumc.org/surveys/?sq=...' \"\"\" payload = self . _initialize_payload ( content = \"surveyQueueLink\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record return cast ( str , self . _call_api ( payload , return_type = \"str\" ))","title":"export_survey_queue_link()"},{"location":"api_reference/project/#redcap.project.Project.export_survey_return_code","text":"Export a Survey Return Code for a Participant !!! note The passed instrument must be set up as a survey instrument, which has return codes enabled. Parameters: Name Type Description Default record str Name of the record required instrument str Name of instrument as seen in the Data Dictionary (metadata). required event Optional[str] Unique event name, only used in longitudinal projects None repeat_instance int only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. 1 Returns: Type Description str A survey return code for a specified record and data collection instrument Examples: >>> proj . export_survey_return_code ( record = \"1\" , instrument = \"form_1\" , event = \"event_1_arm_1\" ) '...' Source code in redcap/project.py def export_survey_return_code ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : # pylint: disable=line-too-long \"\"\" Export a Survey Return Code for a Participant Note: The passed instrument must be set up as a survey instrument, which has return codes enabled. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: A survey return code for a specified record and data collection instrument Examples: >>> proj.export_survey_return_code(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") '...' \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"surveyReturnCode\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" ))","title":"export_survey_return_code()"},{"location":"api_reference/project/#redcap.project.Project.export_user_dag_assignment","text":"Export the User-DAG assignment of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of User-DAGs assignments Examples: >>> proj . export_user_dag_assignment () [{ 'username' : ... , 'redcap_data_access_group' : '' }] Source code in redcap/project.py def export_user_dag_assignment ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the User-DAG assignment of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of User-DAGs assignments Examples: >>> proj.export_user_dag_assignment() [{'username': ..., 'redcap_data_access_group': ''}] \"\"\" payload = self . _initialize_payload ( content = \"userDagMapping\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userDagMapping\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_user_dag_assignment()"},{"location":"api_reference/project/#redcap.project.Project.export_user_role_assignment","text":"Export the User-Role assignments of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of user-role assignments Examples: >>> proj . export_user_role_assignment () [{ 'username' : ... , 'unique_role_name' : '' , 'data_access_group' : '' }] Source code in redcap/project.py def export_user_role_assignment ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the User-Role assignments of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of user-role assignments Examples: >>> proj.export_user_role_assignment() [{'username': ..., 'unique_role_name': '', 'data_access_group': ''}] \"\"\" payload = self . _initialize_payload ( content = \"userRoleMapping\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userRoleMapping\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_user_role_assignment()"},{"location":"api_reference/project/#redcap.project.Project.export_user_roles","text":"Export the user roles of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of user roles with assigned user rights Examples: >>> proj . export_user_roles () [{ 'unique_role_name' : ... , 'role_label' : 'Test role' , 'design' : '0' , 'alerts' : '0' , 'user_rights' : '0' , 'data_access_groups' : '0' , 'reports' : '0' , 'stats_and_charts' : '0' , 'manage_survey_participants' : '0' , 'calendar' : '0' , 'data_import_tool' : '0' , 'data_comparison_tool' : '0' , 'logging' : '0' , 'email_logging' : '0' , 'file_repository' : '0' , 'data_quality_create' : '0' , 'data_quality_execute' : '0' , 'api_export' : '0' , 'api_import' : '0' , 'api_modules' : '0' , 'mobile_app' : '0' , 'mobile_app_download_data' : '0' , 'record_create' : '0' , 'record_rename' : '0' , 'record_delete' : '0' , 'lock_records_customization' : '0' , 'lock_records' : '0' , ... , 'forms' : { 'form_1' : 2 }, 'forms_export' : { 'form_1' : 0 }}] Source code in redcap/project.py def export_user_roles ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the user roles of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of user roles with assigned user rights Examples: >>> proj.export_user_roles() [{'unique_role_name': ..., 'role_label': 'Test role', 'design': '0', 'alerts': '0', 'user_rights': '0', 'data_access_groups': '0', 'reports': '0', 'stats_and_charts': '0', 'manage_survey_participants': '0', 'calendar': '0', 'data_import_tool': '0', 'data_comparison_tool': '0', 'logging': '0', 'email_logging': '0', 'file_repository': '0', 'data_quality_create': '0', 'data_quality_execute': '0', 'api_export': '0', 'api_import': '0', 'api_modules': '0', 'mobile_app': '0', 'mobile_app_download_data': '0', 'record_create': '0', 'record_rename': '0', 'record_delete': '0', 'lock_records_customization': '0', 'lock_records': '0', ..., 'forms': {'form_1': 2}, 'forms_export': {'form_1': 0}}] \"\"\" payload = self . _initialize_payload ( content = \"userRole\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userRole\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_user_roles()"},{"location":"api_reference/project/#redcap.project.Project.export_users","text":"Export the users of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of users with metadata Examples: >>> proj . export_users () [{ 'username' : ... , 'email' : ... , 'expiration' : '' , 'data_access_group' : '' , 'data_access_group_id' : '' , 'design' : 1 , 'alerts' : 1 , 'user_rights' : 1 , 'data_access_groups' : 1 , 'reports' : 1 , ... }] Source code in redcap/project.py def export_users ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the users of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of users with metadata Examples: >>> proj.export_users() [{'username': ..., 'email': ..., 'expiration': '', 'data_access_group': '', 'data_access_group_id': '', 'design': 1, 'alerts': 1, 'user_rights': 1, 'data_access_groups': 1, 'reports': 1, ...}] \"\"\" payload = self . _initialize_payload ( content = \"user\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"user\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_users()"},{"location":"api_reference/project/#redcap.project.Project.export_version","text":"Get the REDCap version Returns: Type Description Optional[semantic_version.base.Version] REDCap version running on the url provided Examples: >>> import semantic_version >>> redcap_version = proj . export_version () >>> assert redcap_version >= semantic_version . Version ( \"12.0.1\" ) Source code in redcap/project.py def export_version ( self ) -> Optional [ semantic_version . Version ]: \"\"\" Get the REDCap version Returns: REDCap version running on the url provided Examples: >>> import semantic_version >>> redcap_version = proj.export_version() >>> assert redcap_version >= semantic_version.Version(\"12.0.1\") \"\"\" payload = self . _initialize_payload ( \"version\" ) resp = None redcap_version = self . _call_api ( payload , return_type = \"str\" ) if semantic_version . validate ( redcap_version ): resp = semantic_version . Version ( redcap_version ) return resp","title":"export_version()"},{"location":"api_reference/project/#redcap.project.Project.generate_next_record_name","text":"Get the next record name Returns: Type Description str The next record name for a project with auto-numbering records enabled Examples: >>> proj . generate_next_record_name () '3' Source code in redcap/project.py def generate_next_record_name ( self ) -> str : \"\"\" Get the next record name Returns: The next record name for a project with auto-numbering records enabled Examples: >>> proj.generate_next_record_name() '3' \"\"\" # Force the csv format here since if the project uses data access groups # or just non-standard record names then the result will not be JSON-compliant payload = self . _initialize_payload ( content = \"generateNextRecordName\" , format_type = \"csv\" ) return cast ( str , self . _call_api ( payload , return_type = \"str\" ))","title":"generate_next_record_name()"},{"location":"api_reference/project/#redcap.project.Project.import_arms","text":"Import Arms into the REDCap Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' override Optional[int] 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Arms in the project while importing new Arms. If override=0, then you can only add new Arms or rename existing ones. 0 Returns: Type Description Union[int, str] Number of Arms added or updated Examples: Create a new arm >>> new_arm = [{ \"arm_num\" : 2 , \"name\" : \"Arm 2\" }] >>> proj . import_arms ( new_arm ) 1 Source code in redcap/project.py def import_arms ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , override : Optional [ int ] = 0 , ): \"\"\" Import Arms into the REDCap Project Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded override: 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Arms in the project while importing new Arms. If override=0, then you can only add new Arms or rename existing ones. Returns: Union[int, str]: Number of Arms added or updated Examples: Create a new arm >>> new_arm = [{\"arm_num\": 2, \"name\": \"Arm 2\"}] >>> proj.import_arms(new_arm) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"arm\" , ) payload [ \"action\" ] = \"import\" payload [ \"override\" ] = override return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_arms()"},{"location":"api_reference/project/#redcap.project.Project.import_dags","text":"Import DAGs into the REDCap Project !!! note DAGs can be renamed by simply changing the group name (data_access_group_name). DAGs can be created by providing group name value while unique group name should be set to blank. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of DAGs added or updated Examples: Create a new data access group >>> new_dag = [{ \"data_access_group_name\" : \"New DAG\" , \"unique_group_name\" : \"\" }] >>> proj . import_dags ( new_dag ) 1 Source code in redcap/project.py def import_dags ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import DAGs into the REDCap Project Note: DAGs can be renamed by simply changing the group name (data_access_group_name). DAGs can be created by providing group name value while unique group name should be set to blank. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of DAGs added or updated Examples: Create a new data access group >>> new_dag = [{\"data_access_group_name\": \"New DAG\", \"unique_group_name\": \"\"}] >>> proj.import_dags(new_dag) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"dag\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_dags()"},{"location":"api_reference/project/#redcap.project.Project.import_events","text":"Import Events into the REDCap Project !!! note This only works for longitudinal projects. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' override Optional[int] 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Events in the project while importing new Events. If override=0, then you can only add new Events or rename existing ones. 0 Returns: Type Description Union[int, str] Number of Events added or updated Examples: Create a new event >>> new_event = [{ \"event_name\" : \"Event 2\" , \"arm_num\" : \"1\" }] >>> proj . import_events ( new_event ) 1 Source code in redcap/project.py def import_events ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , override : Optional [ int ] = 0 , ): \"\"\" Import Events into the REDCap Project Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded override: 0 - false [default], 1 - true You may use override=1 as a 'delete all + import' action in order to erase all existing Events in the project while importing new Events. If override=0, then you can only add new Events or rename existing ones. Returns: Union[int, str]: Number of Events added or updated Examples: Create a new event >>> new_event = [{\"event_name\": \"Event 2\", \"arm_num\": \"1\"}] >>> proj.import_events(new_event) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"event\" , ) payload [ \"action\" ] = \"import\" payload [ \"override\" ] = override return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_events()"},{"location":"api_reference/project/#redcap.project.Project.import_file","text":"Import the contents of a file represented by file_object to a particular records field Parameters: Name Type Description Default record str Record ID required field str Field name where the file will go required file_name str File name visible in REDCap UI required file_object IO File object as returned by open required event Optional[str] For longitudinal projects, the unique event name None repeat_instance Union[int, str] (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). None Returns: Type Description List[dict] Empty JSON object Exceptions: Type Description ValueError Incorrect file field RedcapError Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> import tempfile >>> tmp_file = tempfile . TemporaryFile () >>> proj . import_file ( ... record = \"2\" , ... field = \"upload_field\" , ... file_name = \"myupload.txt\" , ... file_object = tmp_file , ... event = \"event_1_arm_1\" , ... ) [{}] Source code in redcap/project.py def import_file ( self , record : str , field : str , file_name : str , file_object : IO , event : Optional [ str ] = None , repeat_instance : Optional [ Union [ int , str ]] = None , ) -> EmptyJson : \"\"\" Import the contents of a file represented by file_object to a particular records field Args: record: Record ID field: Field name where the file will go file_name: File name visible in REDCap UI file_object: File object as returned by `open` event: For longitudinal projects, the unique event name repeat_instance: (Only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Returns: Empty JSON object Raises: ValueError: Incorrect file field RedcapError: Bad Request e.g. invalid record_id Examples: If your project has events, then you must specifiy the event of interest. Otherwise, you can leave the event parameter blank >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file( ... record=\"2\", ... field=\"upload_field\", ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... event=\"event_1_arm_1\", ... ) [{}] \"\"\" self . _check_file_field ( field ) # load up payload payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"file\" ) payload [ \"action\" ] = \"import\" payload [ \"field\" ] = field payload [ \"record\" ] = record if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = repeat_instance file_upload_dict : FileUpload = { \"file\" : ( file_name , file_object )} return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" , file = file_upload_dict ), )","title":"import_file()"},{"location":"api_reference/project/#redcap.project.Project.import_file_into_repository","text":"Import the contents of a file represented by file_object into the file repository Parameters: Name Type Description Default file_name str File name visible in REDCap UI required file_object IO File object as returned by open required folder_id Optional[int] The folder_id of a specific folder in the File Repository where you wish to store the file. If none is provided, the file will be stored in the top-level directory of the File Repository. None Returns: Type Description List[dict] Empty JSON object Examples: >>> import tempfile >>> tmp_file = tempfile . TemporaryFile () >>> proj . import_file_into_repository ( ... file_name = \"myupload.txt\" , ... file_object = tmp_file , ... ) [{}] Source code in redcap/project.py def import_file_into_repository ( self , file_name : str , file_object : IO , folder_id : Optional [ int ] = None , ) -> EmptyJson : \"\"\" Import the contents of a file represented by file_object into the file repository Args: file_name: File name visible in REDCap UI file_object: File object as returned by `open` folder_id: The folder_id of a specific folder in the File Repository where you wish to store the file. If none is provided, the file will be stored in the top-level directory of the File Repository. Returns: Empty JSON object Examples: >>> import tempfile >>> tmp_file = tempfile.TemporaryFile() >>> proj.import_file_into_repository( ... file_name=\"myupload.txt\", ... file_object=tmp_file, ... ) [{}] \"\"\" payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"fileRepository\" ) payload [ \"action\" ] = \"import\" if folder_id : payload [ \"folder_id\" ] = folder_id file_upload_dict : FileUpload = { \"file\" : ( file_name , file_object )} return cast ( EmptyJson , self . _call_api ( payload = payload , return_type = \"empty_json\" , file = file_upload_dict ), )","title":"import_file_into_repository()"},{"location":"api_reference/project/#redcap.project.Project.import_instrument_event_mappings","text":"Import the project's instrument to event mapping !!! note This only works for longitudinal projects. Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, import_format will be json-encoded 'json' Returns: Type Description Union[int, str] Number of instrument-event mappings imported Examples: Import instrument-event mappings >>> instrument_event_mappings = [{ \"arm_num\" : \"1\" , \"unique_event_name\" : \"event_1_arm_1\" , \"form\" : \"form_1\" }] >>> proj . import_instrument_event_mappings ( instrument_event_mappings ) 1 Source code in redcap/project.py def import_instrument_event_mappings ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): # pylint: disable=line-too-long \"\"\" Import the project's instrument to event mapping Note: This only works for longitudinal projects. Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, import_format will be json-encoded Returns: Union[int, str]: Number of instrument-event mappings imported Examples: Import instrument-event mappings >>> instrument_event_mappings = [{\"arm_num\": \"1\", \"unique_event_name\": \"event_1_arm_1\", \"form\": \"form_1\"}] >>> proj.import_instrument_event_mappings(instrument_event_mappings) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"formEventMapping\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_instrument_event_mappings()"},{"location":"api_reference/project/#redcap.project.Project.import_metadata","text":"Import metadata (Data Dictionary) into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import_format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' date_format Literal['YMD', 'DMY', 'MDY'] Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. 'YMD' Returns: Type Description Union[int, str] The number of imported fields Examples: >>> metadata = proj . export_metadata ( format_type = \"csv\" ) >>> proj . import_metadata ( metadata , import_format = \"csv\" ) 4 Source code in redcap/project.py def import_metadata ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , date_format : Literal [ \"YMD\" , \"DMY\" , \"MDY\" ] = \"YMD\" , ): \"\"\" Import metadata (Data Dictionary) into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import_format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded date_format: Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. Returns: Union[int, str]: The number of imported fields Examples: >>> metadata = proj.export_metadata(format_type=\"csv\") >>> proj.import_metadata(metadata, import_format=\"csv\") 4 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"metadata\" , ) payload [ \"dateFormat\" ] = date_format return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_metadata()"},{"location":"api_reference/project/#redcap.project.Project.import_records","text":"Import data into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] Note: If you pass a df, csv, or xml string, you should use the import_format parameter appropriately. Note: Keys of the dictionaries should be subset of project's, fields, but this isn't a requirement. If you provide keys that aren't defined fields, the returned response will contain an 'error' key. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' return_content Literal['count', 'ids', 'auto_ids', 'nothing'] By default, the response contains a 'count' key with the number of records just imported. By specifying 'ids', a list of ids imported will be returned. 'nothing' will only return the HTTP status code and no message. 'count' overwrite Literal['normal', 'overwrite'] 'overwrite' will erase values previously stored in the database if not specified in the to_import dictionaries. 'normal' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' date_format Literal['YMD', 'DMY', 'MDY'] Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. 'YMD' force_auto_number bool Enables automatic assignment of record IDs of imported records by REDCap. If this is set to true, and auto-numbering for records is enabled for the project, auto-numbering of imported records will be enabled. False Exceptions: Type Description RedcapError Bad request made, double check field names and other inputs Returns: Type Description Union[Dict, str] response from REDCap API, json-decoded if return_format == 'json' Examples: >>> new_record = [{ \"record_id\" : 3 , \"redcap_repeat_instance\" : 1 , \"field_1\" : 1 }] >>> proj . import_records ( new_record ) { 'count' : 1 } Source code in redcap/project.py def import_records ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_content : Literal [ \"count\" , \"ids\" , \"auto_ids\" , \"nothing\" ] = \"count\" , overwrite : Literal [ \"normal\" , \"overwrite\" ] = \"normal\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , date_format : Literal [ \"YMD\" , \"DMY\" , \"MDY\" ] = \"YMD\" , force_auto_number : bool = False , ): \"\"\" Import data into the REDCap Project Args: to_import: Note: If you pass a df, csv, or xml string, you should use the `import_format` parameter appropriately. Note: Keys of the dictionaries should be subset of project's, fields, but this isn't a requirement. If you provide keys that aren't defined fields, the returned response will contain an `'error'` key. return_format_type: Response format. By default, response will be json-decoded. return_content: By default, the response contains a 'count' key with the number of records just imported. By specifying 'ids', a list of ids imported will be returned. 'nothing' will only return the HTTP status code and no message. overwrite: `'overwrite'` will erase values previously stored in the database if not specified in the to_import dictionaries. import_format: Format of incoming data. By default, to_import will be json-encoded date_format: Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. force_auto_number: Enables automatic assignment of record IDs of imported records by REDCap. If this is set to true, and auto-numbering for records is enabled for the project, auto-numbering of imported records will be enabled. Raises: RedcapError: Bad request made, double check field names and other inputs Returns: Union[Dict, str]: response from REDCap API, json-decoded if `return_format` == `'json'` Examples: >>> new_record = [{\"record_id\": 3, \"redcap_repeat_instance\": 1, \"field_1\": 1}] >>> proj.import_records(new_record) {'count': 1} \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"record\" , ) payload [ \"overwriteBehavior\" ] = overwrite payload [ \"returnContent\" ] = return_content payload [ \"dateFormat\" ] = date_format payload [ \"forceAutoNumber\" ] = force_auto_number return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" , import_records_format = return_content , ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_records()"},{"location":"api_reference/project/#redcap.project.Project.import_repeating_instruments_events","text":"Import repeating instrument and event settings into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] The number of repeated instruments activated Examples: >>> rep_instruments = proj . export_repeating_instruments_events ( format_type = \"csv\" ) >>> proj . import_repeating_instruments_events ( rep_instruments , import_format = \"csv\" ) 1 Source code in redcap/project.py def import_repeating_instruments_events ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import repeating instrument and event settings into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: The number of repeated instruments activated Examples: >>> rep_instruments = proj.export_repeating_instruments_events(format_type=\"csv\") >>> proj.import_repeating_instruments_events(rep_instruments, import_format=\"csv\") 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"repeatingFormsEvents\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_repeating_instruments_events()"},{"location":"api_reference/project/#redcap.project.Project.import_user_dag_assignment","text":"Import User-DAG assignments into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of User-DAGs assignments added or updated Examples: Create a new user >>> new_user = \"pandeharris@gmail.com\" >>> proj . import_users ([{ \"username\" : new_user }]) 1 Add that user to a DAG >>> dag_mapping = [ ... { \"username\" : new_user , \"redcap_data_access_group\" : \"test_dag\" } ... ] >>> proj . import_user_dag_assignment ( dag_mapping ) 1 New user-DAG mapping >>> proj . export_user_dag_assignment () [{ 'username' : 'pandeharris@gmail.com' , 'redcap_data_access_group' : 'test_dag' }, { 'username' : ... , 'redcap_data_access_group' : '' }] Remove the user >>> proj . delete_users ([ new_user ]) 1 Source code in redcap/project.py def import_user_dag_assignment ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import User-DAG assignments into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of User-DAGs assignments added or updated Examples: Create a new user >>> new_user = \"pandeharris@gmail.com\" >>> proj.import_users([{\"username\": new_user}]) 1 Add that user to a DAG >>> dag_mapping = [ ... {\"username\": new_user, \"redcap_data_access_group\": \"test_dag\"} ... ] >>> proj.import_user_dag_assignment(dag_mapping) 1 New user-DAG mapping >>> proj.export_user_dag_assignment() [{'username': 'pandeharris@gmail.com', 'redcap_data_access_group': 'test_dag'}, {'username': ..., 'redcap_data_access_group': ''}] Remove the user >>> proj.delete_users([new_user]) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userDagMapping\" , ) payload [ \"action\" ] = \"import\" return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_user_dag_assignment()"},{"location":"api_reference/project/#redcap.project.Project.import_user_role_assignment","text":"Import User-Role assignments into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of user-role assignments added or updated Examples: >>> user_role_assignments = proj . export_user_role_assignment () >>> proj . import_user_role_assignment ( user_role_assignments ) 1 Source code in redcap/project.py def import_user_role_assignment ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import User-Role assignments into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of user-role assignments added or updated Examples: >>> user_role_assignments = proj.export_user_role_assignment() >>> proj.import_user_role_assignment(user_role_assignments) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userRoleMapping\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_user_role_assignment()"},{"location":"api_reference/project/#redcap.project.Project.import_user_roles","text":"Import user roles into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of user roles added or updated Examples: >>> roles = proj . export_user_roles () >>> proj . import_user_roles ( roles ) 1 Source code in redcap/project.py def import_user_roles ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import user roles into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of user roles added or updated Examples: >>> roles = proj.export_user_roles() >>> proj.import_user_roles(roles) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userRole\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_user_roles()"},{"location":"api_reference/project/#redcap.project.Project.import_users","text":"Import users/user rights into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of users added or updated Examples: Add test user. Only username is required >>> test_user = [{ \"username\" : \"pandeharris@gmail.com\" }] >>> proj . import_users ( test_user ) 1 All currently valid options for user rights >>> test_user = [ ... { \"username\" : \"pandeharris@gmail.com\" , \"email\" : \"pandeharris@gmail.com\" , ... \"firstname\" : \"REDCap Trial\" , \"lastname\" : \"User\" , \"expiration\" : \"\" , ... \"data_access_group\" : \"\" , \"data_access_group_id\" : \"\" , \"design\" : 0 , ... \"user_rights\" : 0 , \"data_export\" : 2 , \"reports\" : 1 , \"stats_and_charts\" : 1 , ... \"manage_survey_participants\" : 1 , \"calendar\" : 1 , \"data_access_groups\" : 0 , ... \"data_import_tool\" : 0 , \"data_comparison_tool\" : 0 , \"logging\" : 0 , ... \"file_repository\" : 1 , \"data_quality_create\" : 0 , \"data_quality_execute\" : 0 , ... \"api_export\" : 0 , \"api_import\" : 0 , \"mobile_app\" : 0 , ... \"mobile_app_download_data\" : 0 , \"record_create\" : 1 , \"record_rename\" : 0 , ... \"record_delete\" : 0 , \"lock_records_all_forms\" : 0 , \"lock_records\" : 0 , ... \"lock_records_customization\" : 0 , \"forms\" : { \"form_1\" : 3 }} ... ] >>> proj . import_users ( test_user ) 1 Source code in redcap/project.py def import_users ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import users/user rights into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of users added or updated Examples: Add test user. Only username is required >>> test_user = [{\"username\": \"pandeharris@gmail.com\"}] >>> proj.import_users(test_user) 1 All currently valid options for user rights >>> test_user = [ ... {\"username\": \"pandeharris@gmail.com\", \"email\": \"pandeharris@gmail.com\", ... \"firstname\": \"REDCap Trial\", \"lastname\": \"User\", \"expiration\": \"\", ... \"data_access_group\": \"\", \"data_access_group_id\": \"\", \"design\": 0, ... \"user_rights\": 0, \"data_export\": 2, \"reports\": 1, \"stats_and_charts\": 1, ... \"manage_survey_participants\": 1, \"calendar\": 1, \"data_access_groups\": 0, ... \"data_import_tool\": 0, \"data_comparison_tool\": 0, \"logging\": 0, ... \"file_repository\": 1, \"data_quality_create\": 0, \"data_quality_execute\": 0, ... \"api_export\": 0, \"api_import\": 0, \"mobile_app\": 0, ... \"mobile_app_download_data\": 0, \"record_create\": 1, \"record_rename\": 0, ... \"record_delete\": 0, \"lock_records_all_forms\": 0, \"lock_records\": 0, ... \"lock_records_customization\": 0, \"forms\": {\"form_1\": 3}} ... ] >>> proj.import_users(test_user) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"user\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_users()"},{"location":"api_reference/project/#redcap.project.Project.switch_dag","text":"Allows the current API user to switch (assign/reassign/unassign) their current Data Access Group assignment. The current user must have been assigned to multiple DAGs via the DAG Switcher page in the project Parameters: Name Type Description Default dag str The unique group name of the Data Access Group to which you wish to switch required Returns: Type Description Literal['1'] \"1\" if the user successfully switched DAGs Examples: >>> proj . switch_dag ( \"test_dag\" ) '1' Source code in redcap/project.py def switch_dag ( self , dag : str , ) -> Literal [ \"1\" ]: \"\"\" Allows the current API user to switch (assign/reassign/unassign) their current Data Access Group assignment. The current user must have been assigned to multiple DAGs via the DAG Switcher page in the project Args: dag: The unique group name of the Data Access Group to which you wish to switch Returns: \"1\" if the user successfully switched DAGs Examples: >>> proj.switch_dag(\"test_dag\") # doctest: +SKIP '1' \"\"\" # API docs say that \"1\" is the only valid value payload = self . _initialize_payload ( content = \"dag\" , return_format_type = \"csv\" ) payload [ \"action\" ] = \"switch\" payload [ \"dag\" ] = dag response = cast ( Literal [ \"1\" ], self . _call_api ( payload , return_type = \"str\" )) return response","title":"switch_dag()"},{"location":"api_reference/project_info/","text":"Project Info REDCap API methods for Project info ProjectInfo ( Base ) Responsible for all API methods under 'Projects' in the API Playground Source code in redcap/methods/project_info.py class ProjectInfo ( Base ): \"\"\"Responsible for all API methods under 'Projects' in the API Playground\"\"\" def export_project_info ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export Project Information Args: format_type: Format of returned data df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[str, List[Dict[str, Any]], pandas.DataFrame]: Project information Examples: >>> proj.export_project_info() {'project_id': ... ... 'in_production': 0, 'project_language': 'English', 'purpose': 0, 'purpose_other': '', ... 'project_grant_number': '', 'project_pi_firstname': '', 'project_pi_lastname': '', ... 'bypass_branching_erase_field_prompt': 0} \"\"\" payload = self . _initialize_payload ( content = \"project\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"project\" , format_type = format_type , df_kwargs = df_kwargs , ) def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server export_project_info ( self , format_type = 'json' , df_kwargs = None ) Export Project Information Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[str, List[Dict[str, Any]], pandas.DataFrame] Project information Examples: >>> proj . export_project_info () { 'project_id' : ... ... 'in_production' : 0 , 'project_language' : 'English' , 'purpose' : 0 , 'purpose_other' : '' , ... 'project_grant_number' : '' , 'project_pi_firstname' : '' , 'project_pi_lastname' : '' , ... 'bypass_branching_erase_field_prompt' : 0 } Source code in redcap/methods/project_info.py def export_project_info ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export Project Information Args: format_type: Format of returned data df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[str, List[Dict[str, Any]], pandas.DataFrame]: Project information Examples: >>> proj.export_project_info() {'project_id': ... ... 'in_production': 0, 'project_language': 'English', 'purpose': 0, 'purpose_other': '', ... 'project_grant_number': '', 'project_pi_firstname': '', 'project_pi_lastname': '', ... 'bypass_branching_erase_field_prompt': 0} \"\"\" payload = self . _initialize_payload ( content = \"project\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"project\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"Project Info"},{"location":"api_reference/project_info/#project-info","text":"REDCap API methods for Project info","title":"Project Info"},{"location":"api_reference/project_info/#redcap.methods.project_info.ProjectInfo","text":"Responsible for all API methods under 'Projects' in the API Playground Source code in redcap/methods/project_info.py class ProjectInfo ( Base ): \"\"\"Responsible for all API methods under 'Projects' in the API Playground\"\"\" def export_project_info ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export Project Information Args: format_type: Format of returned data df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[str, List[Dict[str, Any]], pandas.DataFrame]: Project information Examples: >>> proj.export_project_info() {'project_id': ... ... 'in_production': 0, 'project_language': 'English', 'purpose': 0, 'purpose_other': '', ... 'project_grant_number': '', 'project_pi_firstname': '', 'project_pi_lastname': '', ... 'bypass_branching_erase_field_prompt': 0} \"\"\" payload = self . _initialize_payload ( content = \"project\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"project\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"ProjectInfo"},{"location":"api_reference/project_info/#redcap.methods.project_info.ProjectInfo.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/project_info/#redcap.methods.project_info.ProjectInfo.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/project_info/#redcap.methods.project_info.ProjectInfo.forms","text":"Project form names","title":"forms"},{"location":"api_reference/project_info/#redcap.methods.project_info.ProjectInfo.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/project_info/#redcap.methods.project_info.ProjectInfo.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/project_info/#redcap.methods.project_info.ProjectInfo.token","text":"API token to a project","title":"token"},{"location":"api_reference/project_info/#redcap.methods.project_info.ProjectInfo.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/project_info/#redcap.methods.project_info.ProjectInfo.export_project_info","text":"Export Project Information Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[str, List[Dict[str, Any]], pandas.DataFrame] Project information Examples: >>> proj . export_project_info () { 'project_id' : ... ... 'in_production' : 0 , 'project_language' : 'English' , 'purpose' : 0 , 'purpose_other' : '' , ... 'project_grant_number' : '' , 'project_pi_firstname' : '' , 'project_pi_lastname' : '' , ... 'bypass_branching_erase_field_prompt' : 0 } Source code in redcap/methods/project_info.py def export_project_info ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export Project Information Args: format_type: Format of returned data df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[str, List[Dict[str, Any]], pandas.DataFrame]: Project information Examples: >>> proj.export_project_info() {'project_id': ... ... 'in_production': 0, 'project_language': 'English', 'purpose': 0, 'purpose_other': '', ... 'project_grant_number': '', 'project_pi_firstname': '', 'project_pi_lastname': '', ... 'bypass_branching_erase_field_prompt': 0} \"\"\" payload = self . _initialize_payload ( content = \"project\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"project\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_project_info()"},{"location":"api_reference/records/","text":"Records REDCap API methods for Project records Records ( Base ) Responsible for all API methods under 'Records' in the API Playground Source code in redcap/methods/records.py class Records ( Base ): \"\"\"Responsible for all API methods under 'Records' in the API Playground\"\"\" def _backfill_fields ( self , fields : Optional [ List [ str ]], forms : Optional [ List [ str ]]): \"\"\" Properly backfill fields to explicitly request the primary keys and \"form_complete\" fields of the project. REDCap won't include fields like the record_id if they're not on the form being requested, despite the user almost always wanting that field to be included. When record_id is requested, that automatically adds other fields like redcap_event_name, redcap_repeat_instrument, and redcap_repeat_instance to the reponse as well. Args: fields: requested fields forms: requested forms Returns: A list of all fields to request, including self.def_field (record_id) and the \"form_complete\" fields \"\"\" if forms and not fields : return [ f \" { form } _complete\" for form in forms ] + [ self . def_field ] if fields and self . def_field not in fields : return fields + [ self . def_field ] if not fields : return self . field_names + [ f \" { form } _complete\" for form in self . forms ] return fields # pylint: disable=too-many-locals def export_records ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , records : Optional [ List [ str ]] = None , fields : Optional [ Union [ List [ str ], str ]] = None , forms : Optional [ Union [ List [ str ], str ]] = None , events : Optional [ List [ str ]] = None , raw_or_label : Literal [ \"raw\" , \"label\" , \"both\" ] = \"raw\" , raw_or_label_headers : Literal [ \"raw\" , \"label\" ] = \"raw\" , event_name : Literal [ \"label\" , \"unique\" ] = \"label\" , record_type : Literal [ \"flat\" , \"eav\" ] = \"flat\" , export_survey_fields : bool = False , export_data_access_groups : bool = False , export_checkbox_labels : bool = False , filter_logic : Optional [ str ] = None , date_begin : Optional [ datetime ] = None , date_end : Optional [ datetime ] = None , decimal_character : Optional [ Literal [ \",\" , \".\" ]] = None , export_blank_for_gray_form_status : Optional [ bool ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long r \"\"\" Export data from the REDCap project. Args: format_type: Format of returned data. `'json'` returns json-decoded objects while `'csv'` and `'xml'` return other formats. `'df'` will attempt to return a `pandas.DataFrame` records: Array of record names specifying specific records to export. By default, all records are exported fields: Single field name or array of field names specifying specific fields to pull. By default, all fields are exported forms: Single form name or array of form names to export. If in the web UI, the form name has a space in it, replace the space with an underscore. By default, all forms are exported events: An array of unique event names from which to export records Note: This only applies to longitudinal projects raw_or_label: Export the raw coded values or labels for the options of multiple choice fields, or both raw_or_label_headers: Export the column names of the instrument as their raw value or their labeled value event_name: Export the unique event name or the event label record_type: Database output structure type export_survey_fields: Specifies whether or not to export the survey identifier field (e.g., \"redcap_survey_identifier\") or survey timestamp fields (e.g., form_name+\"_timestamp\") when surveys are utilized in the project export_data_access_groups: Specifies whether or not to export the `\"redcap_data_access_group\"` field when data access groups are utilized in the project Note: This flag is only viable if the user whose token is being used to make the API request is *not* in a data access group. If the user is in a group, then this flag will revert to its default value. export_checkbox_labels: Specify whether to export checkbox values as their label on export. filter_logic: Filter which records are returned using REDCap conditional syntax date_begin: Filter on records created after a date date_end: Filter on records created before a date decimal_character: Force all numbers into same decimal format export_blank_for_gray_form_status: Whether or not to export blank values for instrument complete status fields that have a gray status icon df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, `{'index_col': self.def_field}` Returns: Union[List[Dict[str, Any]], str, pd.DataFrame]: Exported data Examples: >>> proj.export_records() [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '1', 'upload_field': 'test_upload.txt', 'form_1_complete': '2'}, {'record_id': '2', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '0', 'checkbox_field___1': '0', 'checkbox_field___2': '0', 'upload_field': 'myupload.txt', 'form_1_complete': '0'}] >>> proj.export_records(filter_logic=\"[field_1] = 1\") [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '1', 'upload_field': 'test_upload.txt', 'form_1_complete': '2'}] >>> proj.export_records( ... format_type=\"csv\", ... fields=[\"field_1\", \"checkbox_field\"], ... raw_or_label=\"label\" ... ) 'record_id,redcap_event_name,redcap_repeat_instrument,redcap_repeat_instance,field_1,checkbox_field___1,checkbox_field___2\\n1,\"Event 1\",,1,Yes,Unchecked,Checked\\n2,\"Event 1\",,1,No,Unchecked,Unchecked\\n' >>> import pandas as pd >>> pd.set_option(\"display.max_columns\", 3) >>> proj.export_records(format_type=\"df\") redcap_repeat_instrument ... form_1_complete record_id redcap_event_name ... 1 event_1_arm_1 NaN ... 2 2 event_1_arm_1 NaN ... 0 ... \"\"\" # pylint: enable=line-too-long payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"record\" , format_type = format_type , record_type = record_type ) if isinstance ( fields , str ): fields = [ fields ] if isinstance ( forms , str ): forms = [ forms ] fields = self . _backfill_fields ( fields , forms ) keys_to_add = ( records , fields , forms , events , raw_or_label , raw_or_label_headers , event_name , export_survey_fields , export_data_access_groups , export_checkbox_labels , filter_logic , decimal_character , export_blank_for_gray_form_status , ) str_keys = ( \"records\" , \"fields\" , \"forms\" , \"events\" , \"rawOrLabel\" , \"rawOrLabelHeaders\" , \"eventName\" , \"exportSurveyFields\" , \"exportDataAccessGroups\" , \"exportCheckboxLabel\" , \"filterLogic\" , \"decimalCharacter\" , \"exportBlankForGrayFormStatus\" , ) for key , data in zip ( str_keys , keys_to_add ): if data : if key in ( \"fields\" , \"records\" , \"forms\" , \"events\" ): data = cast ( List [ str ], data ) for i , value in enumerate ( data ): payload [ f \" { key } [ { i } ]\" ] = value else : payload [ key ] = data if date_begin : payload [ \"dateRangeBegin\" ] = date_begin . strftime ( \"%Y-%m- %d %H:%M:%S\" ) if date_end : payload [ \"dateRangeEnd\" ] = date_end . strftime ( \"%Y-%m- %d %H:%M:%S\" ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"record\" , format_type = format_type , df_kwargs = df_kwargs , record_type = record_type , ) # pylint: enable=too-many-locals def import_records ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_content : Literal [ \"count\" , \"ids\" , \"auto_ids\" , \"nothing\" ] = \"count\" , overwrite : Literal [ \"normal\" , \"overwrite\" ] = \"normal\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , date_format : Literal [ \"YMD\" , \"DMY\" , \"MDY\" ] = \"YMD\" , force_auto_number : bool = False , ): \"\"\" Import data into the REDCap Project Args: to_import: Note: If you pass a df, csv, or xml string, you should use the `import_format` parameter appropriately. Note: Keys of the dictionaries should be subset of project's, fields, but this isn't a requirement. If you provide keys that aren't defined fields, the returned response will contain an `'error'` key. return_format_type: Response format. By default, response will be json-decoded. return_content: By default, the response contains a 'count' key with the number of records just imported. By specifying 'ids', a list of ids imported will be returned. 'nothing' will only return the HTTP status code and no message. overwrite: `'overwrite'` will erase values previously stored in the database if not specified in the to_import dictionaries. import_format: Format of incoming data. By default, to_import will be json-encoded date_format: Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. force_auto_number: Enables automatic assignment of record IDs of imported records by REDCap. If this is set to true, and auto-numbering for records is enabled for the project, auto-numbering of imported records will be enabled. Raises: RedcapError: Bad request made, double check field names and other inputs Returns: Union[Dict, str]: response from REDCap API, json-decoded if `return_format` == `'json'` Examples: >>> new_record = [{\"record_id\": 3, \"redcap_repeat_instance\": 1, \"field_1\": 1}] >>> proj.import_records(new_record) {'count': 1} \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"record\" , ) payload [ \"overwriteBehavior\" ] = overwrite payload [ \"returnContent\" ] = return_content payload [ \"dateFormat\" ] = date_format payload [ \"forceAutoNumber\" ] = force_auto_number return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" , import_records_format = return_content , ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def delete_records ( self , records : List [ str ], arm : Optional [ str ] = None , instrument : Optional [ str ] = None , event : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , delete_logging : bool = False , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): # pylint: disable=line-too-long \"\"\" Delete records from the project. Args: records: List of record IDs to delete from the project arm: the arm number of the arm in which the record(s) should be deleted. (This can only be used if the project is longitudinal with more than one arm.) NOTE: If the arm parameter is not provided, the specified records will be deleted from all arms in which they exist. Whereas, if arm is provided, they will only be deleted from the specified arm. instrument: the unique instrument name (column B in the Data Dictionary) of an instrument (as a string) if you wish to delete the data for all fields on the specified instrument for the records specified. event: the unique event name - only for longitudinal projects. NOTE: If instrument is provided for a longitudinal project, the event parameter is mandatory. repeat_instance: the repeating instance number for a repeating instrument or repeating event. NOTE: If project has repeating instruments/events, it will remove only the data for that repeating instance. delete_logging: provide a value of False (\"keep logging\") or True (\"delete logging\"). This activity when deleting the record?\" setting enabled by an administrator on the Edit Project Settings page. The default value for PyCap is False return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of records deleted Examples: >>> new_records = [ ... {\"record_id\": 3, \"redcap_repeat_instance\": 1, \"field_1\": 1}, ... {\"record_id\": 4, \"redcap_repeat_instance\": 1} ... ] >>> proj.import_records(new_records) {'count': 2} >>> proj.delete_records([\"3\", \"4\"]) 2 >>> new_record = [ ... {\"record_id\": 3, \"redcap_event_name\": \"event_1_arm_1\", \"redcap_repeat_instance\": 1, \"field_1\": 1,}, ... {\"record_id\": 3, \"redcap_event_name\": \"event_1_arm_1\", \"redcap_repeat_instance\": 2, \"field_1\": 0,}, ... ] >>> proj.import_records(new_record) {'count': 1} >>> proj.delete_records(records=[\"3\"], event=\"event_1_arm_1\", repeat_instance=2) 1 >>> proj.export_records(records=[\"3\"]) [{'record_id': '3', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '0', 'upload_field': '', 'form_1_complete': '0'}] >>> proj.delete_records(records=[\"3\"]) 1 \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"record\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" if delete_logging : payload [ \"delete_logging\" ] = \"1\" else : payload [ \"delete_logging\" ] = \"0\" if arm : payload [ \"arm\" ] = arm if instrument : payload [ \"instrument\" ] = instrument if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = repeat_instance # Turn list of records into dict, and append to payload records_dict = { f \"records[ { idx } ]\" : record for idx , record in enumerate ( records ) } payload . update ( records_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def generate_next_record_name ( self ) -> str : \"\"\" Get the next record name Returns: The next record name for a project with auto-numbering records enabled Examples: >>> proj.generate_next_record_name() '3' \"\"\" # Force the csv format here since if the project uses data access groups # or just non-standard record names then the result will not be JSON-compliant payload = self . _initialize_payload ( content = \"generateNextRecordName\" , format_type = \"csv\" ) return cast ( str , self . _call_api ( payload , return_type = \"str\" )) def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server delete_records ( self , records , arm = None , instrument = None , event = None , repeat_instance = None , delete_logging = False , return_format_type = 'json' ) Delete records from the project. Parameters: Name Type Description Default records List[str] List of record IDs to delete from the project required arm Optional[str] the arm number of the arm in which the record(s) should be deleted. (This can only be used if the project is longitudinal with more than one arm.) NOTE: If the arm parameter is not provided, the specified records will be deleted from all arms in which they exist. Whereas, if arm is provided, they will only be deleted from the specified arm. None instrument Optional[str] the unique instrument name (column B in the Data Dictionary) of an instrument (as a string) if you wish to delete the data for all fields on the specified instrument for the records specified. None event Optional[str] the unique event name - only for longitudinal projects. NOTE: If instrument is provided for a longitudinal project, the event parameter is mandatory. None repeat_instance Optional[int] the repeating instance number for a repeating instrument or repeating event. NOTE: If project has repeating instruments/events, it will remove only the data for that repeating instance. None delete_logging bool provide a value of False (\"keep logging\") or True (\"delete logging\"). This activity when deleting the record?\" setting enabled by an administrator on the Edit Project Settings page. The default value for PyCap is False False return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of records deleted Examples: >>> new_records = [ ... { \"record_id\" : 3 , \"redcap_repeat_instance\" : 1 , \"field_1\" : 1 }, ... { \"record_id\" : 4 , \"redcap_repeat_instance\" : 1 } ... ] >>> proj . import_records ( new_records ) { 'count' : 2 } >>> proj . delete_records ([ \"3\" , \"4\" ]) 2 >>> new_record = [ ... { \"record_id\" : 3 , \"redcap_event_name\" : \"event_1_arm_1\" , \"redcap_repeat_instance\" : 1 , \"field_1\" : 1 ,}, ... { \"record_id\" : 3 , \"redcap_event_name\" : \"event_1_arm_1\" , \"redcap_repeat_instance\" : 2 , \"field_1\" : 0 ,}, ... ] >>> proj . import_records ( new_record ) { 'count' : 1 } >>> proj . delete_records ( records = [ \"3\" ], event = \"event_1_arm_1\" , repeat_instance = 2 ) 1 >>> proj . export_records ( records = [ \"3\" ]) [{ 'record_id' : '3' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '0' , 'upload_field' : '' , 'form_1_complete' : '0' }] >>> proj . delete_records ( records = [ \"3\" ]) 1 Source code in redcap/methods/records.py def delete_records ( self , records : List [ str ], arm : Optional [ str ] = None , instrument : Optional [ str ] = None , event : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , delete_logging : bool = False , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): # pylint: disable=line-too-long \"\"\" Delete records from the project. Args: records: List of record IDs to delete from the project arm: the arm number of the arm in which the record(s) should be deleted. (This can only be used if the project is longitudinal with more than one arm.) NOTE: If the arm parameter is not provided, the specified records will be deleted from all arms in which they exist. Whereas, if arm is provided, they will only be deleted from the specified arm. instrument: the unique instrument name (column B in the Data Dictionary) of an instrument (as a string) if you wish to delete the data for all fields on the specified instrument for the records specified. event: the unique event name - only for longitudinal projects. NOTE: If instrument is provided for a longitudinal project, the event parameter is mandatory. repeat_instance: the repeating instance number for a repeating instrument or repeating event. NOTE: If project has repeating instruments/events, it will remove only the data for that repeating instance. delete_logging: provide a value of False (\"keep logging\") or True (\"delete logging\"). This activity when deleting the record?\" setting enabled by an administrator on the Edit Project Settings page. The default value for PyCap is False return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of records deleted Examples: >>> new_records = [ ... {\"record_id\": 3, \"redcap_repeat_instance\": 1, \"field_1\": 1}, ... {\"record_id\": 4, \"redcap_repeat_instance\": 1} ... ] >>> proj.import_records(new_records) {'count': 2} >>> proj.delete_records([\"3\", \"4\"]) 2 >>> new_record = [ ... {\"record_id\": 3, \"redcap_event_name\": \"event_1_arm_1\", \"redcap_repeat_instance\": 1, \"field_1\": 1,}, ... {\"record_id\": 3, \"redcap_event_name\": \"event_1_arm_1\", \"redcap_repeat_instance\": 2, \"field_1\": 0,}, ... ] >>> proj.import_records(new_record) {'count': 1} >>> proj.delete_records(records=[\"3\"], event=\"event_1_arm_1\", repeat_instance=2) 1 >>> proj.export_records(records=[\"3\"]) [{'record_id': '3', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '0', 'upload_field': '', 'form_1_complete': '0'}] >>> proj.delete_records(records=[\"3\"]) 1 \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"record\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" if delete_logging : payload [ \"delete_logging\" ] = \"1\" else : payload [ \"delete_logging\" ] = \"0\" if arm : payload [ \"arm\" ] = arm if instrument : payload [ \"instrument\" ] = instrument if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = repeat_instance # Turn list of records into dict, and append to payload records_dict = { f \"records[ { idx } ]\" : record for idx , record in enumerate ( records ) } payload . update ( records_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response export_records ( self , format_type = 'json' , records = None , fields = None , forms = None , events = None , raw_or_label = 'raw' , raw_or_label_headers = 'raw' , event_name = 'label' , record_type = 'flat' , export_survey_fields = False , export_data_access_groups = False , export_checkbox_labels = False , filter_logic = None , date_begin = None , date_end = None , decimal_character = None , export_blank_for_gray_form_status = None , df_kwargs = None ) Export data from the REDCap project. Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data. 'json' returns json-decoded objects while 'csv' and 'xml' return other formats. 'df' will attempt to return a pandas.DataFrame 'json' records Optional[List[str]] Array of record names specifying specific records to export. By default, all records are exported None fields Union[List[str], str] Single field name or array of field names specifying specific fields to pull. By default, all fields are exported None forms Union[List[str], str] Single form name or array of form names to export. If in the web UI, the form name has a space in it, replace the space with an underscore. By default, all forms are exported None events Optional[List[str]] An array of unique event names from which to export records Note: This only applies to longitudinal projects None raw_or_label Literal['raw', 'label', 'both'] Export the raw coded values or labels for the options of multiple choice fields, or both 'raw' raw_or_label_headers Literal['raw', 'label'] Export the column names of the instrument as their raw value or their labeled value 'raw' event_name Literal['label', 'unique'] Export the unique event name or the event label 'label' record_type Literal['flat', 'eav'] Database output structure type 'flat' export_survey_fields bool Specifies whether or not to export the survey identifier field (e.g., \"redcap_survey_identifier\") or survey timestamp fields (e.g., form_name+\"_timestamp\") when surveys are utilized in the project False export_data_access_groups bool Specifies whether or not to export the \"redcap_data_access_group\" field when data access groups are utilized in the project Note: This flag is only viable if the user whose token is being used to make the API request is not in a data access group. If the user is in a group, then this flag will revert to its default value. False export_checkbox_labels bool Specify whether to export checkbox values as their label on export. False filter_logic Optional[str] Filter which records are returned using REDCap conditional syntax None date_begin Optional[datetime.datetime] Filter on records created after a date None date_end Optional[datetime.datetime] Filter on records created before a date None decimal_character Optional[Literal[',', '.']] Force all numbers into same decimal format None export_blank_for_gray_form_status Optional[bool] Whether or not to export blank values for instrument complete status fields that have a gray status icon None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, {'index_col': self.def_field} None Returns: Type Description Union[List[Dict[str, Any]], str, pd.DataFrame] Exported data Examples: >>> proj . export_records () [{ 'record_id' : '1' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '1' , 'upload_field' : 'test_upload.txt' , 'form_1_complete' : '2' }, { 'record_id' : '2' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '0' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '0' , 'upload_field' : 'myupload.txt' , 'form_1_complete' : '0' }] >>> proj . export_records ( filter_logic = \"[field_1] = 1\" ) [{ 'record_id' : '1' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '1' , 'upload_field' : 'test_upload.txt' , 'form_1_complete' : '2' }] >>> proj . export_records ( ... format_type = \"csv\" , ... fields = [ \"field_1\" , \"checkbox_field\" ], ... raw_or_label = \"label\" ... ) 'record_id,redcap_event_name,redcap_repeat_instrument,redcap_repeat_instance,field_1,checkbox_field___1,checkbox_field___2 \\n 1,\"Event 1\",,1,Yes,Unchecked,Checked \\n 2,\"Event 1\",,1,No,Unchecked,Unchecked \\n ' >>> import pandas as pd >>> pd . set_option ( \"display.max_columns\" , 3 ) >>> proj . export_records ( format_type = \"df\" ) redcap_repeat_instrument ... form_1_complete record_id redcap_event_name ... 1 event_1_arm_1 NaN ... 2 2 event_1_arm_1 NaN ... 0 ... Source code in redcap/methods/records.py def export_records ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , records : Optional [ List [ str ]] = None , fields : Optional [ Union [ List [ str ], str ]] = None , forms : Optional [ Union [ List [ str ], str ]] = None , events : Optional [ List [ str ]] = None , raw_or_label : Literal [ \"raw\" , \"label\" , \"both\" ] = \"raw\" , raw_or_label_headers : Literal [ \"raw\" , \"label\" ] = \"raw\" , event_name : Literal [ \"label\" , \"unique\" ] = \"label\" , record_type : Literal [ \"flat\" , \"eav\" ] = \"flat\" , export_survey_fields : bool = False , export_data_access_groups : bool = False , export_checkbox_labels : bool = False , filter_logic : Optional [ str ] = None , date_begin : Optional [ datetime ] = None , date_end : Optional [ datetime ] = None , decimal_character : Optional [ Literal [ \",\" , \".\" ]] = None , export_blank_for_gray_form_status : Optional [ bool ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long r \"\"\" Export data from the REDCap project. Args: format_type: Format of returned data. `'json'` returns json-decoded objects while `'csv'` and `'xml'` return other formats. `'df'` will attempt to return a `pandas.DataFrame` records: Array of record names specifying specific records to export. By default, all records are exported fields: Single field name or array of field names specifying specific fields to pull. By default, all fields are exported forms: Single form name or array of form names to export. If in the web UI, the form name has a space in it, replace the space with an underscore. By default, all forms are exported events: An array of unique event names from which to export records Note: This only applies to longitudinal projects raw_or_label: Export the raw coded values or labels for the options of multiple choice fields, or both raw_or_label_headers: Export the column names of the instrument as their raw value or their labeled value event_name: Export the unique event name or the event label record_type: Database output structure type export_survey_fields: Specifies whether or not to export the survey identifier field (e.g., \"redcap_survey_identifier\") or survey timestamp fields (e.g., form_name+\"_timestamp\") when surveys are utilized in the project export_data_access_groups: Specifies whether or not to export the `\"redcap_data_access_group\"` field when data access groups are utilized in the project Note: This flag is only viable if the user whose token is being used to make the API request is *not* in a data access group. If the user is in a group, then this flag will revert to its default value. export_checkbox_labels: Specify whether to export checkbox values as their label on export. filter_logic: Filter which records are returned using REDCap conditional syntax date_begin: Filter on records created after a date date_end: Filter on records created before a date decimal_character: Force all numbers into same decimal format export_blank_for_gray_form_status: Whether or not to export blank values for instrument complete status fields that have a gray status icon df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, `{'index_col': self.def_field}` Returns: Union[List[Dict[str, Any]], str, pd.DataFrame]: Exported data Examples: >>> proj.export_records() [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '1', 'upload_field': 'test_upload.txt', 'form_1_complete': '2'}, {'record_id': '2', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '0', 'checkbox_field___1': '0', 'checkbox_field___2': '0', 'upload_field': 'myupload.txt', 'form_1_complete': '0'}] >>> proj.export_records(filter_logic=\"[field_1] = 1\") [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '1', 'upload_field': 'test_upload.txt', 'form_1_complete': '2'}] >>> proj.export_records( ... format_type=\"csv\", ... fields=[\"field_1\", \"checkbox_field\"], ... raw_or_label=\"label\" ... ) 'record_id,redcap_event_name,redcap_repeat_instrument,redcap_repeat_instance,field_1,checkbox_field___1,checkbox_field___2\\n1,\"Event 1\",,1,Yes,Unchecked,Checked\\n2,\"Event 1\",,1,No,Unchecked,Unchecked\\n' >>> import pandas as pd >>> pd.set_option(\"display.max_columns\", 3) >>> proj.export_records(format_type=\"df\") redcap_repeat_instrument ... form_1_complete record_id redcap_event_name ... 1 event_1_arm_1 NaN ... 2 2 event_1_arm_1 NaN ... 0 ... \"\"\" # pylint: enable=line-too-long payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"record\" , format_type = format_type , record_type = record_type ) if isinstance ( fields , str ): fields = [ fields ] if isinstance ( forms , str ): forms = [ forms ] fields = self . _backfill_fields ( fields , forms ) keys_to_add = ( records , fields , forms , events , raw_or_label , raw_or_label_headers , event_name , export_survey_fields , export_data_access_groups , export_checkbox_labels , filter_logic , decimal_character , export_blank_for_gray_form_status , ) str_keys = ( \"records\" , \"fields\" , \"forms\" , \"events\" , \"rawOrLabel\" , \"rawOrLabelHeaders\" , \"eventName\" , \"exportSurveyFields\" , \"exportDataAccessGroups\" , \"exportCheckboxLabel\" , \"filterLogic\" , \"decimalCharacter\" , \"exportBlankForGrayFormStatus\" , ) for key , data in zip ( str_keys , keys_to_add ): if data : if key in ( \"fields\" , \"records\" , \"forms\" , \"events\" ): data = cast ( List [ str ], data ) for i , value in enumerate ( data ): payload [ f \" { key } [ { i } ]\" ] = value else : payload [ key ] = data if date_begin : payload [ \"dateRangeBegin\" ] = date_begin . strftime ( \"%Y-%m- %d %H:%M:%S\" ) if date_end : payload [ \"dateRangeEnd\" ] = date_end . strftime ( \"%Y-%m- %d %H:%M:%S\" ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"record\" , format_type = format_type , df_kwargs = df_kwargs , record_type = record_type , ) generate_next_record_name ( self ) Get the next record name Returns: Type Description str The next record name for a project with auto-numbering records enabled Examples: >>> proj . generate_next_record_name () '3' Source code in redcap/methods/records.py def generate_next_record_name ( self ) -> str : \"\"\" Get the next record name Returns: The next record name for a project with auto-numbering records enabled Examples: >>> proj.generate_next_record_name() '3' \"\"\" # Force the csv format here since if the project uses data access groups # or just non-standard record names then the result will not be JSON-compliant payload = self . _initialize_payload ( content = \"generateNextRecordName\" , format_type = \"csv\" ) return cast ( str , self . _call_api ( payload , return_type = \"str\" )) import_records ( self , to_import , return_format_type = 'json' , return_content = 'count' , overwrite = 'normal' , import_format = 'json' , date_format = 'YMD' , force_auto_number = False ) Import data into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] Note: If you pass a df, csv, or xml string, you should use the import_format parameter appropriately. Note: Keys of the dictionaries should be subset of project's, fields, but this isn't a requirement. If you provide keys that aren't defined fields, the returned response will contain an 'error' key. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' return_content Literal['count', 'ids', 'auto_ids', 'nothing'] By default, the response contains a 'count' key with the number of records just imported. By specifying 'ids', a list of ids imported will be returned. 'nothing' will only return the HTTP status code and no message. 'count' overwrite Literal['normal', 'overwrite'] 'overwrite' will erase values previously stored in the database if not specified in the to_import dictionaries. 'normal' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' date_format Literal['YMD', 'DMY', 'MDY'] Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. 'YMD' force_auto_number bool Enables automatic assignment of record IDs of imported records by REDCap. If this is set to true, and auto-numbering for records is enabled for the project, auto-numbering of imported records will be enabled. False Exceptions: Type Description RedcapError Bad request made, double check field names and other inputs Returns: Type Description Union[Dict, str] response from REDCap API, json-decoded if return_format == 'json' Examples: >>> new_record = [{ \"record_id\" : 3 , \"redcap_repeat_instance\" : 1 , \"field_1\" : 1 }] >>> proj . import_records ( new_record ) { 'count' : 1 } Source code in redcap/methods/records.py def import_records ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_content : Literal [ \"count\" , \"ids\" , \"auto_ids\" , \"nothing\" ] = \"count\" , overwrite : Literal [ \"normal\" , \"overwrite\" ] = \"normal\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , date_format : Literal [ \"YMD\" , \"DMY\" , \"MDY\" ] = \"YMD\" , force_auto_number : bool = False , ): \"\"\" Import data into the REDCap Project Args: to_import: Note: If you pass a df, csv, or xml string, you should use the `import_format` parameter appropriately. Note: Keys of the dictionaries should be subset of project's, fields, but this isn't a requirement. If you provide keys that aren't defined fields, the returned response will contain an `'error'` key. return_format_type: Response format. By default, response will be json-decoded. return_content: By default, the response contains a 'count' key with the number of records just imported. By specifying 'ids', a list of ids imported will be returned. 'nothing' will only return the HTTP status code and no message. overwrite: `'overwrite'` will erase values previously stored in the database if not specified in the to_import dictionaries. import_format: Format of incoming data. By default, to_import will be json-encoded date_format: Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. force_auto_number: Enables automatic assignment of record IDs of imported records by REDCap. If this is set to true, and auto-numbering for records is enabled for the project, auto-numbering of imported records will be enabled. Raises: RedcapError: Bad request made, double check field names and other inputs Returns: Union[Dict, str]: response from REDCap API, json-decoded if `return_format` == `'json'` Examples: >>> new_record = [{\"record_id\": 3, \"redcap_repeat_instance\": 1, \"field_1\": 1}] >>> proj.import_records(new_record) {'count': 1} \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"record\" , ) payload [ \"overwriteBehavior\" ] = overwrite payload [ \"returnContent\" ] = return_content payload [ \"dateFormat\" ] = date_format payload [ \"forceAutoNumber\" ] = force_auto_number return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" , import_records_format = return_content , ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"Records"},{"location":"api_reference/records/#records","text":"REDCap API methods for Project records","title":"Records"},{"location":"api_reference/records/#redcap.methods.records.Records","text":"Responsible for all API methods under 'Records' in the API Playground Source code in redcap/methods/records.py class Records ( Base ): \"\"\"Responsible for all API methods under 'Records' in the API Playground\"\"\" def _backfill_fields ( self , fields : Optional [ List [ str ]], forms : Optional [ List [ str ]]): \"\"\" Properly backfill fields to explicitly request the primary keys and \"form_complete\" fields of the project. REDCap won't include fields like the record_id if they're not on the form being requested, despite the user almost always wanting that field to be included. When record_id is requested, that automatically adds other fields like redcap_event_name, redcap_repeat_instrument, and redcap_repeat_instance to the reponse as well. Args: fields: requested fields forms: requested forms Returns: A list of all fields to request, including self.def_field (record_id) and the \"form_complete\" fields \"\"\" if forms and not fields : return [ f \" { form } _complete\" for form in forms ] + [ self . def_field ] if fields and self . def_field not in fields : return fields + [ self . def_field ] if not fields : return self . field_names + [ f \" { form } _complete\" for form in self . forms ] return fields # pylint: disable=too-many-locals def export_records ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , records : Optional [ List [ str ]] = None , fields : Optional [ Union [ List [ str ], str ]] = None , forms : Optional [ Union [ List [ str ], str ]] = None , events : Optional [ List [ str ]] = None , raw_or_label : Literal [ \"raw\" , \"label\" , \"both\" ] = \"raw\" , raw_or_label_headers : Literal [ \"raw\" , \"label\" ] = \"raw\" , event_name : Literal [ \"label\" , \"unique\" ] = \"label\" , record_type : Literal [ \"flat\" , \"eav\" ] = \"flat\" , export_survey_fields : bool = False , export_data_access_groups : bool = False , export_checkbox_labels : bool = False , filter_logic : Optional [ str ] = None , date_begin : Optional [ datetime ] = None , date_end : Optional [ datetime ] = None , decimal_character : Optional [ Literal [ \",\" , \".\" ]] = None , export_blank_for_gray_form_status : Optional [ bool ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long r \"\"\" Export data from the REDCap project. Args: format_type: Format of returned data. `'json'` returns json-decoded objects while `'csv'` and `'xml'` return other formats. `'df'` will attempt to return a `pandas.DataFrame` records: Array of record names specifying specific records to export. By default, all records are exported fields: Single field name or array of field names specifying specific fields to pull. By default, all fields are exported forms: Single form name or array of form names to export. If in the web UI, the form name has a space in it, replace the space with an underscore. By default, all forms are exported events: An array of unique event names from which to export records Note: This only applies to longitudinal projects raw_or_label: Export the raw coded values or labels for the options of multiple choice fields, or both raw_or_label_headers: Export the column names of the instrument as their raw value or their labeled value event_name: Export the unique event name or the event label record_type: Database output structure type export_survey_fields: Specifies whether or not to export the survey identifier field (e.g., \"redcap_survey_identifier\") or survey timestamp fields (e.g., form_name+\"_timestamp\") when surveys are utilized in the project export_data_access_groups: Specifies whether or not to export the `\"redcap_data_access_group\"` field when data access groups are utilized in the project Note: This flag is only viable if the user whose token is being used to make the API request is *not* in a data access group. If the user is in a group, then this flag will revert to its default value. export_checkbox_labels: Specify whether to export checkbox values as their label on export. filter_logic: Filter which records are returned using REDCap conditional syntax date_begin: Filter on records created after a date date_end: Filter on records created before a date decimal_character: Force all numbers into same decimal format export_blank_for_gray_form_status: Whether or not to export blank values for instrument complete status fields that have a gray status icon df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, `{'index_col': self.def_field}` Returns: Union[List[Dict[str, Any]], str, pd.DataFrame]: Exported data Examples: >>> proj.export_records() [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '1', 'upload_field': 'test_upload.txt', 'form_1_complete': '2'}, {'record_id': '2', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '0', 'checkbox_field___1': '0', 'checkbox_field___2': '0', 'upload_field': 'myupload.txt', 'form_1_complete': '0'}] >>> proj.export_records(filter_logic=\"[field_1] = 1\") [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '1', 'upload_field': 'test_upload.txt', 'form_1_complete': '2'}] >>> proj.export_records( ... format_type=\"csv\", ... fields=[\"field_1\", \"checkbox_field\"], ... raw_or_label=\"label\" ... ) 'record_id,redcap_event_name,redcap_repeat_instrument,redcap_repeat_instance,field_1,checkbox_field___1,checkbox_field___2\\n1,\"Event 1\",,1,Yes,Unchecked,Checked\\n2,\"Event 1\",,1,No,Unchecked,Unchecked\\n' >>> import pandas as pd >>> pd.set_option(\"display.max_columns\", 3) >>> proj.export_records(format_type=\"df\") redcap_repeat_instrument ... form_1_complete record_id redcap_event_name ... 1 event_1_arm_1 NaN ... 2 2 event_1_arm_1 NaN ... 0 ... \"\"\" # pylint: enable=line-too-long payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"record\" , format_type = format_type , record_type = record_type ) if isinstance ( fields , str ): fields = [ fields ] if isinstance ( forms , str ): forms = [ forms ] fields = self . _backfill_fields ( fields , forms ) keys_to_add = ( records , fields , forms , events , raw_or_label , raw_or_label_headers , event_name , export_survey_fields , export_data_access_groups , export_checkbox_labels , filter_logic , decimal_character , export_blank_for_gray_form_status , ) str_keys = ( \"records\" , \"fields\" , \"forms\" , \"events\" , \"rawOrLabel\" , \"rawOrLabelHeaders\" , \"eventName\" , \"exportSurveyFields\" , \"exportDataAccessGroups\" , \"exportCheckboxLabel\" , \"filterLogic\" , \"decimalCharacter\" , \"exportBlankForGrayFormStatus\" , ) for key , data in zip ( str_keys , keys_to_add ): if data : if key in ( \"fields\" , \"records\" , \"forms\" , \"events\" ): data = cast ( List [ str ], data ) for i , value in enumerate ( data ): payload [ f \" { key } [ { i } ]\" ] = value else : payload [ key ] = data if date_begin : payload [ \"dateRangeBegin\" ] = date_begin . strftime ( \"%Y-%m- %d %H:%M:%S\" ) if date_end : payload [ \"dateRangeEnd\" ] = date_end . strftime ( \"%Y-%m- %d %H:%M:%S\" ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"record\" , format_type = format_type , df_kwargs = df_kwargs , record_type = record_type , ) # pylint: enable=too-many-locals def import_records ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_content : Literal [ \"count\" , \"ids\" , \"auto_ids\" , \"nothing\" ] = \"count\" , overwrite : Literal [ \"normal\" , \"overwrite\" ] = \"normal\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , date_format : Literal [ \"YMD\" , \"DMY\" , \"MDY\" ] = \"YMD\" , force_auto_number : bool = False , ): \"\"\" Import data into the REDCap Project Args: to_import: Note: If you pass a df, csv, or xml string, you should use the `import_format` parameter appropriately. Note: Keys of the dictionaries should be subset of project's, fields, but this isn't a requirement. If you provide keys that aren't defined fields, the returned response will contain an `'error'` key. return_format_type: Response format. By default, response will be json-decoded. return_content: By default, the response contains a 'count' key with the number of records just imported. By specifying 'ids', a list of ids imported will be returned. 'nothing' will only return the HTTP status code and no message. overwrite: `'overwrite'` will erase values previously stored in the database if not specified in the to_import dictionaries. import_format: Format of incoming data. By default, to_import will be json-encoded date_format: Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. force_auto_number: Enables automatic assignment of record IDs of imported records by REDCap. If this is set to true, and auto-numbering for records is enabled for the project, auto-numbering of imported records will be enabled. Raises: RedcapError: Bad request made, double check field names and other inputs Returns: Union[Dict, str]: response from REDCap API, json-decoded if `return_format` == `'json'` Examples: >>> new_record = [{\"record_id\": 3, \"redcap_repeat_instance\": 1, \"field_1\": 1}] >>> proj.import_records(new_record) {'count': 1} \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"record\" , ) payload [ \"overwriteBehavior\" ] = overwrite payload [ \"returnContent\" ] = return_content payload [ \"dateFormat\" ] = date_format payload [ \"forceAutoNumber\" ] = force_auto_number return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" , import_records_format = return_content , ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def delete_records ( self , records : List [ str ], arm : Optional [ str ] = None , instrument : Optional [ str ] = None , event : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , delete_logging : bool = False , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): # pylint: disable=line-too-long \"\"\" Delete records from the project. Args: records: List of record IDs to delete from the project arm: the arm number of the arm in which the record(s) should be deleted. (This can only be used if the project is longitudinal with more than one arm.) NOTE: If the arm parameter is not provided, the specified records will be deleted from all arms in which they exist. Whereas, if arm is provided, they will only be deleted from the specified arm. instrument: the unique instrument name (column B in the Data Dictionary) of an instrument (as a string) if you wish to delete the data for all fields on the specified instrument for the records specified. event: the unique event name - only for longitudinal projects. NOTE: If instrument is provided for a longitudinal project, the event parameter is mandatory. repeat_instance: the repeating instance number for a repeating instrument or repeating event. NOTE: If project has repeating instruments/events, it will remove only the data for that repeating instance. delete_logging: provide a value of False (\"keep logging\") or True (\"delete logging\"). This activity when deleting the record?\" setting enabled by an administrator on the Edit Project Settings page. The default value for PyCap is False return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of records deleted Examples: >>> new_records = [ ... {\"record_id\": 3, \"redcap_repeat_instance\": 1, \"field_1\": 1}, ... {\"record_id\": 4, \"redcap_repeat_instance\": 1} ... ] >>> proj.import_records(new_records) {'count': 2} >>> proj.delete_records([\"3\", \"4\"]) 2 >>> new_record = [ ... {\"record_id\": 3, \"redcap_event_name\": \"event_1_arm_1\", \"redcap_repeat_instance\": 1, \"field_1\": 1,}, ... {\"record_id\": 3, \"redcap_event_name\": \"event_1_arm_1\", \"redcap_repeat_instance\": 2, \"field_1\": 0,}, ... ] >>> proj.import_records(new_record) {'count': 1} >>> proj.delete_records(records=[\"3\"], event=\"event_1_arm_1\", repeat_instance=2) 1 >>> proj.export_records(records=[\"3\"]) [{'record_id': '3', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '0', 'upload_field': '', 'form_1_complete': '0'}] >>> proj.delete_records(records=[\"3\"]) 1 \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"record\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" if delete_logging : payload [ \"delete_logging\" ] = \"1\" else : payload [ \"delete_logging\" ] = \"0\" if arm : payload [ \"arm\" ] = arm if instrument : payload [ \"instrument\" ] = instrument if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = repeat_instance # Turn list of records into dict, and append to payload records_dict = { f \"records[ { idx } ]\" : record for idx , record in enumerate ( records ) } payload . update ( records_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def generate_next_record_name ( self ) -> str : \"\"\" Get the next record name Returns: The next record name for a project with auto-numbering records enabled Examples: >>> proj.generate_next_record_name() '3' \"\"\" # Force the csv format here since if the project uses data access groups # or just non-standard record names then the result will not be JSON-compliant payload = self . _initialize_payload ( content = \"generateNextRecordName\" , format_type = \"csv\" ) return cast ( str , self . _call_api ( payload , return_type = \"str\" ))","title":"Records"},{"location":"api_reference/records/#redcap.methods.records.Records.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/records/#redcap.methods.records.Records.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/records/#redcap.methods.records.Records.forms","text":"Project form names","title":"forms"},{"location":"api_reference/records/#redcap.methods.records.Records.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/records/#redcap.methods.records.Records.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/records/#redcap.methods.records.Records.token","text":"API token to a project","title":"token"},{"location":"api_reference/records/#redcap.methods.records.Records.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/records/#redcap.methods.records.Records.delete_records","text":"Delete records from the project. Parameters: Name Type Description Default records List[str] List of record IDs to delete from the project required arm Optional[str] the arm number of the arm in which the record(s) should be deleted. (This can only be used if the project is longitudinal with more than one arm.) NOTE: If the arm parameter is not provided, the specified records will be deleted from all arms in which they exist. Whereas, if arm is provided, they will only be deleted from the specified arm. None instrument Optional[str] the unique instrument name (column B in the Data Dictionary) of an instrument (as a string) if you wish to delete the data for all fields on the specified instrument for the records specified. None event Optional[str] the unique event name - only for longitudinal projects. NOTE: If instrument is provided for a longitudinal project, the event parameter is mandatory. None repeat_instance Optional[int] the repeating instance number for a repeating instrument or repeating event. NOTE: If project has repeating instruments/events, it will remove only the data for that repeating instance. None delete_logging bool provide a value of False (\"keep logging\") or True (\"delete logging\"). This activity when deleting the record?\" setting enabled by an administrator on the Edit Project Settings page. The default value for PyCap is False False return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of records deleted Examples: >>> new_records = [ ... { \"record_id\" : 3 , \"redcap_repeat_instance\" : 1 , \"field_1\" : 1 }, ... { \"record_id\" : 4 , \"redcap_repeat_instance\" : 1 } ... ] >>> proj . import_records ( new_records ) { 'count' : 2 } >>> proj . delete_records ([ \"3\" , \"4\" ]) 2 >>> new_record = [ ... { \"record_id\" : 3 , \"redcap_event_name\" : \"event_1_arm_1\" , \"redcap_repeat_instance\" : 1 , \"field_1\" : 1 ,}, ... { \"record_id\" : 3 , \"redcap_event_name\" : \"event_1_arm_1\" , \"redcap_repeat_instance\" : 2 , \"field_1\" : 0 ,}, ... ] >>> proj . import_records ( new_record ) { 'count' : 1 } >>> proj . delete_records ( records = [ \"3\" ], event = \"event_1_arm_1\" , repeat_instance = 2 ) 1 >>> proj . export_records ( records = [ \"3\" ]) [{ 'record_id' : '3' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '0' , 'upload_field' : '' , 'form_1_complete' : '0' }] >>> proj . delete_records ( records = [ \"3\" ]) 1 Source code in redcap/methods/records.py def delete_records ( self , records : List [ str ], arm : Optional [ str ] = None , instrument : Optional [ str ] = None , event : Optional [ str ] = None , repeat_instance : Optional [ int ] = None , delete_logging : bool = False , return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): # pylint: disable=line-too-long \"\"\" Delete records from the project. Args: records: List of record IDs to delete from the project arm: the arm number of the arm in which the record(s) should be deleted. (This can only be used if the project is longitudinal with more than one arm.) NOTE: If the arm parameter is not provided, the specified records will be deleted from all arms in which they exist. Whereas, if arm is provided, they will only be deleted from the specified arm. instrument: the unique instrument name (column B in the Data Dictionary) of an instrument (as a string) if you wish to delete the data for all fields on the specified instrument for the records specified. event: the unique event name - only for longitudinal projects. NOTE: If instrument is provided for a longitudinal project, the event parameter is mandatory. repeat_instance: the repeating instance number for a repeating instrument or repeating event. NOTE: If project has repeating instruments/events, it will remove only the data for that repeating instance. delete_logging: provide a value of False (\"keep logging\") or True (\"delete logging\"). This activity when deleting the record?\" setting enabled by an administrator on the Edit Project Settings page. The default value for PyCap is False return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of records deleted Examples: >>> new_records = [ ... {\"record_id\": 3, \"redcap_repeat_instance\": 1, \"field_1\": 1}, ... {\"record_id\": 4, \"redcap_repeat_instance\": 1} ... ] >>> proj.import_records(new_records) {'count': 2} >>> proj.delete_records([\"3\", \"4\"]) 2 >>> new_record = [ ... {\"record_id\": 3, \"redcap_event_name\": \"event_1_arm_1\", \"redcap_repeat_instance\": 1, \"field_1\": 1,}, ... {\"record_id\": 3, \"redcap_event_name\": \"event_1_arm_1\", \"redcap_repeat_instance\": 2, \"field_1\": 0,}, ... ] >>> proj.import_records(new_record) {'count': 1} >>> proj.delete_records(records=[\"3\"], event=\"event_1_arm_1\", repeat_instance=2) 1 >>> proj.export_records(records=[\"3\"]) [{'record_id': '3', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '0', 'upload_field': '', 'form_1_complete': '0'}] >>> proj.delete_records(records=[\"3\"]) 1 \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"record\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" if delete_logging : payload [ \"delete_logging\" ] = \"1\" else : payload [ \"delete_logging\" ] = \"0\" if arm : payload [ \"arm\" ] = arm if instrument : payload [ \"instrument\" ] = instrument if event : payload [ \"event\" ] = event if repeat_instance : payload [ \"repeat_instance\" ] = repeat_instance # Turn list of records into dict, and append to payload records_dict = { f \"records[ { idx } ]\" : record for idx , record in enumerate ( records ) } payload . update ( records_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"delete_records()"},{"location":"api_reference/records/#redcap.methods.records.Records.export_records","text":"Export data from the REDCap project. Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data. 'json' returns json-decoded objects while 'csv' and 'xml' return other formats. 'df' will attempt to return a pandas.DataFrame 'json' records Optional[List[str]] Array of record names specifying specific records to export. By default, all records are exported None fields Union[List[str], str] Single field name or array of field names specifying specific fields to pull. By default, all fields are exported None forms Union[List[str], str] Single form name or array of form names to export. If in the web UI, the form name has a space in it, replace the space with an underscore. By default, all forms are exported None events Optional[List[str]] An array of unique event names from which to export records Note: This only applies to longitudinal projects None raw_or_label Literal['raw', 'label', 'both'] Export the raw coded values or labels for the options of multiple choice fields, or both 'raw' raw_or_label_headers Literal['raw', 'label'] Export the column names of the instrument as their raw value or their labeled value 'raw' event_name Literal['label', 'unique'] Export the unique event name or the event label 'label' record_type Literal['flat', 'eav'] Database output structure type 'flat' export_survey_fields bool Specifies whether or not to export the survey identifier field (e.g., \"redcap_survey_identifier\") or survey timestamp fields (e.g., form_name+\"_timestamp\") when surveys are utilized in the project False export_data_access_groups bool Specifies whether or not to export the \"redcap_data_access_group\" field when data access groups are utilized in the project Note: This flag is only viable if the user whose token is being used to make the API request is not in a data access group. If the user is in a group, then this flag will revert to its default value. False export_checkbox_labels bool Specify whether to export checkbox values as their label on export. False filter_logic Optional[str] Filter which records are returned using REDCap conditional syntax None date_begin Optional[datetime.datetime] Filter on records created after a date None date_end Optional[datetime.datetime] Filter on records created before a date None decimal_character Optional[Literal[',', '.']] Force all numbers into same decimal format None export_blank_for_gray_form_status Optional[bool] Whether or not to export blank values for instrument complete status fields that have a gray status icon None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, {'index_col': self.def_field} None Returns: Type Description Union[List[Dict[str, Any]], str, pd.DataFrame] Exported data Examples: >>> proj . export_records () [{ 'record_id' : '1' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '1' , 'upload_field' : 'test_upload.txt' , 'form_1_complete' : '2' }, { 'record_id' : '2' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '0' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '0' , 'upload_field' : 'myupload.txt' , 'form_1_complete' : '0' }] >>> proj . export_records ( filter_logic = \"[field_1] = 1\" ) [{ 'record_id' : '1' , 'redcap_event_name' : 'event_1_arm_1' , 'redcap_repeat_instrument' : '' , 'redcap_repeat_instance' : 1 , 'field_1' : '1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '1' , 'upload_field' : 'test_upload.txt' , 'form_1_complete' : '2' }] >>> proj . export_records ( ... format_type = \"csv\" , ... fields = [ \"field_1\" , \"checkbox_field\" ], ... raw_or_label = \"label\" ... ) 'record_id,redcap_event_name,redcap_repeat_instrument,redcap_repeat_instance,field_1,checkbox_field___1,checkbox_field___2 \\n 1,\"Event 1\",,1,Yes,Unchecked,Checked \\n 2,\"Event 1\",,1,No,Unchecked,Unchecked \\n ' >>> import pandas as pd >>> pd . set_option ( \"display.max_columns\" , 3 ) >>> proj . export_records ( format_type = \"df\" ) redcap_repeat_instrument ... form_1_complete record_id redcap_event_name ... 1 event_1_arm_1 NaN ... 2 2 event_1_arm_1 NaN ... 0 ... Source code in redcap/methods/records.py def export_records ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , records : Optional [ List [ str ]] = None , fields : Optional [ Union [ List [ str ], str ]] = None , forms : Optional [ Union [ List [ str ], str ]] = None , events : Optional [ List [ str ]] = None , raw_or_label : Literal [ \"raw\" , \"label\" , \"both\" ] = \"raw\" , raw_or_label_headers : Literal [ \"raw\" , \"label\" ] = \"raw\" , event_name : Literal [ \"label\" , \"unique\" ] = \"label\" , record_type : Literal [ \"flat\" , \"eav\" ] = \"flat\" , export_survey_fields : bool = False , export_data_access_groups : bool = False , export_checkbox_labels : bool = False , filter_logic : Optional [ str ] = None , date_begin : Optional [ datetime ] = None , date_end : Optional [ datetime ] = None , decimal_character : Optional [ Literal [ \",\" , \".\" ]] = None , export_blank_for_gray_form_status : Optional [ bool ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): # pylint: disable=line-too-long r \"\"\" Export data from the REDCap project. Args: format_type: Format of returned data. `'json'` returns json-decoded objects while `'csv'` and `'xml'` return other formats. `'df'` will attempt to return a `pandas.DataFrame` records: Array of record names specifying specific records to export. By default, all records are exported fields: Single field name or array of field names specifying specific fields to pull. By default, all fields are exported forms: Single form name or array of form names to export. If in the web UI, the form name has a space in it, replace the space with an underscore. By default, all forms are exported events: An array of unique event names from which to export records Note: This only applies to longitudinal projects raw_or_label: Export the raw coded values or labels for the options of multiple choice fields, or both raw_or_label_headers: Export the column names of the instrument as their raw value or their labeled value event_name: Export the unique event name or the event label record_type: Database output structure type export_survey_fields: Specifies whether or not to export the survey identifier field (e.g., \"redcap_survey_identifier\") or survey timestamp fields (e.g., form_name+\"_timestamp\") when surveys are utilized in the project export_data_access_groups: Specifies whether or not to export the `\"redcap_data_access_group\"` field when data access groups are utilized in the project Note: This flag is only viable if the user whose token is being used to make the API request is *not* in a data access group. If the user is in a group, then this flag will revert to its default value. export_checkbox_labels: Specify whether to export checkbox values as their label on export. filter_logic: Filter which records are returned using REDCap conditional syntax date_begin: Filter on records created after a date date_end: Filter on records created before a date decimal_character: Force all numbers into same decimal format export_blank_for_gray_form_status: Whether or not to export blank values for instrument complete status fields that have a gray status icon df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, `{'index_col': self.def_field}` Returns: Union[List[Dict[str, Any]], str, pd.DataFrame]: Exported data Examples: >>> proj.export_records() [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '1', 'upload_field': 'test_upload.txt', 'form_1_complete': '2'}, {'record_id': '2', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '0', 'checkbox_field___1': '0', 'checkbox_field___2': '0', 'upload_field': 'myupload.txt', 'form_1_complete': '0'}] >>> proj.export_records(filter_logic=\"[field_1] = 1\") [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'redcap_repeat_instrument': '', 'redcap_repeat_instance': 1, 'field_1': '1', 'checkbox_field___1': '0', 'checkbox_field___2': '1', 'upload_field': 'test_upload.txt', 'form_1_complete': '2'}] >>> proj.export_records( ... format_type=\"csv\", ... fields=[\"field_1\", \"checkbox_field\"], ... raw_or_label=\"label\" ... ) 'record_id,redcap_event_name,redcap_repeat_instrument,redcap_repeat_instance,field_1,checkbox_field___1,checkbox_field___2\\n1,\"Event 1\",,1,Yes,Unchecked,Checked\\n2,\"Event 1\",,1,No,Unchecked,Unchecked\\n' >>> import pandas as pd >>> pd.set_option(\"display.max_columns\", 3) >>> proj.export_records(format_type=\"df\") redcap_repeat_instrument ... form_1_complete record_id redcap_event_name ... 1 event_1_arm_1 NaN ... 2 2 event_1_arm_1 NaN ... 0 ... \"\"\" # pylint: enable=line-too-long payload : Dict [ str , Any ] = self . _initialize_payload ( content = \"record\" , format_type = format_type , record_type = record_type ) if isinstance ( fields , str ): fields = [ fields ] if isinstance ( forms , str ): forms = [ forms ] fields = self . _backfill_fields ( fields , forms ) keys_to_add = ( records , fields , forms , events , raw_or_label , raw_or_label_headers , event_name , export_survey_fields , export_data_access_groups , export_checkbox_labels , filter_logic , decimal_character , export_blank_for_gray_form_status , ) str_keys = ( \"records\" , \"fields\" , \"forms\" , \"events\" , \"rawOrLabel\" , \"rawOrLabelHeaders\" , \"eventName\" , \"exportSurveyFields\" , \"exportDataAccessGroups\" , \"exportCheckboxLabel\" , \"filterLogic\" , \"decimalCharacter\" , \"exportBlankForGrayFormStatus\" , ) for key , data in zip ( str_keys , keys_to_add ): if data : if key in ( \"fields\" , \"records\" , \"forms\" , \"events\" ): data = cast ( List [ str ], data ) for i , value in enumerate ( data ): payload [ f \" { key } [ { i } ]\" ] = value else : payload [ key ] = data if date_begin : payload [ \"dateRangeBegin\" ] = date_begin . strftime ( \"%Y-%m- %d %H:%M:%S\" ) if date_end : payload [ \"dateRangeEnd\" ] = date_end . strftime ( \"%Y-%m- %d %H:%M:%S\" ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"record\" , format_type = format_type , df_kwargs = df_kwargs , record_type = record_type , )","title":"export_records()"},{"location":"api_reference/records/#redcap.methods.records.Records.generate_next_record_name","text":"Get the next record name Returns: Type Description str The next record name for a project with auto-numbering records enabled Examples: >>> proj . generate_next_record_name () '3' Source code in redcap/methods/records.py def generate_next_record_name ( self ) -> str : \"\"\" Get the next record name Returns: The next record name for a project with auto-numbering records enabled Examples: >>> proj.generate_next_record_name() '3' \"\"\" # Force the csv format here since if the project uses data access groups # or just non-standard record names then the result will not be JSON-compliant payload = self . _initialize_payload ( content = \"generateNextRecordName\" , format_type = \"csv\" ) return cast ( str , self . _call_api ( payload , return_type = \"str\" ))","title":"generate_next_record_name()"},{"location":"api_reference/records/#redcap.methods.records.Records.import_records","text":"Import data into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] Note: If you pass a df, csv, or xml string, you should use the import_format parameter appropriately. Note: Keys of the dictionaries should be subset of project's, fields, but this isn't a requirement. If you provide keys that aren't defined fields, the returned response will contain an 'error' key. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' return_content Literal['count', 'ids', 'auto_ids', 'nothing'] By default, the response contains a 'count' key with the number of records just imported. By specifying 'ids', a list of ids imported will be returned. 'nothing' will only return the HTTP status code and no message. 'count' overwrite Literal['normal', 'overwrite'] 'overwrite' will erase values previously stored in the database if not specified in the to_import dictionaries. 'normal' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' date_format Literal['YMD', 'DMY', 'MDY'] Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. 'YMD' force_auto_number bool Enables automatic assignment of record IDs of imported records by REDCap. If this is set to true, and auto-numbering for records is enabled for the project, auto-numbering of imported records will be enabled. False Exceptions: Type Description RedcapError Bad request made, double check field names and other inputs Returns: Type Description Union[Dict, str] response from REDCap API, json-decoded if return_format == 'json' Examples: >>> new_record = [{ \"record_id\" : 3 , \"redcap_repeat_instance\" : 1 , \"field_1\" : 1 }] >>> proj . import_records ( new_record ) { 'count' : 1 } Source code in redcap/methods/records.py def import_records ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , return_content : Literal [ \"count\" , \"ids\" , \"auto_ids\" , \"nothing\" ] = \"count\" , overwrite : Literal [ \"normal\" , \"overwrite\" ] = \"normal\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , date_format : Literal [ \"YMD\" , \"DMY\" , \"MDY\" ] = \"YMD\" , force_auto_number : bool = False , ): \"\"\" Import data into the REDCap Project Args: to_import: Note: If you pass a df, csv, or xml string, you should use the `import_format` parameter appropriately. Note: Keys of the dictionaries should be subset of project's, fields, but this isn't a requirement. If you provide keys that aren't defined fields, the returned response will contain an `'error'` key. return_format_type: Response format. By default, response will be json-decoded. return_content: By default, the response contains a 'count' key with the number of records just imported. By specifying 'ids', a list of ids imported will be returned. 'nothing' will only return the HTTP status code and no message. overwrite: `'overwrite'` will erase values previously stored in the database if not specified in the to_import dictionaries. import_format: Format of incoming data. By default, to_import will be json-encoded date_format: Describes the formatting of dates. By default, date strings are formatted as 'YYYY-MM-DD' corresponding to 'YMD'. If date strings are formatted as 'MM/DD/YYYY' set this parameter as 'MDY' and if formatted as 'DD/MM/YYYY' set as 'DMY'. No other formattings are allowed. force_auto_number: Enables automatic assignment of record IDs of imported records by REDCap. If this is set to true, and auto-numbering for records is enabled for the project, auto-numbering of imported records will be enabled. Raises: RedcapError: Bad request made, double check field names and other inputs Returns: Union[Dict, str]: response from REDCap API, json-decoded if `return_format` == `'json'` Examples: >>> new_record = [{\"record_id\": 3, \"redcap_repeat_instance\": 1, \"field_1\": 1}] >>> proj.import_records(new_record) {'count': 1} \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"record\" , ) payload [ \"overwriteBehavior\" ] = overwrite payload [ \"returnContent\" ] = return_content payload [ \"dateFormat\" ] = date_format payload [ \"forceAutoNumber\" ] = force_auto_number return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" , import_records_format = return_content , ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_records()"},{"location":"api_reference/repeating/","text":"Repeating REDCap API methods for Project repeating instruments Repeating ( Base ) Responsible for all API methods under 'Repeating Instruments and Events' in the API Playground Source code in redcap/methods/repeating.py class Repeating ( Base ): \"\"\"Responsible for all API methods under 'Repeating Instruments and Events' in the API Playground \"\"\" def export_repeating_instruments_events ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's repeating instruments and events settings Args: format_type: Return the repeating instruments and events in native objects, csv or xml, `'df''` will return a `pandas.DataFrame` df_kwargs: Passed to pandas.read_csv to control construction of returned DataFrame Returns: Union[str, List[Dict[str, Any]], pd.DataFrame]: Repeating instruments and events for the project Examples: >>> proj.export_repeating_instruments_events() [{'event_name': 'event_1_arm_1', 'form_name': '', 'custom_form_label': ''}] \"\"\" payload = self . _initialize_payload ( content = \"repeatingFormsEvents\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"repeatingFormsEvents\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_repeating_instruments_events ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import repeating instrument and event settings into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: The number of repeated instruments activated Examples: >>> rep_instruments = proj.export_repeating_instruments_events(format_type=\"csv\") >>> proj.import_repeating_instruments_events(rep_instruments, import_format=\"csv\") 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"repeatingFormsEvents\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server export_repeating_instruments_events ( self , format_type = 'json' , df_kwargs = None ) Export the project's repeating instruments and events settings Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the repeating instruments and events in native objects, csv or xml, 'df'' will return a pandas.DataFrame 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame None Returns: Type Description Union[str, List[Dict[str, Any]], pd.DataFrame] Repeating instruments and events for the project Examples: >>> proj . export_repeating_instruments_events () [{ 'event_name' : 'event_1_arm_1' , 'form_name' : '' , 'custom_form_label' : '' }] Source code in redcap/methods/repeating.py def export_repeating_instruments_events ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's repeating instruments and events settings Args: format_type: Return the repeating instruments and events in native objects, csv or xml, `'df''` will return a `pandas.DataFrame` df_kwargs: Passed to pandas.read_csv to control construction of returned DataFrame Returns: Union[str, List[Dict[str, Any]], pd.DataFrame]: Repeating instruments and events for the project Examples: >>> proj.export_repeating_instruments_events() [{'event_name': 'event_1_arm_1', 'form_name': '', 'custom_form_label': ''}] \"\"\" payload = self . _initialize_payload ( content = \"repeatingFormsEvents\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"repeatingFormsEvents\" , format_type = format_type , df_kwargs = df_kwargs , ) import_repeating_instruments_events ( self , to_import , return_format_type = 'json' , import_format = 'json' ) Import repeating instrument and event settings into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] The number of repeated instruments activated Examples: >>> rep_instruments = proj . export_repeating_instruments_events ( format_type = \"csv\" ) >>> proj . import_repeating_instruments_events ( rep_instruments , import_format = \"csv\" ) 1 Source code in redcap/methods/repeating.py def import_repeating_instruments_events ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import repeating instrument and event settings into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: The number of repeated instruments activated Examples: >>> rep_instruments = proj.export_repeating_instruments_events(format_type=\"csv\") >>> proj.import_repeating_instruments_events(rep_instruments, import_format=\"csv\") 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"repeatingFormsEvents\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"Repeating"},{"location":"api_reference/repeating/#repeating","text":"REDCap API methods for Project repeating instruments","title":"Repeating"},{"location":"api_reference/repeating/#redcap.methods.repeating.Repeating","text":"Responsible for all API methods under 'Repeating Instruments and Events' in the API Playground Source code in redcap/methods/repeating.py class Repeating ( Base ): \"\"\"Responsible for all API methods under 'Repeating Instruments and Events' in the API Playground \"\"\" def export_repeating_instruments_events ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's repeating instruments and events settings Args: format_type: Return the repeating instruments and events in native objects, csv or xml, `'df''` will return a `pandas.DataFrame` df_kwargs: Passed to pandas.read_csv to control construction of returned DataFrame Returns: Union[str, List[Dict[str, Any]], pd.DataFrame]: Repeating instruments and events for the project Examples: >>> proj.export_repeating_instruments_events() [{'event_name': 'event_1_arm_1', 'form_name': '', 'custom_form_label': ''}] \"\"\" payload = self . _initialize_payload ( content = \"repeatingFormsEvents\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"repeatingFormsEvents\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_repeating_instruments_events ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import repeating instrument and event settings into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: The number of repeated instruments activated Examples: >>> rep_instruments = proj.export_repeating_instruments_events(format_type=\"csv\") >>> proj.import_repeating_instruments_events(rep_instruments, import_format=\"csv\") 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"repeatingFormsEvents\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"Repeating"},{"location":"api_reference/repeating/#redcap.methods.repeating.Repeating.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/repeating/#redcap.methods.repeating.Repeating.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/repeating/#redcap.methods.repeating.Repeating.forms","text":"Project form names","title":"forms"},{"location":"api_reference/repeating/#redcap.methods.repeating.Repeating.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/repeating/#redcap.methods.repeating.Repeating.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/repeating/#redcap.methods.repeating.Repeating.token","text":"API token to a project","title":"token"},{"location":"api_reference/repeating/#redcap.methods.repeating.Repeating.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/repeating/#redcap.methods.repeating.Repeating.export_repeating_instruments_events","text":"Export the project's repeating instruments and events settings Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Return the repeating instruments and events in native objects, csv or xml, 'df'' will return a pandas.DataFrame 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame None Returns: Type Description Union[str, List[Dict[str, Any]], pd.DataFrame] Repeating instruments and events for the project Examples: >>> proj . export_repeating_instruments_events () [{ 'event_name' : 'event_1_arm_1' , 'form_name' : '' , 'custom_form_label' : '' }] Source code in redcap/methods/repeating.py def export_repeating_instruments_events ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the project's repeating instruments and events settings Args: format_type: Return the repeating instruments and events in native objects, csv or xml, `'df''` will return a `pandas.DataFrame` df_kwargs: Passed to pandas.read_csv to control construction of returned DataFrame Returns: Union[str, List[Dict[str, Any]], pd.DataFrame]: Repeating instruments and events for the project Examples: >>> proj.export_repeating_instruments_events() [{'event_name': 'event_1_arm_1', 'form_name': '', 'custom_form_label': ''}] \"\"\" payload = self . _initialize_payload ( content = \"repeatingFormsEvents\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"repeatingFormsEvents\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_repeating_instruments_events()"},{"location":"api_reference/repeating/#redcap.methods.repeating.Repeating.import_repeating_instruments_events","text":"Import repeating instrument and event settings into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] The number of repeated instruments activated Examples: >>> rep_instruments = proj . export_repeating_instruments_events ( format_type = \"csv\" ) >>> proj . import_repeating_instruments_events ( rep_instruments , import_format = \"csv\" ) 1 Source code in redcap/methods/repeating.py def import_repeating_instruments_events ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import repeating instrument and event settings into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: The number of repeated instruments activated Examples: >>> rep_instruments = proj.export_repeating_instruments_events(format_type=\"csv\") >>> proj.import_repeating_instruments_events(rep_instruments, import_format=\"csv\") 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"repeatingFormsEvents\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_repeating_instruments_events()"},{"location":"api_reference/reports/","text":"Reports REDCap API methods for Project reports Reports ( Base ) Responsible for all API methods under 'Reports' in the API Playground Source code in redcap/methods/reports.py class Reports ( Base ): \"\"\"Responsible for all API methods under 'Reports' in the API Playground\"\"\" def export_report ( self , report_id : str , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , raw_or_label : Literal [ \"raw\" , \"label\" ] = \"raw\" , raw_or_label_headers : Literal [ \"raw\" , \"label\" ] = \"raw\" , export_checkbox_labels : bool = False , csv_delimiter : Literal [ \",\" , \"tab\" , \";\" , \"|\" , \"^\" ] = \",\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export a report of the Project Args: report_id: The report ID number provided next to the report name on the report list page format_type: Format of returned data. `'json'` returns json-decoded objects while `'csv'` and `'xml'` return strings. `'df'` will attempt to return a `pandas.DataFrame`. raw_or_label: Export the raw coded values or labels for the options of multiple choice fields raw_or_label_headers: For the CSV headers, export the variable/field names (raw) or the field labels (label) export_checkbox_labels: Specifies the format of checkbox field values specifically when exporting the data as labels (i.e. when `rawOrLabel=label`). When exporting labels, by default (without providing the exportCheckboxLabel flag or if exportCheckboxLabel=false), all checkboxes will either have a value 'Checked' if they are checked or 'Unchecked' if not checked. But if exportCheckboxLabel is set to true, it will instead export the checkbox value as the checkbox option's label (e.g., 'Choice 1') if checked or it will be blank/empty (no value) if not checked csv_delimiter: For the csv format, choose how the csv delimiter. Raises: ValueError: Unsupported format specified Returns: Union[List[Dict[str, Any]], str, pd.DataFrame]: Data from the report ordered by the record (primary key of project) and then by event id Examples: >>> proj.export_report(report_id=\"4292\") # doctest: +SKIP [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'checkbox_field___1': '0', 'checkbox_field___2': '1'}] \"\"\" payload = self . _initialize_payload ( content = \"report\" , format_type = format_type ) keys_to_add = ( report_id , raw_or_label , raw_or_label_headers , export_checkbox_labels , csv_delimiter , ) str_keys = ( \"report_id\" , \"rawOrLabel\" , \"rawOrLabelHeaders\" , \"exportCheckboxLabel\" , \"csvDelimiter\" , ) for key , data in zip ( str_keys , keys_to_add ): data = cast ( str , data ) if data : payload [ key ] = data return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"report\" , format_type = format_type , df_kwargs = df_kwargs , ) def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server export_report ( self , report_id , format_type = 'json' , raw_or_label = 'raw' , raw_or_label_headers = 'raw' , export_checkbox_labels = False , csv_delimiter = ',' , df_kwargs = None ) Export a report of the Project Parameters: Name Type Description Default report_id str The report ID number provided next to the report name on the report list page required format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data. 'json' returns json-decoded objects while 'csv' and 'xml' return strings. 'df' will attempt to return a pandas.DataFrame . 'json' raw_or_label Literal['raw', 'label'] Export the raw coded values or labels for the options of multiple choice fields 'raw' raw_or_label_headers Literal['raw', 'label'] For the CSV headers, export the variable/field names (raw) or the field labels (label) 'raw' export_checkbox_labels bool Specifies the format of checkbox field values specifically when exporting the data as labels (i.e. when rawOrLabel=label ). When exporting labels, by default (without providing the exportCheckboxLabel flag or if exportCheckboxLabel=false), all checkboxes will either have a value 'Checked' if they are checked or 'Unchecked' if not checked. But if exportCheckboxLabel is set to true, it will instead export the checkbox value as the checkbox option's label (e.g., 'Choice 1') if checked or it will be blank/empty (no value) if not checked False csv_delimiter Literal[',', 'tab', ';', '|', '^'] For the csv format, choose how the csv delimiter. ',' Exceptions: Type Description ValueError Unsupported format specified Returns: Type Description Union[List[Dict[str, Any]], str, pd.DataFrame] Data from the report ordered by the record (primary key of project) and then by event id Examples: >>> proj . export_report ( report_id = \"4292\" ) [{ 'record_id' : '1' , 'redcap_event_name' : 'event_1_arm_1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '1' }] Source code in redcap/methods/reports.py def export_report ( self , report_id : str , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , raw_or_label : Literal [ \"raw\" , \"label\" ] = \"raw\" , raw_or_label_headers : Literal [ \"raw\" , \"label\" ] = \"raw\" , export_checkbox_labels : bool = False , csv_delimiter : Literal [ \",\" , \"tab\" , \";\" , \"|\" , \"^\" ] = \",\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export a report of the Project Args: report_id: The report ID number provided next to the report name on the report list page format_type: Format of returned data. `'json'` returns json-decoded objects while `'csv'` and `'xml'` return strings. `'df'` will attempt to return a `pandas.DataFrame`. raw_or_label: Export the raw coded values or labels for the options of multiple choice fields raw_or_label_headers: For the CSV headers, export the variable/field names (raw) or the field labels (label) export_checkbox_labels: Specifies the format of checkbox field values specifically when exporting the data as labels (i.e. when `rawOrLabel=label`). When exporting labels, by default (without providing the exportCheckboxLabel flag or if exportCheckboxLabel=false), all checkboxes will either have a value 'Checked' if they are checked or 'Unchecked' if not checked. But if exportCheckboxLabel is set to true, it will instead export the checkbox value as the checkbox option's label (e.g., 'Choice 1') if checked or it will be blank/empty (no value) if not checked csv_delimiter: For the csv format, choose how the csv delimiter. Raises: ValueError: Unsupported format specified Returns: Union[List[Dict[str, Any]], str, pd.DataFrame]: Data from the report ordered by the record (primary key of project) and then by event id Examples: >>> proj.export_report(report_id=\"4292\") # doctest: +SKIP [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'checkbox_field___1': '0', 'checkbox_field___2': '1'}] \"\"\" payload = self . _initialize_payload ( content = \"report\" , format_type = format_type ) keys_to_add = ( report_id , raw_or_label , raw_or_label_headers , export_checkbox_labels , csv_delimiter , ) str_keys = ( \"report_id\" , \"rawOrLabel\" , \"rawOrLabelHeaders\" , \"exportCheckboxLabel\" , \"csvDelimiter\" , ) for key , data in zip ( str_keys , keys_to_add ): data = cast ( str , data ) if data : payload [ key ] = data return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"report\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"Reports"},{"location":"api_reference/reports/#reports","text":"REDCap API methods for Project reports","title":"Reports"},{"location":"api_reference/reports/#redcap.methods.reports.Reports","text":"Responsible for all API methods under 'Reports' in the API Playground Source code in redcap/methods/reports.py class Reports ( Base ): \"\"\"Responsible for all API methods under 'Reports' in the API Playground\"\"\" def export_report ( self , report_id : str , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , raw_or_label : Literal [ \"raw\" , \"label\" ] = \"raw\" , raw_or_label_headers : Literal [ \"raw\" , \"label\" ] = \"raw\" , export_checkbox_labels : bool = False , csv_delimiter : Literal [ \",\" , \"tab\" , \";\" , \"|\" , \"^\" ] = \",\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export a report of the Project Args: report_id: The report ID number provided next to the report name on the report list page format_type: Format of returned data. `'json'` returns json-decoded objects while `'csv'` and `'xml'` return strings. `'df'` will attempt to return a `pandas.DataFrame`. raw_or_label: Export the raw coded values or labels for the options of multiple choice fields raw_or_label_headers: For the CSV headers, export the variable/field names (raw) or the field labels (label) export_checkbox_labels: Specifies the format of checkbox field values specifically when exporting the data as labels (i.e. when `rawOrLabel=label`). When exporting labels, by default (without providing the exportCheckboxLabel flag or if exportCheckboxLabel=false), all checkboxes will either have a value 'Checked' if they are checked or 'Unchecked' if not checked. But if exportCheckboxLabel is set to true, it will instead export the checkbox value as the checkbox option's label (e.g., 'Choice 1') if checked or it will be blank/empty (no value) if not checked csv_delimiter: For the csv format, choose how the csv delimiter. Raises: ValueError: Unsupported format specified Returns: Union[List[Dict[str, Any]], str, pd.DataFrame]: Data from the report ordered by the record (primary key of project) and then by event id Examples: >>> proj.export_report(report_id=\"4292\") # doctest: +SKIP [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'checkbox_field___1': '0', 'checkbox_field___2': '1'}] \"\"\" payload = self . _initialize_payload ( content = \"report\" , format_type = format_type ) keys_to_add = ( report_id , raw_or_label , raw_or_label_headers , export_checkbox_labels , csv_delimiter , ) str_keys = ( \"report_id\" , \"rawOrLabel\" , \"rawOrLabelHeaders\" , \"exportCheckboxLabel\" , \"csvDelimiter\" , ) for key , data in zip ( str_keys , keys_to_add ): data = cast ( str , data ) if data : payload [ key ] = data return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"report\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"Reports"},{"location":"api_reference/reports/#redcap.methods.reports.Reports.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/reports/#redcap.methods.reports.Reports.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/reports/#redcap.methods.reports.Reports.forms","text":"Project form names","title":"forms"},{"location":"api_reference/reports/#redcap.methods.reports.Reports.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/reports/#redcap.methods.reports.Reports.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/reports/#redcap.methods.reports.Reports.token","text":"API token to a project","title":"token"},{"location":"api_reference/reports/#redcap.methods.reports.Reports.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/reports/#redcap.methods.reports.Reports.export_report","text":"Export a report of the Project Parameters: Name Type Description Default report_id str The report ID number provided next to the report name on the report list page required format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data. 'json' returns json-decoded objects while 'csv' and 'xml' return strings. 'df' will attempt to return a pandas.DataFrame . 'json' raw_or_label Literal['raw', 'label'] Export the raw coded values or labels for the options of multiple choice fields 'raw' raw_or_label_headers Literal['raw', 'label'] For the CSV headers, export the variable/field names (raw) or the field labels (label) 'raw' export_checkbox_labels bool Specifies the format of checkbox field values specifically when exporting the data as labels (i.e. when rawOrLabel=label ). When exporting labels, by default (without providing the exportCheckboxLabel flag or if exportCheckboxLabel=false), all checkboxes will either have a value 'Checked' if they are checked or 'Unchecked' if not checked. But if exportCheckboxLabel is set to true, it will instead export the checkbox value as the checkbox option's label (e.g., 'Choice 1') if checked or it will be blank/empty (no value) if not checked False csv_delimiter Literal[',', 'tab', ';', '|', '^'] For the csv format, choose how the csv delimiter. ',' Exceptions: Type Description ValueError Unsupported format specified Returns: Type Description Union[List[Dict[str, Any]], str, pd.DataFrame] Data from the report ordered by the record (primary key of project) and then by event id Examples: >>> proj . export_report ( report_id = \"4292\" ) [{ 'record_id' : '1' , 'redcap_event_name' : 'event_1_arm_1' , 'checkbox_field___1' : '0' , 'checkbox_field___2' : '1' }] Source code in redcap/methods/reports.py def export_report ( self , report_id : str , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , raw_or_label : Literal [ \"raw\" , \"label\" ] = \"raw\" , raw_or_label_headers : Literal [ \"raw\" , \"label\" ] = \"raw\" , export_checkbox_labels : bool = False , csv_delimiter : Literal [ \",\" , \"tab\" , \";\" , \"|\" , \"^\" ] = \",\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export a report of the Project Args: report_id: The report ID number provided next to the report name on the report list page format_type: Format of returned data. `'json'` returns json-decoded objects while `'csv'` and `'xml'` return strings. `'df'` will attempt to return a `pandas.DataFrame`. raw_or_label: Export the raw coded values or labels for the options of multiple choice fields raw_or_label_headers: For the CSV headers, export the variable/field names (raw) or the field labels (label) export_checkbox_labels: Specifies the format of checkbox field values specifically when exporting the data as labels (i.e. when `rawOrLabel=label`). When exporting labels, by default (without providing the exportCheckboxLabel flag or if exportCheckboxLabel=false), all checkboxes will either have a value 'Checked' if they are checked or 'Unchecked' if not checked. But if exportCheckboxLabel is set to true, it will instead export the checkbox value as the checkbox option's label (e.g., 'Choice 1') if checked or it will be blank/empty (no value) if not checked csv_delimiter: For the csv format, choose how the csv delimiter. Raises: ValueError: Unsupported format specified Returns: Union[List[Dict[str, Any]], str, pd.DataFrame]: Data from the report ordered by the record (primary key of project) and then by event id Examples: >>> proj.export_report(report_id=\"4292\") # doctest: +SKIP [{'record_id': '1', 'redcap_event_name': 'event_1_arm_1', 'checkbox_field___1': '0', 'checkbox_field___2': '1'}] \"\"\" payload = self . _initialize_payload ( content = \"report\" , format_type = format_type ) keys_to_add = ( report_id , raw_or_label , raw_or_label_headers , export_checkbox_labels , csv_delimiter , ) str_keys = ( \"report_id\" , \"rawOrLabel\" , \"rawOrLabelHeaders\" , \"exportCheckboxLabel\" , \"csvDelimiter\" , ) for key , data in zip ( str_keys , keys_to_add ): data = cast ( str , data ) if data : payload [ key ] = data return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"report\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_report()"},{"location":"api_reference/surveys/","text":"Surveys REDCap API methods for Project surveys Surveys ( Base ) Responsible for all API methods under 'Surveys' in the API Playground Source code in redcap/methods/surveys.py class Surveys ( Base ): \"\"\"Responsible for all API methods under 'Surveys' in the API Playground\"\"\" def export_survey_link ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : \"\"\" Export one survey link Note: The passed instrument must be set up as a survey instrument. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: URL of survey link requested Examples: >>> proj.export_survey_link(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") 'https://redcapdemo.vumc.org/surveys/?s=...' \"\"\" payload = self . _initialize_payload ( content = \"surveyLink\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" )) def export_survey_queue_link ( self , record : str , ) -> str : \"\"\" Export one survey queue link Note: The passed instrument must be set up as a survey instrument. The survey queue must be enabled for the project. Args: record: Name of the record Returns: URL of survey queue link requested Examples: >>> proj.export_survey_queue_link(record=\"1\") 'https://redcapdemo.vumc.org/surveys/?sq=...' \"\"\" payload = self . _initialize_payload ( content = \"surveyQueueLink\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record return cast ( str , self . _call_api ( payload , return_type = \"str\" )) def export_survey_access_code ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : # pylint: disable=line-too-long \"\"\" Export a Survey Access Code for a Participant Note: The passed instrument must be set up as a survey instrument. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: A survey access code for a specified record and data collection instrument Examples: >>> proj.export_survey_access_code(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") '...' \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"surveyAccessCode\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" )) def export_survey_return_code ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : # pylint: disable=line-too-long \"\"\" Export a Survey Return Code for a Participant Note: The passed instrument must be set up as a survey instrument, which has return codes enabled. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: A survey return code for a specified record and data collection instrument Examples: >>> proj.export_survey_return_code(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") '...' \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"surveyReturnCode\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" )) def export_survey_participant_list ( self , instrument : str , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , event : Optional [ str ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the Survey Participant List Note: The passed instrument must be set up as a survey instrument. Args: instrument: Name of instrument as seen in the Data Dictionary (metadata). format_type: Format of returned data event: Unique event name, only used in longitudinal projects df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of survey participants, along with other useful metadata such as the record, response status, etc. Examples: >>> proj.export_survey_participant_list(instrument=\"form_1\", event=\"event_1_arm_1\") [{'email': '', ... 'survey_access_code': ...}, {'email': '', ... 'survey_access_code': ...}] \"\"\" payload = self . _initialize_payload ( content = \"participantList\" , format_type = format_type , ) payload [ \"instrument\" ] = instrument if event : payload [ \"event\" ] = event return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"participantList\" , format_type = format_type , df_kwargs = df_kwargs , ) def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server export_survey_access_code ( self , record , instrument , event = None , repeat_instance = 1 ) Export a Survey Access Code for a Participant !!! note The passed instrument must be set up as a survey instrument. Parameters: Name Type Description Default record str Name of the record required instrument str Name of instrument as seen in the Data Dictionary (metadata). required event Optional[str] Unique event name, only used in longitudinal projects None repeat_instance int only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. 1 Returns: Type Description str A survey access code for a specified record and data collection instrument Examples: >>> proj . export_survey_access_code ( record = \"1\" , instrument = \"form_1\" , event = \"event_1_arm_1\" ) '...' Source code in redcap/methods/surveys.py def export_survey_access_code ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : # pylint: disable=line-too-long \"\"\" Export a Survey Access Code for a Participant Note: The passed instrument must be set up as a survey instrument. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: A survey access code for a specified record and data collection instrument Examples: >>> proj.export_survey_access_code(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") '...' \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"surveyAccessCode\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" )) export_survey_link ( self , record , instrument , event = None , repeat_instance = 1 ) Export one survey link !!! note The passed instrument must be set up as a survey instrument. Parameters: Name Type Description Default record str Name of the record required instrument str Name of instrument as seen in the Data Dictionary (metadata). required event Optional[str] Unique event name, only used in longitudinal projects None repeat_instance int only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. 1 Returns: Type Description str URL of survey link requested Examples: >>> proj . export_survey_link ( record = \"1\" , instrument = \"form_1\" , event = \"event_1_arm_1\" ) 'https://redcapdemo.vumc.org/surveys/?s=...' Source code in redcap/methods/surveys.py def export_survey_link ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : \"\"\" Export one survey link Note: The passed instrument must be set up as a survey instrument. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: URL of survey link requested Examples: >>> proj.export_survey_link(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") 'https://redcapdemo.vumc.org/surveys/?s=...' \"\"\" payload = self . _initialize_payload ( content = \"surveyLink\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" )) export_survey_participant_list ( self , instrument , format_type = 'json' , event = None , df_kwargs = None ) Export the Survey Participant List !!! note The passed instrument must be set up as a survey instrument. Parameters: Name Type Description Default instrument str Name of instrument as seen in the Data Dictionary (metadata). required format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data 'json' event Optional[str] Unique event name, only used in longitudinal projects None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of survey participants, along with other useful metadata such as the record, response status, etc. Examples: >>> proj . export_survey_participant_list ( instrument = \"form_1\" , event = \"event_1_arm_1\" ) [{ 'email' : '' , ... 'survey_access_code' : ... }, { 'email' : '' , ... 'survey_access_code' : ... }] Source code in redcap/methods/surveys.py def export_survey_participant_list ( self , instrument : str , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , event : Optional [ str ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the Survey Participant List Note: The passed instrument must be set up as a survey instrument. Args: instrument: Name of instrument as seen in the Data Dictionary (metadata). format_type: Format of returned data event: Unique event name, only used in longitudinal projects df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of survey participants, along with other useful metadata such as the record, response status, etc. Examples: >>> proj.export_survey_participant_list(instrument=\"form_1\", event=\"event_1_arm_1\") [{'email': '', ... 'survey_access_code': ...}, {'email': '', ... 'survey_access_code': ...}] \"\"\" payload = self . _initialize_payload ( content = \"participantList\" , format_type = format_type , ) payload [ \"instrument\" ] = instrument if event : payload [ \"event\" ] = event return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"participantList\" , format_type = format_type , df_kwargs = df_kwargs , ) export_survey_queue_link ( self , record ) Export one survey queue link !!! note The passed instrument must be set up as a survey instrument. The survey queue must be enabled for the project. Parameters: Name Type Description Default record str Name of the record required Returns: Type Description str URL of survey queue link requested Examples: >>> proj . export_survey_queue_link ( record = \"1\" ) 'https://redcapdemo.vumc.org/surveys/?sq=...' Source code in redcap/methods/surveys.py def export_survey_queue_link ( self , record : str , ) -> str : \"\"\" Export one survey queue link Note: The passed instrument must be set up as a survey instrument. The survey queue must be enabled for the project. Args: record: Name of the record Returns: URL of survey queue link requested Examples: >>> proj.export_survey_queue_link(record=\"1\") 'https://redcapdemo.vumc.org/surveys/?sq=...' \"\"\" payload = self . _initialize_payload ( content = \"surveyQueueLink\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record return cast ( str , self . _call_api ( payload , return_type = \"str\" )) export_survey_return_code ( self , record , instrument , event = None , repeat_instance = 1 ) Export a Survey Return Code for a Participant !!! note The passed instrument must be set up as a survey instrument, which has return codes enabled. Parameters: Name Type Description Default record str Name of the record required instrument str Name of instrument as seen in the Data Dictionary (metadata). required event Optional[str] Unique event name, only used in longitudinal projects None repeat_instance int only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. 1 Returns: Type Description str A survey return code for a specified record and data collection instrument Examples: >>> proj . export_survey_return_code ( record = \"1\" , instrument = \"form_1\" , event = \"event_1_arm_1\" ) '...' Source code in redcap/methods/surveys.py def export_survey_return_code ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : # pylint: disable=line-too-long \"\"\" Export a Survey Return Code for a Participant Note: The passed instrument must be set up as a survey instrument, which has return codes enabled. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: A survey return code for a specified record and data collection instrument Examples: >>> proj.export_survey_return_code(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") '...' \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"surveyReturnCode\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" ))","title":"Surveys"},{"location":"api_reference/surveys/#surveys","text":"REDCap API methods for Project surveys","title":"Surveys"},{"location":"api_reference/surveys/#redcap.methods.surveys.Surveys","text":"Responsible for all API methods under 'Surveys' in the API Playground Source code in redcap/methods/surveys.py class Surveys ( Base ): \"\"\"Responsible for all API methods under 'Surveys' in the API Playground\"\"\" def export_survey_link ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : \"\"\" Export one survey link Note: The passed instrument must be set up as a survey instrument. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: URL of survey link requested Examples: >>> proj.export_survey_link(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") 'https://redcapdemo.vumc.org/surveys/?s=...' \"\"\" payload = self . _initialize_payload ( content = \"surveyLink\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" )) def export_survey_queue_link ( self , record : str , ) -> str : \"\"\" Export one survey queue link Note: The passed instrument must be set up as a survey instrument. The survey queue must be enabled for the project. Args: record: Name of the record Returns: URL of survey queue link requested Examples: >>> proj.export_survey_queue_link(record=\"1\") 'https://redcapdemo.vumc.org/surveys/?sq=...' \"\"\" payload = self . _initialize_payload ( content = \"surveyQueueLink\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record return cast ( str , self . _call_api ( payload , return_type = \"str\" )) def export_survey_access_code ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : # pylint: disable=line-too-long \"\"\" Export a Survey Access Code for a Participant Note: The passed instrument must be set up as a survey instrument. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: A survey access code for a specified record and data collection instrument Examples: >>> proj.export_survey_access_code(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") '...' \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"surveyAccessCode\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" )) def export_survey_return_code ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : # pylint: disable=line-too-long \"\"\" Export a Survey Return Code for a Participant Note: The passed instrument must be set up as a survey instrument, which has return codes enabled. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: A survey return code for a specified record and data collection instrument Examples: >>> proj.export_survey_return_code(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") '...' \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"surveyReturnCode\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" )) def export_survey_participant_list ( self , instrument : str , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , event : Optional [ str ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the Survey Participant List Note: The passed instrument must be set up as a survey instrument. Args: instrument: Name of instrument as seen in the Data Dictionary (metadata). format_type: Format of returned data event: Unique event name, only used in longitudinal projects df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of survey participants, along with other useful metadata such as the record, response status, etc. Examples: >>> proj.export_survey_participant_list(instrument=\"form_1\", event=\"event_1_arm_1\") [{'email': '', ... 'survey_access_code': ...}, {'email': '', ... 'survey_access_code': ...}] \"\"\" payload = self . _initialize_payload ( content = \"participantList\" , format_type = format_type , ) payload [ \"instrument\" ] = instrument if event : payload [ \"event\" ] = event return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"participantList\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"Surveys"},{"location":"api_reference/surveys/#redcap.methods.surveys.Surveys.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/surveys/#redcap.methods.surveys.Surveys.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/surveys/#redcap.methods.surveys.Surveys.forms","text":"Project form names","title":"forms"},{"location":"api_reference/surveys/#redcap.methods.surveys.Surveys.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/surveys/#redcap.methods.surveys.Surveys.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/surveys/#redcap.methods.surveys.Surveys.token","text":"API token to a project","title":"token"},{"location":"api_reference/surveys/#redcap.methods.surveys.Surveys.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/surveys/#redcap.methods.surveys.Surveys.export_survey_access_code","text":"Export a Survey Access Code for a Participant !!! note The passed instrument must be set up as a survey instrument. Parameters: Name Type Description Default record str Name of the record required instrument str Name of instrument as seen in the Data Dictionary (metadata). required event Optional[str] Unique event name, only used in longitudinal projects None repeat_instance int only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. 1 Returns: Type Description str A survey access code for a specified record and data collection instrument Examples: >>> proj . export_survey_access_code ( record = \"1\" , instrument = \"form_1\" , event = \"event_1_arm_1\" ) '...' Source code in redcap/methods/surveys.py def export_survey_access_code ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : # pylint: disable=line-too-long \"\"\" Export a Survey Access Code for a Participant Note: The passed instrument must be set up as a survey instrument. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: A survey access code for a specified record and data collection instrument Examples: >>> proj.export_survey_access_code(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") '...' \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"surveyAccessCode\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" ))","title":"export_survey_access_code()"},{"location":"api_reference/surveys/#redcap.methods.surveys.Surveys.export_survey_link","text":"Export one survey link !!! note The passed instrument must be set up as a survey instrument. Parameters: Name Type Description Default record str Name of the record required instrument str Name of instrument as seen in the Data Dictionary (metadata). required event Optional[str] Unique event name, only used in longitudinal projects None repeat_instance int only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. 1 Returns: Type Description str URL of survey link requested Examples: >>> proj . export_survey_link ( record = \"1\" , instrument = \"form_1\" , event = \"event_1_arm_1\" ) 'https://redcapdemo.vumc.org/surveys/?s=...' Source code in redcap/methods/surveys.py def export_survey_link ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : \"\"\" Export one survey link Note: The passed instrument must be set up as a survey instrument. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: URL of survey link requested Examples: >>> proj.export_survey_link(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") 'https://redcapdemo.vumc.org/surveys/?s=...' \"\"\" payload = self . _initialize_payload ( content = \"surveyLink\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" ))","title":"export_survey_link()"},{"location":"api_reference/surveys/#redcap.methods.surveys.Surveys.export_survey_participant_list","text":"Export the Survey Participant List !!! note The passed instrument must be set up as a survey instrument. Parameters: Name Type Description Default instrument str Name of instrument as seen in the Data Dictionary (metadata). required format_type Literal['json', 'csv', 'xml', 'df'] Format of returned data 'json' event Optional[str] Unique event name, only used in longitudinal projects None df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of survey participants, along with other useful metadata such as the record, response status, etc. Examples: >>> proj . export_survey_participant_list ( instrument = \"form_1\" , event = \"event_1_arm_1\" ) [{ 'email' : '' , ... 'survey_access_code' : ... }, { 'email' : '' , ... 'survey_access_code' : ... }] Source code in redcap/methods/surveys.py def export_survey_participant_list ( self , instrument : str , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , event : Optional [ str ] = None , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the Survey Participant List Note: The passed instrument must be set up as a survey instrument. Args: instrument: Name of instrument as seen in the Data Dictionary (metadata). format_type: Format of returned data event: Unique event name, only used in longitudinal projects df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of survey participants, along with other useful metadata such as the record, response status, etc. Examples: >>> proj.export_survey_participant_list(instrument=\"form_1\", event=\"event_1_arm_1\") [{'email': '', ... 'survey_access_code': ...}, {'email': '', ... 'survey_access_code': ...}] \"\"\" payload = self . _initialize_payload ( content = \"participantList\" , format_type = format_type , ) payload [ \"instrument\" ] = instrument if event : payload [ \"event\" ] = event return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"participantList\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_survey_participant_list()"},{"location":"api_reference/surveys/#redcap.methods.surveys.Surveys.export_survey_queue_link","text":"Export one survey queue link !!! note The passed instrument must be set up as a survey instrument. The survey queue must be enabled for the project. Parameters: Name Type Description Default record str Name of the record required Returns: Type Description str URL of survey queue link requested Examples: >>> proj . export_survey_queue_link ( record = \"1\" ) 'https://redcapdemo.vumc.org/surveys/?sq=...' Source code in redcap/methods/surveys.py def export_survey_queue_link ( self , record : str , ) -> str : \"\"\" Export one survey queue link Note: The passed instrument must be set up as a survey instrument. The survey queue must be enabled for the project. Args: record: Name of the record Returns: URL of survey queue link requested Examples: >>> proj.export_survey_queue_link(record=\"1\") 'https://redcapdemo.vumc.org/surveys/?sq=...' \"\"\" payload = self . _initialize_payload ( content = \"surveyQueueLink\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record return cast ( str , self . _call_api ( payload , return_type = \"str\" ))","title":"export_survey_queue_link()"},{"location":"api_reference/surveys/#redcap.methods.surveys.Surveys.export_survey_return_code","text":"Export a Survey Return Code for a Participant !!! note The passed instrument must be set up as a survey instrument, which has return codes enabled. Parameters: Name Type Description Default record str Name of the record required instrument str Name of instrument as seen in the Data Dictionary (metadata). required event Optional[str] Unique event name, only used in longitudinal projects None repeat_instance int only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. 1 Returns: Type Description str A survey return code for a specified record and data collection instrument Examples: >>> proj . export_survey_return_code ( record = \"1\" , instrument = \"form_1\" , event = \"event_1_arm_1\" ) '...' Source code in redcap/methods/surveys.py def export_survey_return_code ( self , record : str , instrument : str , event : Optional [ str ] = None , repeat_instance : int = 1 , ) -> str : # pylint: disable=line-too-long \"\"\" Export a Survey Return Code for a Participant Note: The passed instrument must be set up as a survey instrument, which has return codes enabled. Args: record: Name of the record instrument: Name of instrument as seen in the Data Dictionary (metadata). event: Unique event name, only used in longitudinal projects repeat_instance: only for projects with repeating instruments/events) The repeat instance number of the repeating event (if longitudinal) or the repeating instrument (if classic or longitudinal). Default value is '1'. Returns: A survey return code for a specified record and data collection instrument Examples: >>> proj.export_survey_return_code(record=\"1\", instrument=\"form_1\", event=\"event_1_arm_1\") '...' \"\"\" # pylint: enable=line-too-long payload = self . _initialize_payload ( content = \"surveyReturnCode\" , # Hard-coded due to the nature of the response return_format_type = \"csv\" , ) payload [ \"record\" ] = record payload [ \"instrument\" ] = instrument payload [ \"repeat_instance\" ] = repeat_instance if event : payload [ \"event\" ] = event return cast ( str , self . _call_api ( payload , return_type = \"str\" ))","title":"export_survey_return_code()"},{"location":"api_reference/user_roles/","text":"User Roles REDCap API methods for Project user roles UserRoles ( Base ) Responsible for all API methods under 'Users Roles' in the API Playground Source code in redcap/methods/user_roles.py class UserRoles ( Base ): \"\"\"Responsible for all API methods under 'Users Roles' in the API Playground\"\"\" def export_user_roles ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the user roles of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of user roles with assigned user rights Examples: >>> proj.export_user_roles() [{'unique_role_name': ..., 'role_label': 'Test role', 'design': '0', 'alerts': '0', 'user_rights': '0', 'data_access_groups': '0', 'reports': '0', 'stats_and_charts': '0', 'manage_survey_participants': '0', 'calendar': '0', 'data_import_tool': '0', 'data_comparison_tool': '0', 'logging': '0', 'email_logging': '0', 'file_repository': '0', 'data_quality_create': '0', 'data_quality_execute': '0', 'api_export': '0', 'api_import': '0', 'api_modules': '0', 'mobile_app': '0', 'mobile_app_download_data': '0', 'record_create': '0', 'record_rename': '0', 'record_delete': '0', 'lock_records_customization': '0', 'lock_records': '0', ..., 'forms': {'form_1': 2}, 'forms_export': {'form_1': 0}}] \"\"\" payload = self . _initialize_payload ( content = \"userRole\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userRole\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_user_roles ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import user roles into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of user roles added or updated Examples: >>> roles = proj.export_user_roles() >>> proj.import_user_roles(roles) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userRole\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def delete_user_roles ( self , roles : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete user roles from the project. Args: roles: List of user roles to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of user roles deleted Examples: Create a new user role >>> new_role = [{\"role_label\": \"New Role\"}] >>> proj.import_user_roles(new_role) 1 We don't know what the 'unique_role_name' is for the newly created role, so we have to look it up by 'role_label' >>> roles = proj.export_user_roles() >>> new_role_id = [ ... role for role in roles ... if role[\"role_label\"] == \"New Role\" ... ][0][\"unique_role_name\"] Delete the role >>> proj.delete_user_roles([new_role_id]) 1 \"\"\" payload = self . _initialize_payload ( content = \"userRole\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of user roles into dict, and append to payload roles_dict = { f \"roles[ { idx } ]\" : role for idx , role in enumerate ( roles )} payload . update ( roles_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def export_user_role_assignment ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the User-Role assignments of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of user-role assignments Examples: >>> proj.export_user_role_assignment() [{'username': ..., 'unique_role_name': '', 'data_access_group': ''}] \"\"\" payload = self . _initialize_payload ( content = \"userRoleMapping\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userRoleMapping\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_user_role_assignment ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import User-Role assignments into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of user-role assignments added or updated Examples: >>> user_role_assignments = proj.export_user_role_assignment() >>> proj.import_user_role_assignment(user_role_assignments) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userRoleMapping\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server delete_user_roles ( self , roles , return_format_type = 'json' ) Delete user roles from the project. Parameters: Name Type Description Default roles List[str] List of user roles to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of user roles deleted Examples: Create a new user role >>> new_role = [{ \"role_label\" : \"New Role\" }] >>> proj . import_user_roles ( new_role ) 1 We don't know what the 'unique_role_name' is for the newly created role, so we have to look it up by 'role_label' >>> roles = proj . export_user_roles () >>> new_role_id = [ ... role for role in roles ... if role [ \"role_label\" ] == \"New Role\" ... ][ 0 ][ \"unique_role_name\" ] Delete the role >>> proj . delete_user_roles ([ new_role_id ]) 1 Source code in redcap/methods/user_roles.py def delete_user_roles ( self , roles : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete user roles from the project. Args: roles: List of user roles to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of user roles deleted Examples: Create a new user role >>> new_role = [{\"role_label\": \"New Role\"}] >>> proj.import_user_roles(new_role) 1 We don't know what the 'unique_role_name' is for the newly created role, so we have to look it up by 'role_label' >>> roles = proj.export_user_roles() >>> new_role_id = [ ... role for role in roles ... if role[\"role_label\"] == \"New Role\" ... ][0][\"unique_role_name\"] Delete the role >>> proj.delete_user_roles([new_role_id]) 1 \"\"\" payload = self . _initialize_payload ( content = \"userRole\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of user roles into dict, and append to payload roles_dict = { f \"roles[ { idx } ]\" : role for idx , role in enumerate ( roles )} payload . update ( roles_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response export_user_role_assignment ( self , format_type = 'json' , df_kwargs = None ) Export the User-Role assignments of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of user-role assignments Examples: >>> proj . export_user_role_assignment () [{ 'username' : ... , 'unique_role_name' : '' , 'data_access_group' : '' }] Source code in redcap/methods/user_roles.py def export_user_role_assignment ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the User-Role assignments of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of user-role assignments Examples: >>> proj.export_user_role_assignment() [{'username': ..., 'unique_role_name': '', 'data_access_group': ''}] \"\"\" payload = self . _initialize_payload ( content = \"userRoleMapping\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userRoleMapping\" , format_type = format_type , df_kwargs = df_kwargs , ) export_user_roles ( self , format_type = 'json' , df_kwargs = None ) Export the user roles of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of user roles with assigned user rights Examples: >>> proj . export_user_roles () [{ 'unique_role_name' : ... , 'role_label' : 'Test role' , 'design' : '0' , 'alerts' : '0' , 'user_rights' : '0' , 'data_access_groups' : '0' , 'reports' : '0' , 'stats_and_charts' : '0' , 'manage_survey_participants' : '0' , 'calendar' : '0' , 'data_import_tool' : '0' , 'data_comparison_tool' : '0' , 'logging' : '0' , 'email_logging' : '0' , 'file_repository' : '0' , 'data_quality_create' : '0' , 'data_quality_execute' : '0' , 'api_export' : '0' , 'api_import' : '0' , 'api_modules' : '0' , 'mobile_app' : '0' , 'mobile_app_download_data' : '0' , 'record_create' : '0' , 'record_rename' : '0' , 'record_delete' : '0' , 'lock_records_customization' : '0' , 'lock_records' : '0' , ... , 'forms' : { 'form_1' : 2 }, 'forms_export' : { 'form_1' : 0 }}] Source code in redcap/methods/user_roles.py def export_user_roles ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the user roles of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of user roles with assigned user rights Examples: >>> proj.export_user_roles() [{'unique_role_name': ..., 'role_label': 'Test role', 'design': '0', 'alerts': '0', 'user_rights': '0', 'data_access_groups': '0', 'reports': '0', 'stats_and_charts': '0', 'manage_survey_participants': '0', 'calendar': '0', 'data_import_tool': '0', 'data_comparison_tool': '0', 'logging': '0', 'email_logging': '0', 'file_repository': '0', 'data_quality_create': '0', 'data_quality_execute': '0', 'api_export': '0', 'api_import': '0', 'api_modules': '0', 'mobile_app': '0', 'mobile_app_download_data': '0', 'record_create': '0', 'record_rename': '0', 'record_delete': '0', 'lock_records_customization': '0', 'lock_records': '0', ..., 'forms': {'form_1': 2}, 'forms_export': {'form_1': 0}}] \"\"\" payload = self . _initialize_payload ( content = \"userRole\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userRole\" , format_type = format_type , df_kwargs = df_kwargs , ) import_user_role_assignment ( self , to_import , return_format_type = 'json' , import_format = 'json' ) Import User-Role assignments into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of user-role assignments added or updated Examples: >>> user_role_assignments = proj . export_user_role_assignment () >>> proj . import_user_role_assignment ( user_role_assignments ) 1 Source code in redcap/methods/user_roles.py def import_user_role_assignment ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import User-Role assignments into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of user-role assignments added or updated Examples: >>> user_role_assignments = proj.export_user_role_assignment() >>> proj.import_user_role_assignment(user_role_assignments) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userRoleMapping\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response import_user_roles ( self , to_import , return_format_type = 'json' , import_format = 'json' ) Import user roles into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of user roles added or updated Examples: >>> roles = proj . export_user_roles () >>> proj . import_user_roles ( roles ) 1 Source code in redcap/methods/user_roles.py def import_user_roles ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import user roles into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of user roles added or updated Examples: >>> roles = proj.export_user_roles() >>> proj.import_user_roles(roles) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userRole\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"User Roles"},{"location":"api_reference/user_roles/#user-roles","text":"REDCap API methods for Project user roles","title":"User Roles"},{"location":"api_reference/user_roles/#redcap.methods.user_roles.UserRoles","text":"Responsible for all API methods under 'Users Roles' in the API Playground Source code in redcap/methods/user_roles.py class UserRoles ( Base ): \"\"\"Responsible for all API methods under 'Users Roles' in the API Playground\"\"\" def export_user_roles ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the user roles of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of user roles with assigned user rights Examples: >>> proj.export_user_roles() [{'unique_role_name': ..., 'role_label': 'Test role', 'design': '0', 'alerts': '0', 'user_rights': '0', 'data_access_groups': '0', 'reports': '0', 'stats_and_charts': '0', 'manage_survey_participants': '0', 'calendar': '0', 'data_import_tool': '0', 'data_comparison_tool': '0', 'logging': '0', 'email_logging': '0', 'file_repository': '0', 'data_quality_create': '0', 'data_quality_execute': '0', 'api_export': '0', 'api_import': '0', 'api_modules': '0', 'mobile_app': '0', 'mobile_app_download_data': '0', 'record_create': '0', 'record_rename': '0', 'record_delete': '0', 'lock_records_customization': '0', 'lock_records': '0', ..., 'forms': {'form_1': 2}, 'forms_export': {'form_1': 0}}] \"\"\" payload = self . _initialize_payload ( content = \"userRole\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userRole\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_user_roles ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import user roles into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of user roles added or updated Examples: >>> roles = proj.export_user_roles() >>> proj.import_user_roles(roles) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userRole\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def delete_user_roles ( self , roles : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete user roles from the project. Args: roles: List of user roles to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of user roles deleted Examples: Create a new user role >>> new_role = [{\"role_label\": \"New Role\"}] >>> proj.import_user_roles(new_role) 1 We don't know what the 'unique_role_name' is for the newly created role, so we have to look it up by 'role_label' >>> roles = proj.export_user_roles() >>> new_role_id = [ ... role for role in roles ... if role[\"role_label\"] == \"New Role\" ... ][0][\"unique_role_name\"] Delete the role >>> proj.delete_user_roles([new_role_id]) 1 \"\"\" payload = self . _initialize_payload ( content = \"userRole\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of user roles into dict, and append to payload roles_dict = { f \"roles[ { idx } ]\" : role for idx , role in enumerate ( roles )} payload . update ( roles_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def export_user_role_assignment ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the User-Role assignments of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of user-role assignments Examples: >>> proj.export_user_role_assignment() [{'username': ..., 'unique_role_name': '', 'data_access_group': ''}] \"\"\" payload = self . _initialize_payload ( content = \"userRoleMapping\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userRoleMapping\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_user_role_assignment ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import User-Role assignments into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of user-role assignments added or updated Examples: >>> user_role_assignments = proj.export_user_role_assignment() >>> proj.import_user_role_assignment(user_role_assignments) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userRoleMapping\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"UserRoles"},{"location":"api_reference/user_roles/#redcap.methods.user_roles.UserRoles.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/user_roles/#redcap.methods.user_roles.UserRoles.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/user_roles/#redcap.methods.user_roles.UserRoles.forms","text":"Project form names","title":"forms"},{"location":"api_reference/user_roles/#redcap.methods.user_roles.UserRoles.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/user_roles/#redcap.methods.user_roles.UserRoles.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/user_roles/#redcap.methods.user_roles.UserRoles.token","text":"API token to a project","title":"token"},{"location":"api_reference/user_roles/#redcap.methods.user_roles.UserRoles.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/user_roles/#redcap.methods.user_roles.UserRoles.delete_user_roles","text":"Delete user roles from the project. Parameters: Name Type Description Default roles List[str] List of user roles to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of user roles deleted Examples: Create a new user role >>> new_role = [{ \"role_label\" : \"New Role\" }] >>> proj . import_user_roles ( new_role ) 1 We don't know what the 'unique_role_name' is for the newly created role, so we have to look it up by 'role_label' >>> roles = proj . export_user_roles () >>> new_role_id = [ ... role for role in roles ... if role [ \"role_label\" ] == \"New Role\" ... ][ 0 ][ \"unique_role_name\" ] Delete the role >>> proj . delete_user_roles ([ new_role_id ]) 1 Source code in redcap/methods/user_roles.py def delete_user_roles ( self , roles : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete user roles from the project. Args: roles: List of user roles to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of user roles deleted Examples: Create a new user role >>> new_role = [{\"role_label\": \"New Role\"}] >>> proj.import_user_roles(new_role) 1 We don't know what the 'unique_role_name' is for the newly created role, so we have to look it up by 'role_label' >>> roles = proj.export_user_roles() >>> new_role_id = [ ... role for role in roles ... if role[\"role_label\"] == \"New Role\" ... ][0][\"unique_role_name\"] Delete the role >>> proj.delete_user_roles([new_role_id]) 1 \"\"\" payload = self . _initialize_payload ( content = \"userRole\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of user roles into dict, and append to payload roles_dict = { f \"roles[ { idx } ]\" : role for idx , role in enumerate ( roles )} payload . update ( roles_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"delete_user_roles()"},{"location":"api_reference/user_roles/#redcap.methods.user_roles.UserRoles.export_user_role_assignment","text":"Export the User-Role assignments of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of user-role assignments Examples: >>> proj . export_user_role_assignment () [{ 'username' : ... , 'unique_role_name' : '' , 'data_access_group' : '' }] Source code in redcap/methods/user_roles.py def export_user_role_assignment ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the User-Role assignments of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of user-role assignments Examples: >>> proj.export_user_role_assignment() [{'username': ..., 'unique_role_name': '', 'data_access_group': ''}] \"\"\" payload = self . _initialize_payload ( content = \"userRoleMapping\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userRoleMapping\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_user_role_assignment()"},{"location":"api_reference/user_roles/#redcap.methods.user_roles.UserRoles.export_user_roles","text":"Export the user roles of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of user roles with assigned user rights Examples: >>> proj . export_user_roles () [{ 'unique_role_name' : ... , 'role_label' : 'Test role' , 'design' : '0' , 'alerts' : '0' , 'user_rights' : '0' , 'data_access_groups' : '0' , 'reports' : '0' , 'stats_and_charts' : '0' , 'manage_survey_participants' : '0' , 'calendar' : '0' , 'data_import_tool' : '0' , 'data_comparison_tool' : '0' , 'logging' : '0' , 'email_logging' : '0' , 'file_repository' : '0' , 'data_quality_create' : '0' , 'data_quality_execute' : '0' , 'api_export' : '0' , 'api_import' : '0' , 'api_modules' : '0' , 'mobile_app' : '0' , 'mobile_app_download_data' : '0' , 'record_create' : '0' , 'record_rename' : '0' , 'record_delete' : '0' , 'lock_records_customization' : '0' , 'lock_records' : '0' , ... , 'forms' : { 'form_1' : 2 }, 'forms_export' : { 'form_1' : 0 }}] Source code in redcap/methods/user_roles.py def export_user_roles ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the user roles of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of user roles with assigned user rights Examples: >>> proj.export_user_roles() [{'unique_role_name': ..., 'role_label': 'Test role', 'design': '0', 'alerts': '0', 'user_rights': '0', 'data_access_groups': '0', 'reports': '0', 'stats_and_charts': '0', 'manage_survey_participants': '0', 'calendar': '0', 'data_import_tool': '0', 'data_comparison_tool': '0', 'logging': '0', 'email_logging': '0', 'file_repository': '0', 'data_quality_create': '0', 'data_quality_execute': '0', 'api_export': '0', 'api_import': '0', 'api_modules': '0', 'mobile_app': '0', 'mobile_app_download_data': '0', 'record_create': '0', 'record_rename': '0', 'record_delete': '0', 'lock_records_customization': '0', 'lock_records': '0', ..., 'forms': {'form_1': 2}, 'forms_export': {'form_1': 0}}] \"\"\" payload = self . _initialize_payload ( content = \"userRole\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"userRole\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_user_roles()"},{"location":"api_reference/user_roles/#redcap.methods.user_roles.UserRoles.import_user_role_assignment","text":"Import User-Role assignments into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of user-role assignments added or updated Examples: >>> user_role_assignments = proj . export_user_role_assignment () >>> proj . import_user_role_assignment ( user_role_assignments ) 1 Source code in redcap/methods/user_roles.py def import_user_role_assignment ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import User-Role assignments into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of user-role assignments added or updated Examples: >>> user_role_assignments = proj.export_user_role_assignment() >>> proj.import_user_role_assignment(user_role_assignments) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userRoleMapping\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_user_role_assignment()"},{"location":"api_reference/user_roles/#redcap.methods.user_roles.UserRoles.import_user_roles","text":"Import user roles into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of user roles added or updated Examples: >>> roles = proj . export_user_roles () >>> proj . import_user_roles ( roles ) 1 Source code in redcap/methods/user_roles.py def import_user_roles ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import user roles into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of user roles added or updated Examples: >>> roles = proj.export_user_roles() >>> proj.import_user_roles(roles) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"userRole\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_user_roles()"},{"location":"api_reference/users/","text":"Users REDCap API methods for Project users Users ( Base ) Responsible for all API methods under 'Users & User Privileges' in the API Playground Source code in redcap/methods/users.py class Users ( Base ): \"\"\"Responsible for all API methods under 'Users & User Privileges' in the API Playground\"\"\" def export_users ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the users of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of users with metadata Examples: >>> proj.export_users() [{'username': ..., 'email': ..., 'expiration': '', 'data_access_group': '', 'data_access_group_id': '', 'design': 1, 'alerts': 1, 'user_rights': 1, 'data_access_groups': 1, 'reports': 1, ...}] \"\"\" payload = self . _initialize_payload ( content = \"user\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"user\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_users ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import users/user rights into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of users added or updated Examples: Add test user. Only username is required >>> test_user = [{\"username\": \"pandeharris@gmail.com\"}] >>> proj.import_users(test_user) 1 All currently valid options for user rights >>> test_user = [ ... {\"username\": \"pandeharris@gmail.com\", \"email\": \"pandeharris@gmail.com\", ... \"firstname\": \"REDCap Trial\", \"lastname\": \"User\", \"expiration\": \"\", ... \"data_access_group\": \"\", \"data_access_group_id\": \"\", \"design\": 0, ... \"user_rights\": 0, \"data_export\": 2, \"reports\": 1, \"stats_and_charts\": 1, ... \"manage_survey_participants\": 1, \"calendar\": 1, \"data_access_groups\": 0, ... \"data_import_tool\": 0, \"data_comparison_tool\": 0, \"logging\": 0, ... \"file_repository\": 1, \"data_quality_create\": 0, \"data_quality_execute\": 0, ... \"api_export\": 0, \"api_import\": 0, \"mobile_app\": 0, ... \"mobile_app_download_data\": 0, \"record_create\": 1, \"record_rename\": 0, ... \"record_delete\": 0, \"lock_records_all_forms\": 0, \"lock_records\": 0, ... \"lock_records_customization\": 0, \"forms\": {\"form_1\": 3}} ... ] >>> proj.import_users(test_user) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"user\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def delete_users ( self , users : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete users from the project. Args: users: List of usernames to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of users deleted Examples: >>> new_user = [{\"username\": \"pandeharris@gmail.com\"}] >>> proj.import_users(new_user) 1 >>> proj.delete_users([\"pandeharris@gmail.com\"], return_format_type=\"xml\") '1' \"\"\" payload = self . _initialize_payload ( content = \"user\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of users into dict, and append to payload users_dict = { f \"users[ { idx } ]\" : user for idx , user in enumerate ( users )} payload . update ( users_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server delete_users ( self , users , return_format_type = 'json' ) Delete users from the project. Parameters: Name Type Description Default users List[str] List of usernames to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of users deleted Examples: >>> new_user = [{ \"username\" : \"pandeharris@gmail.com\" }] >>> proj . import_users ( new_user ) 1 >>> proj . delete_users ([ \"pandeharris@gmail.com\" ], return_format_type = \"xml\" ) '1' Source code in redcap/methods/users.py def delete_users ( self , users : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete users from the project. Args: users: List of usernames to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of users deleted Examples: >>> new_user = [{\"username\": \"pandeharris@gmail.com\"}] >>> proj.import_users(new_user) 1 >>> proj.delete_users([\"pandeharris@gmail.com\"], return_format_type=\"xml\") '1' \"\"\" payload = self . _initialize_payload ( content = \"user\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of users into dict, and append to payload users_dict = { f \"users[ { idx } ]\" : user for idx , user in enumerate ( users )} payload . update ( users_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response export_users ( self , format_type = 'json' , df_kwargs = None ) Export the users of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of users with metadata Examples: >>> proj . export_users () [{ 'username' : ... , 'email' : ... , 'expiration' : '' , 'data_access_group' : '' , 'data_access_group_id' : '' , 'design' : 1 , 'alerts' : 1 , 'user_rights' : 1 , 'data_access_groups' : 1 , 'reports' : 1 , ... }] Source code in redcap/methods/users.py def export_users ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the users of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of users with metadata Examples: >>> proj.export_users() [{'username': ..., 'email': ..., 'expiration': '', 'data_access_group': '', 'data_access_group_id': '', 'design': 1, 'alerts': 1, 'user_rights': 1, 'data_access_groups': 1, 'reports': 1, ...}] \"\"\" payload = self . _initialize_payload ( content = \"user\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"user\" , format_type = format_type , df_kwargs = df_kwargs , ) import_users ( self , to_import , return_format_type = 'json' , import_format = 'json' ) Import users/user rights into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of users added or updated Examples: Add test user. Only username is required >>> test_user = [{ \"username\" : \"pandeharris@gmail.com\" }] >>> proj . import_users ( test_user ) 1 All currently valid options for user rights >>> test_user = [ ... { \"username\" : \"pandeharris@gmail.com\" , \"email\" : \"pandeharris@gmail.com\" , ... \"firstname\" : \"REDCap Trial\" , \"lastname\" : \"User\" , \"expiration\" : \"\" , ... \"data_access_group\" : \"\" , \"data_access_group_id\" : \"\" , \"design\" : 0 , ... \"user_rights\" : 0 , \"data_export\" : 2 , \"reports\" : 1 , \"stats_and_charts\" : 1 , ... \"manage_survey_participants\" : 1 , \"calendar\" : 1 , \"data_access_groups\" : 0 , ... \"data_import_tool\" : 0 , \"data_comparison_tool\" : 0 , \"logging\" : 0 , ... \"file_repository\" : 1 , \"data_quality_create\" : 0 , \"data_quality_execute\" : 0 , ... \"api_export\" : 0 , \"api_import\" : 0 , \"mobile_app\" : 0 , ... \"mobile_app_download_data\" : 0 , \"record_create\" : 1 , \"record_rename\" : 0 , ... \"record_delete\" : 0 , \"lock_records_all_forms\" : 0 , \"lock_records\" : 0 , ... \"lock_records_customization\" : 0 , \"forms\" : { \"form_1\" : 3 }} ... ] >>> proj . import_users ( test_user ) 1 Source code in redcap/methods/users.py def import_users ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import users/user rights into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of users added or updated Examples: Add test user. Only username is required >>> test_user = [{\"username\": \"pandeharris@gmail.com\"}] >>> proj.import_users(test_user) 1 All currently valid options for user rights >>> test_user = [ ... {\"username\": \"pandeharris@gmail.com\", \"email\": \"pandeharris@gmail.com\", ... \"firstname\": \"REDCap Trial\", \"lastname\": \"User\", \"expiration\": \"\", ... \"data_access_group\": \"\", \"data_access_group_id\": \"\", \"design\": 0, ... \"user_rights\": 0, \"data_export\": 2, \"reports\": 1, \"stats_and_charts\": 1, ... \"manage_survey_participants\": 1, \"calendar\": 1, \"data_access_groups\": 0, ... \"data_import_tool\": 0, \"data_comparison_tool\": 0, \"logging\": 0, ... \"file_repository\": 1, \"data_quality_create\": 0, \"data_quality_execute\": 0, ... \"api_export\": 0, \"api_import\": 0, \"mobile_app\": 0, ... \"mobile_app_download_data\": 0, \"record_create\": 1, \"record_rename\": 0, ... \"record_delete\": 0, \"lock_records_all_forms\": 0, \"lock_records\": 0, ... \"lock_records_customization\": 0, \"forms\": {\"form_1\": 3}} ... ] >>> proj.import_users(test_user) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"user\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"Users"},{"location":"api_reference/users/#users","text":"REDCap API methods for Project users","title":"Users"},{"location":"api_reference/users/#redcap.methods.users.Users","text":"Responsible for all API methods under 'Users & User Privileges' in the API Playground Source code in redcap/methods/users.py class Users ( Base ): \"\"\"Responsible for all API methods under 'Users & User Privileges' in the API Playground\"\"\" def export_users ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the users of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of users with metadata Examples: >>> proj.export_users() [{'username': ..., 'email': ..., 'expiration': '', 'data_access_group': '', 'data_access_group_id': '', 'design': 1, 'alerts': 1, 'user_rights': 1, 'data_access_groups': 1, 'reports': 1, ...}] \"\"\" payload = self . _initialize_payload ( content = \"user\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"user\" , format_type = format_type , df_kwargs = df_kwargs , ) def import_users ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import users/user rights into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of users added or updated Examples: Add test user. Only username is required >>> test_user = [{\"username\": \"pandeharris@gmail.com\"}] >>> proj.import_users(test_user) 1 All currently valid options for user rights >>> test_user = [ ... {\"username\": \"pandeharris@gmail.com\", \"email\": \"pandeharris@gmail.com\", ... \"firstname\": \"REDCap Trial\", \"lastname\": \"User\", \"expiration\": \"\", ... \"data_access_group\": \"\", \"data_access_group_id\": \"\", \"design\": 0, ... \"user_rights\": 0, \"data_export\": 2, \"reports\": 1, \"stats_and_charts\": 1, ... \"manage_survey_participants\": 1, \"calendar\": 1, \"data_access_groups\": 0, ... \"data_import_tool\": 0, \"data_comparison_tool\": 0, \"logging\": 0, ... \"file_repository\": 1, \"data_quality_create\": 0, \"data_quality_execute\": 0, ... \"api_export\": 0, \"api_import\": 0, \"mobile_app\": 0, ... \"mobile_app_download_data\": 0, \"record_create\": 1, \"record_rename\": 0, ... \"record_delete\": 0, \"lock_records_all_forms\": 0, \"lock_records\": 0, ... \"lock_records_customization\": 0, \"forms\": {\"form_1\": 3}} ... ] >>> proj.import_users(test_user) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"user\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response def delete_users ( self , users : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete users from the project. Args: users: List of usernames to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of users deleted Examples: >>> new_user = [{\"username\": \"pandeharris@gmail.com\"}] >>> proj.import_users(new_user) 1 >>> proj.delete_users([\"pandeharris@gmail.com\"], return_format_type=\"xml\") '1' \"\"\" payload = self . _initialize_payload ( content = \"user\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of users into dict, and append to payload users_dict = { f \"users[ { idx } ]\" : user for idx , user in enumerate ( users )} payload . update ( users_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"Users"},{"location":"api_reference/users/#redcap.methods.users.Users.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/users/#redcap.methods.users.Users.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/users/#redcap.methods.users.Users.forms","text":"Project form names","title":"forms"},{"location":"api_reference/users/#redcap.methods.users.Users.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/users/#redcap.methods.users.Users.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/users/#redcap.methods.users.Users.token","text":"API token to a project","title":"token"},{"location":"api_reference/users/#redcap.methods.users.Users.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/users/#redcap.methods.users.Users.delete_users","text":"Delete users from the project. Parameters: Name Type Description Default users List[str] List of usernames to delete from the project required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' Returns: Type Description Union[int, str] Number of users deleted Examples: >>> new_user = [{ \"username\" : \"pandeharris@gmail.com\" }] >>> proj . import_users ( new_user ) 1 >>> proj . delete_users ([ \"pandeharris@gmail.com\" ], return_format_type = \"xml\" ) '1' Source code in redcap/methods/users.py def delete_users ( self , users : List [ str ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , ): \"\"\" Delete users from the project. Args: users: List of usernames to delete from the project return_format_type: Response format. By default, response will be json-decoded. Returns: Union[int, str]: Number of users deleted Examples: >>> new_user = [{\"username\": \"pandeharris@gmail.com\"}] >>> proj.import_users(new_user) 1 >>> proj.delete_users([\"pandeharris@gmail.com\"], return_format_type=\"xml\") '1' \"\"\" payload = self . _initialize_payload ( content = \"user\" , return_format_type = return_format_type ) payload [ \"action\" ] = \"delete\" # Turn list of users into dict, and append to payload users_dict = { f \"users[ { idx } ]\" : user for idx , user in enumerate ( users )} payload . update ( users_dict ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"delete\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"delete_users()"},{"location":"api_reference/users/#redcap.methods.users.Users.export_users","text":"Export the users of the Project Parameters: Name Type Description Default format_type Literal['json', 'csv', 'xml', 'df'] Response return format 'json' df_kwargs Optional[Dict[str, Any]] Passed to pandas.read_csv to control construction of returned DataFrame. By default, nothing None Returns: Type Description Union[List[Dict[str, Any]], str, pandas.DataFrame] List of users with metadata Examples: >>> proj . export_users () [{ 'username' : ... , 'email' : ... , 'expiration' : '' , 'data_access_group' : '' , 'data_access_group_id' : '' , 'design' : 1 , 'alerts' : 1 , 'user_rights' : 1 , 'data_access_groups' : 1 , 'reports' : 1 , ... }] Source code in redcap/methods/users.py def export_users ( self , format_type : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , df_kwargs : Optional [ Dict [ str , Any ]] = None , ): \"\"\" Export the users of the Project Args: format_type: Response return format df_kwargs: Passed to `pandas.read_csv` to control construction of returned DataFrame. By default, nothing Returns: Union[List[Dict[str, Any]], str, pandas.DataFrame]: List of users with metadata Examples: >>> proj.export_users() [{'username': ..., 'email': ..., 'expiration': '', 'data_access_group': '', 'data_access_group_id': '', 'design': 1, 'alerts': 1, 'user_rights': 1, 'data_access_groups': 1, 'reports': 1, ...}] \"\"\" payload = self . _initialize_payload ( content = \"user\" , format_type = format_type ) return_type = self . _lookup_return_type ( format_type , request_type = \"export\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return self . _return_data ( response = response , content = \"user\" , format_type = format_type , df_kwargs = df_kwargs , )","title":"export_users()"},{"location":"api_reference/users/#redcap.methods.users.Users.import_users","text":"Import users/user rights into the REDCap Project Parameters: Name Type Description Default to_import Union[str, List[Dict[str, Any]], pd.DataFrame] array of dicts, csv/xml string, pandas.DataFrame Note: If you pass a csv or xml string, you should use the import format parameter appropriately. required return_format_type Literal['json', 'csv', 'xml'] Response format. By default, response will be json-decoded. 'json' import_format Literal['json', 'csv', 'xml', 'df'] Format of incoming data. By default, to_import will be json-encoded 'json' Returns: Type Description Union[int, str] Number of users added or updated Examples: Add test user. Only username is required >>> test_user = [{ \"username\" : \"pandeharris@gmail.com\" }] >>> proj . import_users ( test_user ) 1 All currently valid options for user rights >>> test_user = [ ... { \"username\" : \"pandeharris@gmail.com\" , \"email\" : \"pandeharris@gmail.com\" , ... \"firstname\" : \"REDCap Trial\" , \"lastname\" : \"User\" , \"expiration\" : \"\" , ... \"data_access_group\" : \"\" , \"data_access_group_id\" : \"\" , \"design\" : 0 , ... \"user_rights\" : 0 , \"data_export\" : 2 , \"reports\" : 1 , \"stats_and_charts\" : 1 , ... \"manage_survey_participants\" : 1 , \"calendar\" : 1 , \"data_access_groups\" : 0 , ... \"data_import_tool\" : 0 , \"data_comparison_tool\" : 0 , \"logging\" : 0 , ... \"file_repository\" : 1 , \"data_quality_create\" : 0 , \"data_quality_execute\" : 0 , ... \"api_export\" : 0 , \"api_import\" : 0 , \"mobile_app\" : 0 , ... \"mobile_app_download_data\" : 0 , \"record_create\" : 1 , \"record_rename\" : 0 , ... \"record_delete\" : 0 , \"lock_records_all_forms\" : 0 , \"lock_records\" : 0 , ... \"lock_records_customization\" : 0 , \"forms\" : { \"form_1\" : 3 }} ... ] >>> proj . import_users ( test_user ) 1 Source code in redcap/methods/users.py def import_users ( self , to_import : Union [ str , List [ Dict [ str , Any ]], \"pd.DataFrame\" ], return_format_type : Literal [ \"json\" , \"csv\" , \"xml\" ] = \"json\" , import_format : Literal [ \"json\" , \"csv\" , \"xml\" , \"df\" ] = \"json\" , ): \"\"\" Import users/user rights into the REDCap Project Args: to_import: array of dicts, csv/xml string, `pandas.DataFrame` Note: If you pass a csv or xml string, you should use the `import format` parameter appropriately. return_format_type: Response format. By default, response will be json-decoded. import_format: Format of incoming data. By default, to_import will be json-encoded Returns: Union[int, str]: Number of users added or updated Examples: Add test user. Only username is required >>> test_user = [{\"username\": \"pandeharris@gmail.com\"}] >>> proj.import_users(test_user) 1 All currently valid options for user rights >>> test_user = [ ... {\"username\": \"pandeharris@gmail.com\", \"email\": \"pandeharris@gmail.com\", ... \"firstname\": \"REDCap Trial\", \"lastname\": \"User\", \"expiration\": \"\", ... \"data_access_group\": \"\", \"data_access_group_id\": \"\", \"design\": 0, ... \"user_rights\": 0, \"data_export\": 2, \"reports\": 1, \"stats_and_charts\": 1, ... \"manage_survey_participants\": 1, \"calendar\": 1, \"data_access_groups\": 0, ... \"data_import_tool\": 0, \"data_comparison_tool\": 0, \"logging\": 0, ... \"file_repository\": 1, \"data_quality_create\": 0, \"data_quality_execute\": 0, ... \"api_export\": 0, \"api_import\": 0, \"mobile_app\": 0, ... \"mobile_app_download_data\": 0, \"record_create\": 1, \"record_rename\": 0, ... \"record_delete\": 0, \"lock_records_all_forms\": 0, \"lock_records\": 0, ... \"lock_records_customization\": 0, \"forms\": {\"form_1\": 3}} ... ] >>> proj.import_users(test_user) 1 \"\"\" payload = self . _initialize_import_payload ( to_import = to_import , import_format = import_format , return_format_type = return_format_type , content = \"user\" , ) return_type = self . _lookup_return_type ( format_type = return_format_type , request_type = \"import\" ) response = cast ( Union [ Json , str ], self . _call_api ( payload , return_type )) return response","title":"import_users()"},{"location":"api_reference/version/","text":"Version REDCap API methods for Project REDCap version Version ( Base ) Responsible for all API methods under 'REDCap' in the API Playground Source code in redcap/methods/version.py class Version ( Base ): \"\"\"Responsible for all API methods under 'REDCap' in the API Playground\"\"\" def export_version ( self ) -> Optional [ semantic_version . Version ]: \"\"\" Get the REDCap version Returns: REDCap version running on the url provided Examples: >>> import semantic_version >>> redcap_version = proj.export_version() >>> assert redcap_version >= semantic_version.Version(\"12.0.1\") \"\"\" payload = self . _initialize_payload ( \"version\" ) resp = None redcap_version = self . _call_api ( payload , return_type = \"str\" ) if semantic_version . validate ( redcap_version ): resp = semantic_version . Version ( redcap_version ) return resp def_field : str inherited property readonly The 'record_id' field equivalent for a project field_names : List [ str ] inherited property readonly Project field names !!! note These are survey field names, not export field names forms : List [ str ] inherited property readonly Project form names is_longitudinal : bool inherited property readonly Whether or not this project is longitudinal metadata : Json inherited property readonly Project metadata in JSON format token : str inherited property readonly API token to a project url : str inherited property readonly API URL to a REDCap server export_version ( self ) Get the REDCap version Returns: Type Description Optional[semantic_version.base.Version] REDCap version running on the url provided Examples: >>> import semantic_version >>> redcap_version = proj . export_version () >>> assert redcap_version >= semantic_version . Version ( \"12.0.1\" ) Source code in redcap/methods/version.py def export_version ( self ) -> Optional [ semantic_version . Version ]: \"\"\" Get the REDCap version Returns: REDCap version running on the url provided Examples: >>> import semantic_version >>> redcap_version = proj.export_version() >>> assert redcap_version >= semantic_version.Version(\"12.0.1\") \"\"\" payload = self . _initialize_payload ( \"version\" ) resp = None redcap_version = self . _call_api ( payload , return_type = \"str\" ) if semantic_version . validate ( redcap_version ): resp = semantic_version . Version ( redcap_version ) return resp","title":"Version"},{"location":"api_reference/version/#version","text":"REDCap API methods for Project REDCap version","title":"Version"},{"location":"api_reference/version/#redcap.methods.version.Version","text":"Responsible for all API methods under 'REDCap' in the API Playground Source code in redcap/methods/version.py class Version ( Base ): \"\"\"Responsible for all API methods under 'REDCap' in the API Playground\"\"\" def export_version ( self ) -> Optional [ semantic_version . Version ]: \"\"\" Get the REDCap version Returns: REDCap version running on the url provided Examples: >>> import semantic_version >>> redcap_version = proj.export_version() >>> assert redcap_version >= semantic_version.Version(\"12.0.1\") \"\"\" payload = self . _initialize_payload ( \"version\" ) resp = None redcap_version = self . _call_api ( payload , return_type = \"str\" ) if semantic_version . validate ( redcap_version ): resp = semantic_version . Version ( redcap_version ) return resp","title":"Version"},{"location":"api_reference/version/#redcap.methods.version.Version.def_field","text":"The 'record_id' field equivalent for a project","title":"def_field"},{"location":"api_reference/version/#redcap.methods.version.Version.field_names","text":"Project field names !!! note These are survey field names, not export field names","title":"field_names"},{"location":"api_reference/version/#redcap.methods.version.Version.forms","text":"Project form names","title":"forms"},{"location":"api_reference/version/#redcap.methods.version.Version.is_longitudinal","text":"Whether or not this project is longitudinal","title":"is_longitudinal"},{"location":"api_reference/version/#redcap.methods.version.Version.metadata","text":"Project metadata in JSON format","title":"metadata"},{"location":"api_reference/version/#redcap.methods.version.Version.token","text":"API token to a project","title":"token"},{"location":"api_reference/version/#redcap.methods.version.Version.url","text":"API URL to a REDCap server","title":"url"},{"location":"api_reference/version/#redcap.methods.version.Version.export_version","text":"Get the REDCap version Returns: Type Description Optional[semantic_version.base.Version] REDCap version running on the url provided Examples: >>> import semantic_version >>> redcap_version = proj . export_version () >>> assert redcap_version >= semantic_version . Version ( \"12.0.1\" ) Source code in redcap/methods/version.py def export_version ( self ) -> Optional [ semantic_version . Version ]: \"\"\" Get the REDCap version Returns: REDCap version running on the url provided Examples: >>> import semantic_version >>> redcap_version = proj.export_version() >>> assert redcap_version >= semantic_version.Version(\"12.0.1\") \"\"\" payload = self . _initialize_payload ( \"version\" ) resp = None redcap_version = self . _call_api ( payload , return_type = \"str\" ) if semantic_version . validate ( redcap_version ): resp = semantic_version . Version ( redcap_version ) return resp","title":"export_version()"}]}